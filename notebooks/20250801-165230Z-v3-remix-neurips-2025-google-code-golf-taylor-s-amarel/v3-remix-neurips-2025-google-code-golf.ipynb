{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":95282,"databundleVersionId":13245791,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport os\nimport zipfile\nimport numpy as np\nfrom collections import defaultdict, Counter\nfrom scipy.ndimage import label, binary_dilation, binary_erosion\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import KFold\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\nfrom typing import List, Dict, Tuple, Optional, Any\nimport random\nimport traceback\nimport warnings\nimport itertools\nwarnings.filterwarnings('ignore')\n\nARC_COLORS = {\n    0: '#000000',\n    1: '#0074D9',\n    2: '#FF4136',\n    3: '#2ECC40',\n    4: '#FFDC00',\n    5: '#AAAAAA',\n    6: '#F012BE',\n    7: '#FF851B',\n    8: '#7FDBFF',\n    9: '#870C25'\n}\n\nclass EnhancedARCSolutionGenerator:\n    def __init__(self, enable_visuals=True, genetic_generations=10):\n        self.enable_visuals = enable_visuals\n        self.genetic_generations = genetic_generations\n        self.pattern_success_rates = defaultdict(lambda: {'attempts': 0, 'successes': 0})\n        self.solution_complexity_scores = {}\n        self.pattern_explanations = {}\n        self.population = []\n        self.fitness_history = []\n        \n        # Extended pattern handlers list with new patterns\n        self.pattern_handlers = [\n            # Original patterns\n            (self.handle_outline_only, \"Extract object outlines\", \"geometric\"),\n            (self.handle_center_object, \"Center objects in grid\", \"geometric\"),\n            (self.handle_diagonal_mirror, \"Diagonal mirror transformation\", \"geometric\"),\n            (self.handle_color_palette_row, \"Extract color palette\", \"color\"),\n            (self.handle_bounding_fill_by_color, \"Fill bounding boxes by color\", \"geometric\"),\n            (self.handle_row_col_propagation, \"Propagate colors along rows/columns\", \"propagation\"),\n            (self.handle_repeat_pattern, \"Tile pattern across grid\", \"tiling\"),\n            (self.handle_checkerboard, \"Create checkerboard pattern\", \"tiling\"),\n            (self.handle_vertical_stripes, \"Create vertical stripes\", \"tiling\"),\n            (self.handle_horizontal_stripes, \"Create horizontal stripes\", \"tiling\"),\n            (self.handle_majority_color_fill, \"Fill with majority color\", \"color\"),\n            (self.handle_cross_lines, \"Draw cross lines\", \"geometric\"),\n            (self.handle_color_swap, \"Swap two colors\", \"color\"),\n            (self.handle_crop_center, \"Crop to center region\", \"geometric\"),\n            (self.handle_single_color_output, \"Output single color\", \"color\"),\n            (self.handle_bounding_crop, \"Crop to bounding box\", \"geometric\"),\n            (self.handle_overlay_fill, \"Overlay fill pattern\", \"composite\"),\n            (self.handle_remove_color, \"Remove specific color\", \"color\"),\n            (self.handle_color_mapping, \"Map colors to new values\", \"color\"),\n            (self.handle_grid_operations, \"Grid rotation/flip\", \"geometric\"),\n            (self.handle_resize, \"Resize grid\", \"geometric\"),\n            (self.handle_object_operations, \"Object translations\", \"geometric\"),\n            (self.handle_pattern_replication, \"Replicate patterns\", \"tiling\"),\n            (self.handle_mirror_symmetry, \"Mirror symmetry\", \"geometric\"),\n            (self.handle_arithmetic_operations, \"Arithmetic operations\", \"arithmetic\"),\n            (self.handle_conditional_operations, \"Conditional operations\", \"logic\"),\n            (self.handle_upscale_nearest, \"Nearest neighbor upscaling\", \"scaling\"),\n            (self.handle_downscale_sample, \"Downscale by sampling\", \"scaling\"),\n            (self.handle_fill_gaps_rowwise, \"Fill gaps in rows\", \"propagation\"),\n            (self.handle_background_to_majority, \"Change background to majority\", \"color\"),\n            (self.handle_keep_dominant_color, \"Keep only dominant color\", \"color\"),\n            (self.handle_extract_first_nonempty_rowcol, \"Extract first non-empty row/col\", \"extraction\"),\n            (self.handle_sort_rows_by_density, \"Sort rows by density\", \"sorting\"),\n            (self.handle_sort_cols_by_density, \"Sort columns by density\", \"sorting\"),\n            (self.handle_complete_by_mirror_half, \"Complete by mirroring half\", \"geometric\"),\n            (self.handle_palette_column, \"Extract color palette column\", \"color\"),\n            (self.handle_uniform_row_fill, \"Fill rows uniformly\", \"propagation\"),\n            (self.handle_uniform_col_fill, \"Fill columns uniformly\", \"propagation\"),\n            (self.handle_draw_frame, \"Draw frame around grid\", \"geometric\"),\n            (self.handle_main_diag_line, \"Draw main diagonal\", \"geometric\"),\n            (self.handle_anti_diag_line, \"Draw anti-diagonal\", \"geometric\"),\n            (self.handle_border_to_zero, \"Clear border pixels\", \"geometric\"),\n            (self.handle_single_object_translate, \"Translate single object\", \"geometric\"),\n            (self.handle_object_count_row, \"Count objects in row\", \"counting\"),\n            (self.handle_color_shift_plus_one, \"Shift colors by +1\", \"arithmetic\"),\n            (self.handle_keep_colors, \"Keep only specific colors\", \"color\"),\n            (self.handle_remove_small_objects, \"Remove small objects\", \"filtering\"),\n            (self.handle_duplicate_quadrant, \"Duplicate quadrant\", \"tiling\"),\n            \n            # New patterns added\n            (self.handle_flood_fill, \"Flood fill from corners\", \"propagation\"),\n            (self.handle_extract_largest_object, \"Extract largest connected component\", \"filtering\"),\n            (self.handle_count_objects, \"Count connected components\", \"counting\"),\n            (self.handle_gravity_all_directions, \"Apply gravity in all directions\", \"physics\"),\n            (self.handle_snake_pattern, \"Snake/zigzag pattern\", \"geometric\"),\n            (self.handle_spiral_pattern, \"Spiral pattern\", \"geometric\"),\n            (self.handle_pixel_art_double, \"Pixel art doubling\", \"scaling\"),\n            (self.handle_extract_shape_template, \"Extract shape as template\", \"extraction\"),\n            (self.handle_apply_mask, \"Apply mask pattern\", \"composite\"),\n            (self.handle_color_gradient, \"Color gradient fill\", \"color\"),\n            (self.handle_binary_operations, \"Binary AND/OR/XOR\", \"logic\"),\n            (self.handle_convolution_patterns, \"Convolution patterns\", \"filtering\"),\n            (self.handle_symmetry_detection, \"Detect and apply symmetry\", \"geometric\"),\n            (self.handle_pattern_continuation, \"Continue pattern\", \"propagation\"),\n            (self.handle_object_duplication, \"Duplicate objects\", \"geometric\"),\n            (self.handle_color_inversion, \"Invert colors (9-x)\", \"arithmetic\"),\n            (self.handle_extract_corners, \"Extract corner regions\", \"extraction\"),\n            (self.handle_combine_grids, \"Combine multiple grids\", \"composite\"),\n            (self.handle_sliding_window, \"Sliding window operations\", \"filtering\"),\n            (self.handle_morphological_ops, \"Morphological operations\", \"filtering\"),\n        ]\n\n    # New pattern handlers\n    def handle_flood_fill(self, task_data, analysis):\n        \"\"\"Flood fill from corners or specific positions\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            if a.shape != b.shape:\n                return None\n            \n            # Check if it's a flood fill from corner\n            if a[0,0] == 0 and b[0,0] != 0:\n                fill_color = int(b[0,0])\n                # Simple flood fill from top-left\n                return f\"\"\"def p(g):\n H,W=len(g),len(g[0])\n out=[r[:] for r in g]\n stack=[(0,0)]\n out[0][0]={fill_color}\n while stack:\n  y,x=stack.pop()\n  for dy,dx in [(0,1),(1,0),(0,-1),(-1,0)]:\n   ny,nx=y+dy,x+dx\n   if 0<=ny<H and 0<=nx<W and out[ny][nx]==0:\n    out[ny][nx]={fill_color}\n    stack.append((ny,nx))\n return out\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_extract_largest_object(self, task_data, analysis):\n        \"\"\"Extract the largest connected component\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            # Label connected components\n            labeled, num = label(a > 0)\n            if num == 0:\n                return None\n            \n            # Find largest component\n            sizes = [np.sum(labeled == i) for i in range(1, num + 1)]\n            largest = np.argmax(sizes) + 1\n            \n            # Check if output is just the largest component\n            largest_mask = (labeled == largest).astype(int)\n            result = a * largest_mask\n            \n            if np.array_equal(result, b):\n                return \"\"\"def p(g):\n from scipy.ndimage import label\n import numpy as np\n a=np.array(g)\n labeled,num=label(a>0)\n if num==0: return g\n sizes=[np.sum(labeled==i) for i in range(1,num+1)]\n largest=np.argmax(sizes)+1\n mask=(labeled==largest).astype(int)\n return (a*mask).tolist()\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_count_objects(self, task_data, analysis):\n        \"\"\"Count number of connected components\"\"\"\n        try:\n            a, b = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n            \n            # Count objects in input\n            labeled, num = label(np.array(a) > 0)\n            \n            # Check various output formats\n            if len(b) == 1 and len(b[0]) == 1 and b[0][0] == num:\n                return \"\"\"def p(g):\n from scipy.ndimage import label\n import numpy as np\n _,n=label(np.array(g)>0)\n return [[n]]\n\"\"\"\n            \n            # Output as row of length num\n            if len(b) == 1 and len(b[0]) == num and all(x == 1 for x in b[0]):\n                return \"\"\"def p(g):\n from scipy.ndimage import label\n import numpy as np\n _,n=label(np.array(g)>0)\n return [[1]*n]\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_gravity_all_directions(self, task_data, analysis):\n        \"\"\"Apply gravity in different directions based on pattern\"\"\"\n        try:\n            a, b = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n            \n            # Try gravity in each direction\n            # Down\n            down = [[0]*len(a[0]) for _ in range(len(a)-sum(1 for r in a if any(r)))]+[r for r in a if any(r)]\n            if down == b:\n                return \"\"\"def p(g):\n return [[0]*len(g[0])for _ in range(len(g)-sum(1 for r in g if any(r)))]+[r for r in g if any(r)]\n\"\"\"\n            \n            # Up\n            up = [r for r in a if any(r)]+[[0]*len(a[0]) for _ in range(len(a)-sum(1 for r in a if any(r)))]\n            if up == b:\n                return \"\"\"def p(g):\n return [r for r in g if any(r)]+[[0]*len(g[0])for _ in range(len(g)-sum(1 for r in g if any(r)))]\n\"\"\"\n            \n            # Diagonal gravity (elements fall to bottom-left)\n            h, w = len(a), len(a[0])\n            result = [[0]*w for _ in range(h)]\n            for i in range(h):\n                for j in range(w):\n                    if a[i][j] != 0:\n                        # Find lowest position along diagonal\n                        ni, nj = i, j\n                        while ni + 1 < h and nj - 1 >= 0 and result[ni + 1][nj - 1] == 0:\n                            ni += 1\n                            nj -= 1\n                        result[ni][nj] = a[i][j]\n            if result == b:\n                return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n r=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    ni,nj=i,j\n    while ni+1<h and nj-1>=0 and r[ni+1][nj-1]==0:\n     ni+=1;nj-=1\n    r[ni][nj]=g[i][j]\n return r\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_snake_pattern(self, task_data, analysis):\n        \"\"\"Create snake/zigzag pattern\"\"\"\n        try:\n            out = task_data['train'][0]['output']\n            h, w = len(out), len(out[0])\n            \n            # Check if it's a snake pattern with incrementing values\n            expected = []\n            for i in range(h):\n                if i % 2 == 0:\n                    expected.extend([i*w + j for j in range(w)])\n                else:\n                    expected.extend([i*w + w - 1 - j for j in range(w)])\n            \n            flat_out = [x for row in out for x in row]\n            if all(flat_out[i] == expected[i] % 10 for i in range(len(flat_out))):\n                return f\"\"\"def p(g):\n h,w={h},{w}\n r=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   if i%2==0: row.append((i*w+j)%10)\n   else: row.append((i*w+w-1-j)%10)\n  r.append(row)\n return r\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_spiral_pattern(self, task_data, analysis):\n        \"\"\"Create spiral pattern\"\"\"\n        try:\n            out = np.array(task_data['train'][0]['output'])\n            h, w = out.shape\n            \n            # Generate spiral pattern and check if it matches\n            spiral = [[0]*w for _ in range(h)]\n            top, bottom, left, right = 0, h-1, 0, w-1\n            num = 0\n            \n            while top <= bottom and left <= right:\n                # Right\n                for i in range(left, right + 1):\n                    spiral[top][i] = num % 10\n                    num += 1\n                top += 1\n                \n                # Down\n                for i in range(top, bottom + 1):\n                    spiral[i][right] = num % 10\n                    num += 1\n                right -= 1\n                \n                # Left\n                if top <= bottom:\n                    for i in range(right, left - 1, -1):\n                        spiral[bottom][i] = num % 10\n                        num += 1\n                    bottom -= 1\n                \n                # Up\n                if left <= right:\n                    for i in range(bottom, top - 1, -1):\n                        spiral[i][left] = num % 10\n                        num += 1\n                    left += 1\n            \n            if np.array_equal(np.array(spiral), out):\n                return f\"\"\"def p(g):\n h,w={h},{w}\n s=[[0]*w for _ in range(h)]\n t,b,l,r=0,h-1,0,w-1\n n=0\n while t<=b and l<=r:\n  for i in range(l,r+1):s[t][i]=n%10;n+=1\n  t+=1\n  for i in range(t,b+1):s[i][r]=n%10;n+=1\n  r-=1\n  if t<=b:\n   for i in range(r,l-1,-1):s[b][i]=n%10;n+=1\n   b-=1\n  if l<=r:\n   for i in range(b,t-1,-1):s[i][l]=n%10;n+=1\n   l+=1\n return s\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_pixel_art_double(self, task_data, analysis):\n        \"\"\"Double each pixel (different from regular 2x scaling)\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            # Check if each pixel becomes a 2x2 block with variations\n            if b.shape[0] == a.shape[0] * 2 and b.shape[1] == a.shape[1] * 2:\n                # Check for pattern where each pixel becomes a specific 2x2 pattern\n                valid = True\n                for i in range(a.shape[0]):\n                    for j in range(a.shape[1]):\n                        block = b[i*2:(i+1)*2, j*2:(j+1)*2]\n                        # Check various patterns\n                        if a[i,j] == 0:\n                            if not np.all(block == 0):\n                                valid = False\n                                break\n                        else:\n                            # Cross pattern\n                            if block[0,0] == a[i,j] and block[1,1] == a[i,j] and block[0,1] == 0 and block[1,0] == 0:\n                                continue\n                            # Inverse cross\n                            elif block[0,1] == a[i,j] and block[1,0] == a[i,j] and block[0,0] == 0 and block[1,1] == 0:\n                                continue\n                            else:\n                                valid = False\n                                break\n                    if not valid:\n                        break\n                \n                if valid:\n                    return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n r=[[0]*(w*2) for _ in range(h*2)]\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    r[i*2][j*2]=g[i][j]\n    r[i*2+1][j*2+1]=g[i][j]\n return r\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_extract_shape_template(self, task_data, analysis):\n        \"\"\"Extract a specific shape pattern\"\"\"\n        try:\n            # Look for extraction of specific shapes (like L-shapes, T-shapes)\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            # If output is smaller, might be extracting a template\n            if b.shape[0] < a.shape[0] or b.shape[1] < a.shape[1]:\n                # Try to find b as a subregion in a\n                for i in range(a.shape[0] - b.shape[0] + 1):\n                    for j in range(a.shape[1] - b.shape[1] + 1):\n                        if np.array_equal(a[i:i+b.shape[0], j:j+b.shape[1]], b):\n                            return f\"\"\"def p(g):\n return [row[{j}:{j+b.shape[1]}] for row in g[{i}:{i+b.shape[0]}]]\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_apply_mask(self, task_data, analysis):\n        \"\"\"Apply a mask pattern to the input\"\"\"\n        try:\n            if len(task_data['train']) >= 2:\n                # Assume first input is data, second input is mask\n                a1 = np.array(task_data['train'][0]['input'])\n                a2 = np.array(task_data['train'][1]['input']) if len(task_data['train']) > 1 else None\n                b = np.array(task_data['train'][0]['output'])\n                \n                if a1.shape == b.shape:\n                    # Check if output is input masked by non-zero positions\n                    mask = (a1 > 0).astype(int)\n                    if np.array_equal(b, a1 * mask):\n                        return \"\"\"def p(g):\n return [[x if x>0 else 0 for x in r] for r in g]\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_color_gradient(self, task_data, analysis):\n        \"\"\"Generate color gradients\"\"\"\n        try:\n            out = np.array(task_data['train'][0]['output'])\n            h, w = out.shape\n            \n            # Radial gradient from center\n            cy, cx = h // 2, w // 2\n            radial = np.zeros((h, w))\n            for i in range(h):\n                for j in range(w):\n                    dist = int(np.sqrt((i - cy)**2 + (j - cx)**2))\n                    radial[i, j] = min(dist, 9)\n            \n            if np.array_equal(out, radial.astype(int)):\n                return f\"\"\"def p(g):\n h,w={h},{w}\n cy,cx=h//2,w//2\n import numpy as np\n r=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   d=int(np.sqrt((i-cy)**2+(j-cx)**2))\n   row.append(min(d,9))\n  r.append(row)\n return r\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_binary_operations(self, task_data, analysis):\n        \"\"\"Binary operations between grids\"\"\"\n        try:\n            if len(task_data['train']) >= 2:\n                # AND operation\n                inp = task_data['train'][0]['input']\n                out = task_data['train'][0]['output']\n                \n                # Self AND (keep non-zero)\n                and_result = [[1 if x > 0 else 0 for x in row] for row in inp]\n                if and_result == out:\n                    return \"\"\"def p(g):\n return [[1 if x>0 else 0 for x in r] for r in g]\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_convolution_patterns(self, task_data, analysis):\n        \"\"\"Apply convolution-like patterns\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            if a.shape == b.shape:\n                # Edge detection kernel\n                h, w = a.shape\n                result = np.zeros_like(a)\n                for i in range(1, h-1):\n                    for j in range(1, w-1):\n                        if a[i,j] > 0:\n                            # Count neighbors\n                            neighbors = sum(1 for di in [-1,0,1] for dj in [-1,0,1] \n                                          if (di,dj) != (0,0) and a[i+di,j+dj] > 0)\n                            if neighbors < 3:\n                                result[i,j] = a[i,j]\n                \n                if np.array_equal(result, b):\n                    return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n r=[[0]*w for _ in range(h)]\n for i in range(1,h-1):\n  for j in range(1,w-1):\n   if g[i][j]>0:\n    n=sum(1 for di in [-1,0,1] for dj in [-1,0,1] if (di,dj)!=(0,0) and g[i+di][j+dj]>0)\n    if n<3: r[i][j]=g[i][j]\n return r\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_symmetry_detection(self, task_data, analysis):\n        \"\"\"Detect and complete symmetry\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            if a.shape == b.shape:\n                # Check if completing vertical symmetry\n                h, w = a.shape\n                if w % 2 == 0:\n                    left_half = a[:, :w//2]\n                    right_half_flipped = a[:, w//2:][:, ::-1]\n                    \n                    # Complete right side from left\n                    result = np.hstack([left_half, left_half[:, ::-1]])\n                    if np.array_equal(result, b):\n                        return \"\"\"def p(g):\n w=len(g[0])\n return [r[:w//2]+r[:w//2][::-1] for r in g]\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_pattern_continuation(self, task_data, analysis):\n        \"\"\"Continue a pattern to fill the grid\"\"\"\n        try:\n            a, b = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n            \n            # Detect repeating pattern in first row/column and continue it\n            if len(a) > 0 and len(a[0]) > 0:\n                # Check row pattern\n                first_row = a[0]\n                pattern_len = 0\n                for plen in range(1, len(first_row)//2 + 1):\n                    if first_row[:plen] * (len(first_row)//plen) == first_row[:len(first_row)//plen*plen]:\n                        pattern_len = plen\n                        break\n                \n                if pattern_len > 0:\n                    pattern = first_row[:pattern_len]\n                    # Generate full grid with this pattern\n                    result = []\n                    for i in range(len(b)):\n                        row = []\n                        for j in range(len(b[0])):\n                            row.append(pattern[j % pattern_len])\n                        result.append(row)\n                    \n                    if result == b:\n                        pattern_str = str(pattern)\n                        return f\"\"\"def p(g):\n pat={pattern_str}\n h,w=len(g),len(g[0])\n return [[pat[j%{pattern_len}] for j in range(w)] for i in range(h)]\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_object_duplication(self, task_data, analysis):\n        \"\"\"Duplicate objects in specific patterns\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            # Check if objects are duplicated with offset\n            labeled_a, num_a = label(a > 0)\n            labeled_b, num_b = label(b > 0)\n            \n            if num_b == num_a * 2:  # Objects doubled\n                # Find offset pattern\n                return None  # Complex implementation\n        except:\n            pass\n        return None\n\n    def handle_color_inversion(self, task_data, analysis):\n        \"\"\"Invert colors using formula 9-x\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            if a.shape == b.shape:\n                # Check if it's color inversion\n                if np.all(b == 9 - a):\n                    return \"\"\"def p(g):\n return [[9-x for x in r] for r in g]\n\"\"\"\n                \n                # Check modular arithmetic\n                for mod in [2, 3, 4, 5, 6, 7, 8, 9]:\n                    if np.all(b == a % mod):\n                        return f\"\"\"def p(g):\n return [[x%{mod} for x in r] for r in g]\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_extract_corners(self, task_data, analysis):\n        \"\"\"Extract corner regions\"\"\"\n        try:\n            a, b = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n            \n            # Check if output is just corners\n            if len(b) == 2 and len(b[0]) == 2:\n                h, w = len(a), len(a[0])\n                corners = [[a[0][0], a[0][w-1]], [a[h-1][0], a[h-1][w-1]]]\n                if corners == b:\n                    return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n return [[g[0][0],g[0][w-1]],[g[h-1][0],g[h-1][w-1]]]\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_combine_grids(self, task_data, analysis):\n        \"\"\"Combine multiple grids using various operations\"\"\"\n        # This would need multiple inputs, skip for now\n        return None\n\n    def handle_sliding_window(self, task_data, analysis):\n        \"\"\"Apply sliding window operations\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            # Max pooling with 2x2 window\n            if b.shape[0] == a.shape[0]//2 and b.shape[1] == a.shape[1]//2:\n                valid = True\n                for i in range(b.shape[0]):\n                    for j in range(b.shape[1]):\n                        window = a[i*2:(i+1)*2, j*2:(j+1)*2]\n                        if b[i,j] != np.max(window):\n                            valid = False\n                            break\n                    if not valid:\n                        break\n                \n                if valid:\n                    return \"\"\"def p(g):\n h,w=len(g)//2,len(g[0])//2\n r=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   row.append(max(g[i*2][j*2],g[i*2][j*2+1],g[i*2+1][j*2],g[i*2+1][j*2+1]))\n  r.append(row)\n return r\n\"\"\"\n        except:\n            pass\n        return None\n\n    def handle_morphological_ops(self, task_data, analysis):\n        \"\"\"Morphological operations like erosion/dilation\"\"\"\n        try:\n            a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n            \n            if a.shape == b.shape:\n                # Dilation\n                dilated = binary_dilation(a > 0).astype(int)\n                if np.array_equal(b > 0, dilated):\n                    return \"\"\"def p(g):\n from scipy.ndimage import binary_dilation\n import numpy as np\n return (binary_dilation(np.array(g)>0).astype(int)*1).tolist()\n\"\"\"\n                \n                # Erosion\n                eroded = binary_erosion(a > 0).astype(int)\n                if np.array_equal(b > 0, eroded):\n                    return \"\"\"def p(g):\n from scipy.ndimage import binary_erosion\n import numpy as np\n return (binary_erosion(np.array(g)>0).astype(int)*1).tolist()\n\"\"\"\n        except:\n            pass\n        return None\n\n    # Fixed checkerboard handler\n    def handle_checkerboard(self, task_data, analysis):\n        try:\n            out = np.array(task_data['train'][0]['output'])\n            unique_values = np.unique(out)\n            \n            # Check if we have at least 2 unique values\n            if len(unique_values) < 2:\n                return None\n                \n            if len(unique_values) == 2:\n                c0, c1 = int(unique_values[0]), int(unique_values[1])\n                # Check if it's a checkerboard pattern\n                is_checker = True\n                for i in range(out.shape[0]):\n                    for j in range(out.shape[1]):\n                        expected = c0 if (i + j) % 2 == 0 else c1\n                        if out[i, j] != expected:\n                            is_checker = False\n                            break\n                    if not is_checker:\n                        break\n                \n                if is_checker:\n                    return f\"\"\"def p(g):\n return[[{c0} if (i+j)%2==0 else {c1} for j in range(len(g[0]))] for i in range(len(g))]\n\"\"\"\n        except:\n            pass\n        return None\n\n    # Fixed arithmetic operations handler\n    def handle_detect_arithmetic(self, in_grid, out_grid):\n        \"\"\"Fixed arithmetic detection with better error handling\"\"\"\n        if in_grid.shape != out_grid.shape:\n            return None\n            \n        try:\n            # Check addition\n            diff = out_grid - in_grid\n            if np.all(diff == diff[0,0]):\n                return ('add', int(diff[0,0]))\n            \n            # Check multiplication\n            non_zero_mask = in_grid > 0\n            if np.any(non_zero_mask):\n                with np.errstate(divide='ignore', invalid='ignore'):\n                    safe_in = np.where(in_grid == 0, 1, in_grid)\n                    ratio = out_grid / safe_in\n                    # Only check ratio where input is non-zero\n                    ratio_values = ratio[non_zero_mask]\n                    if len(ratio_values) > 0 and np.all(ratio_values == ratio_values[0]):\n                        return ('multiply', float(ratio_values[0]))\n        except:\n            pass\n        return None\n\n    # Original methods remain the same...\n    def handle_uniform_row_fill(self, task_data, analysis):\n        a,b = map(np.array,(task_data['train'][0]['input'],\n                            task_data['train'][0]['output']))\n        if a.shape!=b.shape: return None\n        ok=True\n        for r1,r2 in zip(a,b):\n            maj = np.bincount(r1).argmax()\n            if not np.all(r2==maj): ok=False; break\n        if not ok: return None\n        return \"\"\"def p(g):\n return [[max(set(r), key=r.count)]*len(r) for r in g]\n\"\"\"\n\n    def handle_uniform_col_fill(self, task_data, analysis):\n        a,b = map(np.array,(task_data['train'][0]['input'],\n                            task_data['train'][0]['output']))\n        if a.shape!=b.shape: return None\n        H,W=a.shape\n        ok=True\n        for j in range(W):\n            col=a[:,j].tolist()\n            maj=max(set(col), key=col.count)\n            if not np.all(b[:,j]==maj): ok=False; break\n        if not ok: return None\n        return \"\"\"def p(g):\n H,W=len(g),len(g[0])\n cols=[[g[i][j] for i in range(H)] for j in range(W)]\n res=[[0]*W for _ in range(H)]\n for j,col in enumerate(cols):\n  maj=max(set(col), key=col.count)\n  for i in range(H): res[i][j]=maj\n return res\n\"\"\"\n\n    def handle_draw_frame(self, task_data, analysis):\n        a,b = map(np.array,(task_data['train'][0]['input'],\n                            task_data['train'][0]['output']))\n        if b.shape[0]!=a.shape[0]+2 or b.shape[1]!=a.shape[1]+2: return None\n        frame_color = int(b[0,0])\n        inner = b[1:-1,1:-1]\n        if np.array_equal(inner,a) and \\\n           np.all(b[[0,-1],:]==frame_color) and np.all(b[:,[0,-1]]==frame_color):\n            return f\"\"\"def p(g):\n H,W=len(g),len(g[0])\n c={frame_color}\n out=[[c]*(W+2)]\n for r in g: out.append([c]+r+[c])\n out.append([c]*(W+2))\n return out\n\"\"\"\n        return None\n\n    def handle_main_diag_line(self, task_data, analysis):\n        a,b = map(np.array,(task_data['train'][0]['input'],\n                            task_data['train'][0]['output']))\n        if a.shape!=b.shape: return None\n        H,W=a.shape\n        if H!=W: return None\n        diff = np.where(a!=b)\n        if len(diff[0])==H and all(i==j for i,j in zip(*diff)):\n            c=int(b[0,0])\n            return f\"\"\"def p(g):\n n=len(g)\n return [[ {c} if i==j else g[i][j] for j in range(n)] for i in range(n)]\n\"\"\"\n        return None\n\n    def handle_anti_diag_line(self, task_data, analysis):\n        a,b = map(np.array,(task_data['train'][0]['input'],\n                            task_data['train'][0]['output']))\n        if a.shape!=b.shape: return None\n        H,W=a.shape\n        if H!=W: return None\n        diff = np.where(a!=b)\n        if len(diff[0])==H and all(i+j==H-1 for i,j in zip(*diff)):\n            c=int(b[0,W-1])\n            return f\"\"\"def p(g):\n n=len(g)\n return [[ {c} if i+j==n-1 else g[i][j] for j in range(n)] for i in range(n)]\n\"\"\"\n        return None\n\n    def handle_border_to_zero(self, task_data, analysis):\n        a,b = map(np.array,(task_data['train'][0]['input'],\n                            task_data['train'][0]['output']))\n        if a.shape!=b.shape: return None\n        inner = a[1:-1,1:-1]\n        if np.array_equal(b[1:-1,1:-1], inner) and np.all(b[[0,-1],:]==0) \\\n           and np.all(b[:,[0,-1]]==0):\n            return \"\"\"def p(g):\n H,W=len(g),len(g[0])\n out=[r[:] for r in g]\n for i in range(H):\n  out[i][0]=out[i][-1]=0\n for j in range(W):\n  out[0][j]=out[-1][j]=0\n return out\n\"\"\"\n        return None\n\n    def handle_single_object_translate(self, task_data, analysis):\n        try:\n            if not analysis['object_properties'] or not analysis['object_properties'][0]:\n                return None\n            props = analysis['object_properties'][0][0]\n            mv = props.get('position_change', None)\n            if mv is None or isinstance(mv, str):\n                return None\n            dy, dx = map(int, mv)\n            if (dy, dx) == (0, 0):\n                return None\n            return f'''def p(g):\n H, W = len(g), len(g[0])\n ys = [i for i,row in enumerate(g) for v in row if v]\n xs = [j for i,row in enumerate(g) for j,v in enumerate(row) if v]\n res = [[0]*W for _ in range(H)]\n for i,j in zip(ys, xs):\n     ni, nj = i+{dy}, j+{dx}\n     if 0 <= ni < H and 0 <= nj < W:\n         res[ni][nj] = g[i][j]\n return res\n'''\n        except:\n            return None\n\n    def handle_object_count_row(self, task_data, analysis):\n        a,b=(task_data['train'][0]['input'],task_data['train'][0]['output'])\n        if len(b)!=1: return None\n        flat=[x for r in a for x in r if x!=0]\n        if not flat: return None\n        maj=max(set(flat), key=flat.count)\n        cnt=flat.count(maj)\n        if b==[[maj]*cnt]:\n            return f\"\"\"def p(g):\n flat=[x for r in g for x in r if x!=0]\n maj=max(set(flat), key=flat.count)\n return [[maj]*flat.count(maj)]\n\"\"\"\n        return None\n\n    def handle_color_shift_plus_one(self, task_data, analysis):\n        a,b=(task_data['train'][0]['input'],task_data['train'][0]['output'])\n        if [[(x+1)%10 for x in r] for r in a]==b:\n            return \"\"\"def p(g):\n return [[(x+1)%10 for x in r] for r in g]\n\"\"\"\n        return None\n\n    def handle_keep_colors(self, task_data, analysis):\n        keep=set(x for ex in task_data['train']\n                   for r in ex['output'] for x in r)\n        if len(keep)>=10: return None\n        a,b=(task_data['train'][0]['input'],task_data['train'][0]['output'])\n        if [[x if x in keep else 0 for x in r] for r in a]==b:\n            keep_str=\",\".join(map(str,keep))\n            return f\"\"\"def p(g):\n keep={{ {keep_str} }}\n return [[x if x in keep else 0 for x in r] for r in g]\n\"\"\"\n        return None\n\n    def handle_remove_small_objects(self, task_data, analysis):\n        a,b=map(np.array,(task_data['train'][0]['input'],\n                          task_data['train'][0]['output']))\n        if a.shape!=b.shape: return None\n        diff=a!=b\n        if not diff.any(): return None\n        ys,xs=np.where(diff)\n        if len(ys)<=2 and np.all(b[ys,xs]==0):\n            coords=[(int(y),int(x)) for y,x in zip(ys,xs)]\n            return f\"\"\"def p(g):\n g=[r[:] for r in g]\n for y,x in {coords}: g[y][x]=0\n return g\n\"\"\"\n        return None\n\n    def handle_duplicate_quadrant(self, task_data, analysis):\n        a,b=map(np.array,(task_data['train'][0]['input'],\n                          task_data['train'][0]['output']))\n        h,w=a.shape\n        if h%2 or w%2 or b.shape!=(h,w): return None\n        q=a[:h//2,:w//2]\n        cand=np.block([[q,q],[q,q]])\n        if np.array_equal(cand,b):\n            return \"\"\"def p(g):\n h,w=len(g),len(g[0]);hh,ww=h//2,w//2\n q=[row[:ww] for row in g[:hh]]\n return [q_row+q_row for q_row in q]+[q_row+q_row for q_row in q]\n\"\"\"\n        return None\n\n    def handle_upscale_nearest(self, task_data, analysis):\n        a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n        hi, wi = a.shape; ho, wo = b.shape\n        if ho%hi or wo%wi: return None\n        ky, kx = ho//hi, wo//wi\n        ok = True\n        for i in range(hi):\n            for j in range(wi):\n                block = b[i*ky:(i+1)*ky, j*kx:(j+1)*kx]\n                if not np.all(block == a[i,j]): ok=False; break\n            if not ok: break\n        if not ok: return None\n        return f\"\"\"def p(g):\n ky, kx = {ky}, {kx}\n H, W = len(g), len(g[0])\n return [[ g[i//ky][j//kx] for j in range(W*kx) ] for i in range(H*ky)]\n\"\"\"\n\n    def handle_downscale_sample(self, task_data, analysis):\n        a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n        hi, wi = a.shape; ho, wo = b.shape\n        if hi%ho or wi%wo: return None\n        ky, kx = hi//ho, wi//wo\n        if not np.all(b == a[::ky, ::kx]): return None\n        return f\"\"\"def p(g):\n ky, kx = {ky}, {kx}\n return [[ g[i*ky][j*kx] for j in range(len(g[0])//kx) ] for i in range(len(g)//ky)]\n\"\"\"\n\n    def handle_fill_gaps_rowwise(self, task_data, analysis):\n        a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n        if a.shape != b.shape: return None\n        def fill_row(r):\n            r = r[:]\n            for c in set(x for x in r if x!=0):\n                idx = [j for j,x in enumerate(r) if x==c]\n                if idx:\n                    l, rgt = min(idx), max(idx)\n                    for j in range(l, rgt+1):\n                        if r[j]==0: r[j]=c\n            return r\n        cand = np.array([fill_row(list(row)) for row in a.tolist()])\n        if not np.array_equal(cand, b): return None\n        return \"\"\"def p(g):\n res=[]\n for r in g:\n  r=r[:]\n  s={x for x in r if x!=0}\n  for c in s:\n   idx=[j for j,x in enumerate(r) if x==c]\n   l,rgt=min(idx),max(idx)\n   for j in range(l,rgt+1):\n    if r[j]==0: r[j]=c\n  res.append(r)\n return res\n\"\"\"\n\n    def handle_background_to_majority(self, task_data, analysis):\n        a, b = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n        def apply(g):\n            flat=[x for r in g for x in r if x!=0]\n            c=max(range(10), key=lambda v: flat.count(v)) if flat else 0\n            return [[x if x!=0 else c for x in r] for r in g]\n        if apply(a)==b:\n            return \"\"\"def p(g):\n flat=[x for r in g for x in r if x!=0]\n c=max(range(10), key=lambda v: flat.count(v)) if flat else 0\n return [[x if x!=0 else c for x in r] for r in g]\n\"\"\"\n        return None\n\n    def handle_keep_dominant_color(self, task_data, analysis):\n        a, b = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n        def apply(g):\n            flat=[x for r in g for x in r if x!=0]\n            if not flat: return [[0 for _ in r] for r in g]\n            c=max(range(10), key=lambda v: flat.count(v))\n            return [[x if x==c else 0 for x in r] for r in g]\n        if apply(a)==b:\n            return \"\"\"def p(g):\n flat=[x for r in g for x in r if x!=0]\n if not flat: return [[0 for _ in r] for r in g]\n c=max(range(10), key=lambda v: flat.count(v))\n return [[x if x==c else 0 for x in r] for r in g]\n\"\"\"\n        return None\n\n    def handle_extract_first_nonempty_rowcol(self, task_data, analysis):\n        a, b = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n        for i, r in enumerate(a):\n            if any(x!=0 for x in r):\n                if b == [r]:\n                    return \"\"\"def p(g):\n for r in g:\n  if any(x!=0 for x in r): return [r]\n return [g[0]]\n\"\"\"\n                break\n        H, W = len(a), len(a[0])\n        col = None\n        for j in range(W):\n            c = [a[i][j] for i in range(H)]\n            if any(x!=0 for x in c):\n                col = [[x] for x in c]; break\n        if col and b == col:\n            return \"\"\"def p(g):\n H,W=len(g),len(g[0])\n for j in range(W):\n  c=[g[i][j] for i in range(H)]\n  if any(x!=0 for x in c): return [[x] for x in c]\n return [[g[i][0]] for i in range(H)]\n\"\"\"\n        return None\n\n    def handle_sort_rows_by_density(self, task_data, analysis):\n        a, b = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n        if len(a)!=len(b) or len(a[0])!=len(b[0]): return None\n        asc  = sorted(a, key=lambda r: sum(x!=0 for x in r))\n        desc = asc[::-1]\n        if b==asc:\n            return \"\"\"def p(g):\n return sorted(g, key=lambda r: sum(x!=0 for x in r))\n\"\"\"\n        if b==desc:\n            return \"\"\"def p(g):\n return sorted(g, key=lambda r: sum(x!=0 for x in r), reverse=True)\n\"\"\"\n        return None\n\n    def handle_sort_cols_by_density(self, task_data, analysis):\n        a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n        if a.shape != b.shape: return None\n        H,W=a.shape\n        def sort_cols(arr, rev=False):\n            cols=[arr[:,j].tolist() for j in range(W)]\n            cols=sorted(cols, key=lambda c: sum(x!=0 for x in c), reverse=rev)\n            return [[cols[j][i] for j in range(W)] for i in range(H)]\n        if np.array_equal(b, np.array(sort_cols(a, False))):\n            return \"\"\"def p(g):\n H,W=len(g),len(g[0])\n cols=[[g[i][j] for i in range(H)] for j in range(W)]\n cols=sorted(cols, key=lambda c: sum(x!=0 for x in c))\n return [[cols[j][i] for j in range(W)] for i in range(H)]\n\"\"\"\n        if np.array_equal(b, np.array(sort_cols(a, True))):\n            return \"\"\"def p(g):\n H,W=len(g),len(g[0])\n cols=[[g[i][j] for i in range(H)] for j in range(W)]\n cols=sorted(cols, key=lambda c: sum(x!=0 for x in c), reverse=True)\n return [[cols[j][i] for j in range(W)] for i in range(H)]\n\"\"\"\n        return None\n\n    def handle_complete_by_mirror_half(self, task_data, analysis):\n        a, b = map(np.array, (task_data['train'][0]['input'], task_data['train'][0]['output']))\n        if a.shape != b.shape: return None\n        H,W=a.shape\n        mid=W//2\n        left=a[:, :mid]\n        cand_lr=np.hstack([left, np.fliplr(left)])\n        if np.array_equal(b, cand_lr):\n            return \"\"\"def p(g):\n H,W=len(g),len(g[0]);m=W//2\n left=[r[:m] for r in g]\n return [ left[i]+left[i][::-1] for i in range(H) ]\n\"\"\"\n        mid=H//2\n        top=a[:mid, :]\n        cand_ud=np.vstack([top, np.flipud(top)])\n        if np.array_equal(b, cand_ud):\n            return \"\"\"def p(g):\n H,W=len(g),len(g[0]);m=H//2\n top=g[:m]\n return top + top[::-1]\n\"\"\"\n        return None\n\n    def handle_palette_column(self, task_data, analysis):\n        inp, out = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n        colors = sorted({x for r in inp for x in r})\n        if out == [[c] for c in colors]:\n            return \"\"\"def p(g):\n c=sorted({x for r in g for x in r})\n return [[x] for x in c]\n\"\"\"\n        return None\n        \n    def handle_repeat_pattern(self, task_data, analysis):\n        inp = task_data['train'][0]['input']\n        out = task_data['train'][0]['output']\n        \n        if not inp or not out or not inp[0] or not out[0]:\n            return None\n            \n        if len(out) % len(inp) == 0 and len(out[0]) % len(inp[0]) == 0:\n            ry = len(out) // len(inp)\n            rx = len(out[0]) // len(inp[0])\n            tiled = [[inp[i % len(inp)][j % len(inp[0])]\n                      for j in range(len(inp[0]) * rx)]\n                     for i in range(len(inp) * ry)]\n            if tiled == out:\n                return f\"\"\"def p(g):\n ry, rx = {ry}, {rx}\n h, w = len(g), len(g[0])\n return [[g[i % h][j % w] for j in range(w * rx)]\n         for i in range(h * ry)]\n\"\"\"\n        return None\n\n    def handle_vertical_stripes(self, task_data, analysis):\n        inp,out=(np.array(task_data['train'][0][k]) for k in('input','output'))\n        if out.shape!=inp.shape: return None\n        for j in range(out.shape[1]):\n            if len(set(out[:,j]))==1 and not np.array_equal(inp[:,j],out[:,j]):\n                return f\"\"\"def p(g):\n H,W=len(g),len(g[0])\n return[[g[i][0] for _ in range(W)] for i in range(H)]\n\"\"\"\n        return None\n\n    def handle_horizontal_stripes(self, task_data, analysis):\n        inp,out=(np.array(task_data['train'][0][k]) for k in('input','output'))\n        if out.shape!=inp.shape: return None\n        for i in range(out.shape[0]):\n            if len(set(out[i]))==1 and not np.array_equal(inp[i],out[i]):\n                return \"\"\"def p(g):\n return[[x for _ in g[0]] for x in [r[0] for r in g]]\n\"\"\"\n        return None\n\n    def handle_majority_color_fill(self, task_data, analysis):\n        inp, out=(task_data['train'][0]['input'],task_data['train'][0]['output'])\n        flat=[x for r in inp for x in r]\n        maj=max(set(flat), key=flat.count)\n        if all(all(x==maj for x in r) for r in out):\n            return f\"\"\"def p(g):\n from collections import Counter\n flat=[x for r in g for x in r]\n maj=Counter(flat).most_common(1)[0][0]\n return[[maj]*len(g[0]) for _ in g]\n\"\"\"\n        return None\n\n    def handle_cross_lines(self, task_data, analysis):\n        inp,out=(np.array(task_data['train'][0][k]) for k in('input','output'))\n        if out.shape!=inp.shape: return None\n        H,W=out.shape; cy,cx=H//2,W//2\n        if np.all(out[cy,:]==out[cy,0]) and np.all(out[:,cx]==out[0,cx]):\n            c=int(out[cy,cx])\n            return f\"\"\"def p(g):\n H,W=len(g),len(g[0]);cy,cx=H//2,W//2\n return[[{c} if i==cy or j==cx else g[i][j] for j in range(W)] for i in range(H)]\n\"\"\"\n        return None\n\n    def handle_color_swap(self, task_data, analysis):\n        inp,out=(task_data['train'][0]['input'],task_data['train'][0]['output'])\n        in_set={x for r in inp for x in r}; out_set={x for r in out for x in r}\n        if len(in_set)==len(out_set)==2 and in_set==out_set:\n            a,b=sorted(in_set)\n            return f\"\"\"def p(g):\n return[[{a} if x=={b} else ({b} if x=={a} else x) for x in r] for r in g]\n\"\"\"\n        return None\n\n    def handle_crop_center(self, task_data, analysis):\n        inp,out=(np.array(task_data['train'][0][k]) for k in ('input','output'))\n        h,w=inp.shape; ho,wo=out.shape\n        cy,cx=(h-ho)//2,(w-wo)//2\n        if np.array_equal(out, inp[cy:cy+ho, cx:cx+wo]):\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0]);ho,wo={ho},{wo}\n cy,cx=(h-ho)//2,(w-wo)//2\n return[g[i][cx:cx+wo] for i in range(cy,cy+ho)]\n\"\"\"\n        return None\n\n    def handle_outline_only(self, task_data, analysis):\n        inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        if inp.shape != out.shape: return None\n        h, w = inp.shape\n        edge = np.zeros_like(inp)\n        for i in range(h):\n            for j in range(w):\n                if inp[i,j]==0: continue\n                nbor = [(i+1,j),(i-1,j),(i,j+1),(i,j-1)]\n                if any(not(0<=y<h and 0<=x<w) or inp[y,x]==0 for y,x in nbor):\n                    edge[i,j] = inp[i,j]\n        if np.array_equal(out, edge):\n            return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n return[[ g[i][j] if g[i][j] and any( (y<0 or y>=h or x<0 or x>=w or g[y][x]==0)\n        for y,x in ((i+1,j),(i-1,j),(i,j+1),(i,j-1)) )\n        else 0 for j in range(w)] for i in range(h)]\n\"\"\"\n        return None\n\n    def handle_center_object(self, task_data, analysis):\n        inp = task_data['train'][0]['input']\n        out = task_data['train'][0]['output']\n        if len(inp) != len(out) or len(inp[0]) != len(out[0]):\n            return None\n        ys = [i for i, row in enumerate(inp) for v in row if v]\n        xs = [j for row in inp for j, v in enumerate(row) if v]\n        if not ys:\n            return None\n        y0, y1 = min(ys), max(ys) + 1\n        x0, x1 = min(xs), max(xs) + 1\n        crop = [r[x0:x1] for r in inp[y0:y1]]\n        H, W = len(inp), len(inp[0])\n        h, w = len(crop), len(crop[0])\n        cy, cx = (H - h) // 2, (W - w) // 2\n        canvas = [[0] * W for _ in range(H)]\n        for i in range(h):\n            canvas[cy + i][cx:cx + w] = crop[i][:]\n        if canvas == out:\n            return f'''def p(g):\n H, W = len(g), len(g[0])\n ys = [i for i,row in enumerate(g) for v in row if v]\n xs = [j for row in g for j,v in enumerate(row) if v]\n y0, y1 = min(ys), max(ys)+1\n x0, x1 = min(xs), max(xs)+1\n crop = [r[x0:x1] for r in g[y0:y1]]\n h, w = len(crop), len(crop[0])\n cy, cx = (H-h)//2, (W-w)//2\n res = [[0]*W for _ in range(H)]\n for i in range(h):\n     res[cy+i][cx:cx+w] = crop[i][:]\n return res\n'''\n\n    def handle_diagonal_mirror(self, task_data, analysis):\n        inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        if inp.shape[0]!=inp.shape[1]: return None\n        if np.array_equal(out, inp.T):\n            return \"\"\"def p(g):\n return[list(r) for r in zip(*g)]\n\"\"\"\n        return None\n\n    def handle_color_palette_row(self, task_data, analysis):\n        inp, out = (task_data['train'][0]['input'], task_data['train'][0]['output'])\n        colors = sorted({x for row in inp for x in row})\n        if len(out)==1 and out[0]==colors:\n            return \"\"\"def p(g):\n c=sorted({x for r in g for x in r})\n return [c]\n\"\"\"\n        return None\n\n    def handle_bounding_fill_by_color(self, task_data, analysis):\n        inp = task_data['train'][0]['input']\n        out = task_data['train'][0]['output']\n        if len(inp) != len(out) or len(inp[0]) != len(out[0]):\n            return None\n        H, W = len(inp), len(inp[0])\n        res = [[0] * W for _ in range(H)]\n        colors = {v for row in inp for v in row if v}\n        for c in colors:\n            ys = [i for i, row in enumerate(inp) for v in row if v == c]\n            xs = [j for i, row in enumerate(inp) for j, v in enumerate(row) if v == c]\n            y0, y1 = min(ys), max(ys) + 1\n            x0, x1 = min(xs), max(xs) + 1\n            for i in range(y0, y1):\n                for j in range(x0, x1):\n                    res[i][j] = c\n        if res == out:\n            return '''def p(g):\n H, W = len(g), len(g[0])\n res = [[0]*W for _ in range(H)]\n colors = {v for row in g for v in row if v}\n for c in colors:\n     ys = [i for i,row in enumerate(g) for v in row if v==c]\n     xs = [j for i,row in enumerate(g) for j,v in enumerate(row) if v==c]\n     y0,y1 = min(ys), max(ys)+1\n     x0,x1 = min(xs), max(xs)+1\n     for i in range(y0,y1):\n         for j in range(x0,x1):\n             res[i][j] = c\n return res\n'''\n\n    def handle_row_col_propagation(self, task_data, analysis):\n        inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        if inp.shape!=out.shape: return None\n        if all((np.unique(o).size==1) or np.array_equal(o, i)\n               for i,o in zip(inp, out)):\n            return \"\"\"def p(g):\n return[[g[r][0] if len(set(g[r]))>1 else g[r][c]\n         for c in range(len(g[0]))] for r in range(len(g))]\n\"\"\"\n        if all((np.unique(out[:,c]).size==1) or np.array_equal(out[:,c], inp[:,c])\n               for c in range(inp.shape[1])):\n            return \"\"\"def p(g):\n H,W=len(g),len(g[0])\n cols=[[g[r][c] for r in range(H)] for c in range(W)]\n for c in range(W):\n     if len(set(cols[c]))>1:\n         cols[c]=[cols[c][0]]*H\n return[[cols[c][r] for c in range(W)] for r in range(H)]\n\"\"\"\n        return None\n\n    def handle_single_color_output(self, task_data, analysis):\n        cands = {int(x) for ex in task_data['train']\n                       for row in ex['output'] for x in row}\n        if len(cands) == 1:\n            c = cands.pop()\n            return f\"\"\"def p(g):\n return[[{c}]*len(g[0]) for _ in g]\n\"\"\"\n        return None\n\n    def handle_bounding_crop(self, task_data, analysis):\n        inp, out = map(np.array, (task_data['train'][0]['input'],\n                                  task_data['train'][0]['output']))\n        nz = np.argwhere(inp)\n        if not len(nz):\n            return None\n        (y0,x0),(y1,x1) = nz.min(0), nz.max(0)+1\n        if np.array_equal(out, inp[y0:y1, x0:x1]):\n            return f\"\"\"def p(g):\n c=[(i,j)for i,r in enumerate(g)for j,x in enumerate(r)if x]\n y0=min(i for i,_ in c); y1=max(i for i,_ in c)+1\n x0=min(j for _,j in c); x1=max(j for _,j in c)+1\n return[g[i][x0:x1] for i in range(y0,y1)]\n\"\"\"\n        return None\n\n    def handle_overlay_fill(self, task_data, analysis):\n        inp, out = map(np.array, (task_data['train'][0]['input'],\n                                  task_data['train'][0]['output']))\n        if inp.shape != out.shape:\n            return None\n        if np.all(np.where(out==0, inp, out) == out):\n            return \"\"\"def p(g):\n return[[g[i][j] if r[j]==0 else r[j]\n         for j in range(len(r))]\n        for i,r in enumerate(g)]\n\"\"\"\n        return None\n\n    def handle_remove_color(self, task_data, analysis):\n        inp, out = map(np.array, (task_data['train'][0]['input'],\n                                  task_data['train'][0]['output']))\n        if inp.shape != out.shape:\n            return None\n        diff = inp != out\n        removed = {int(inp[i,j]) for (i,j) in zip(*np.where(diff))}\n        if len(removed)==1 and np.all(out[diff]==0):\n            c = removed.pop()\n            return f\"\"\"def p(g):\n return[[0 if x=={c} else x for x in r] for r in g]\n\"\"\"\n        return None\n        \n    def handle_color_mapping(self, task_data, analysis):\n        color_map = {}\n        for pos, changes in analysis['color_changes'].items():\n            if len(changes) == 1:\n                src, dest = next(iter(changes))\n                if src not in color_map:\n                    color_map[src] = dest\n                elif color_map[src] != dest:\n                    return None\n        \n        if not color_map:\n            return None\n            \n        cases = \"\\n\".join([f\"    if x=={int(src)}: return {int(dest)}\" for src, dest in color_map.items()])\n        return f\"\"\"def p(g):\n return[[(lambda x:\n{cases}\n    else x)(x)for x in r]for r in g]\n\"\"\"\n    \n    def handle_grid_operations(self, task_data, analysis):\n        if not analysis['symmetry']:\n            return None\n        sym_type = analysis['symmetry']\n        if sym_type == 'rotate_90':\n            return \"\"\"def p(g):\n return[list(r)for r in zip(*g[::-1])]\n\"\"\"\n        if sym_type == 'rotate_180':\n            return \"\"\"def p(g):\n return[r[::-1]for r in g[::-1]]\n\"\"\"\n        if sym_type == 'rotate_270':\n            return \"\"\"def p(g):\n return[list(r)for r in zip(*g)][::-1]\n\"\"\"\n        if sym_type == 'flip_vertical':\n            return \"\"\"def p(g):\n return g[::-1]\n\"\"\"\n        if sym_type == 'flip_horizontal':\n            return \"\"\"def p(g):\n return[r[::-1]for r in g]\n\"\"\"\n        return None\n\n    def handle_resize(self, task_data, analysis):\n        first_pair = task_data['train'][0]\n        in_grid = np.array(first_pair['input'])\n        out_grid = np.array(first_pair['output'])\n        h_out, w_out = out_grid.shape\n        h_in, w_in = in_grid.shape\n        \n        if (h_out < h_in) or (w_out < w_in):\n            return f\"\"\"def p(g):\n return [row[:{w_out}] for row in g[:{h_out}]]\n\"\"\"\n        if (h_out > h_in) or (w_out > w_in):\n            return f\"\"\"def p(g):\n return [row+[0]*({w_out}-len(row)) for row in g]+[[0]*{w_out} for _ in range({h_out}-len(g))]\n\"\"\"\n        return None\n\n    def handle_object_operations(self, task_data, analysis):\n        obj_changes = [obj for example in analysis['object_properties'] for obj in example]\n        if not obj_changes:\n            return None\n        if len(obj_changes) == 1 and isinstance(obj_changes[0]['position_change'], np.ndarray):\n            dy, dx = map(int, obj_changes[0]['position_change'])\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n return[[g[i-{dy}][j-{dx}] if 0<=i-{dy}<h and 0<=j-{dx}<w else 0 for j in range(w)]for i in range(h)]\n\"\"\"\n        return None\n    \n    def handle_pattern_replication(self, task_data, analysis):\n        first_pair = task_data['train'][0]\n        in_grid = np.array(first_pair['input'])\n        out_grid = np.array(first_pair['output'])\n        if (out_grid.shape[0] % in_grid.shape[0] == 0 and \n            out_grid.shape[1] % in_grid.shape[1] == 0):\n            tiles_y = out_grid.shape[0] // in_grid.shape[0]\n            tiles_x = out_grid.shape[1] // in_grid.shape[1]\n            return f\"\"\"def p(g):\n return[[g[i%{in_grid.shape[0]}][j%{in_grid.shape[1]}]for j in range(len(g[0])*{tiles_x})]for i in range(len(g)*{tiles_y})]\n\"\"\"\n        return None\n    \n    def handle_mirror_symmetry(self, task_data, analysis):\n        first_pair = task_data['train'][0]\n        in_grid = np.array(first_pair['input'])\n        out_grid = np.array(first_pair['output'])\n        if np.array_equal(out_grid, in_grid[:, ::-1]) and in_grid.shape == out_grid.shape:\n            return \"\"\"def p(g):\n return[r[::-1]for r in g]\n\"\"\"\n        return None\n    \n    def handle_arithmetic_operations(self, task_data, analysis):\n        if not analysis['arithmetic']:\n            return None\n        op, val = analysis['arithmetic']\n        if op == 'add':\n            return f\"\"\"def p(g):\n return[[x+{val}for x in r]for r in g]\n\"\"\"\n        if op == 'multiply':\n            return f\"\"\"def p(g):\n return[[x*{val}for x in r]for r in g]\n\"\"\"\n        return None\n    \n    def handle_conditional_operations(self, task_data, analysis):\n        first_pair = task_data['train'][0]\n        in_grid = np.array(first_pair['input'])\n        out_grid = np.array(first_pair['output'])\n        if in_grid.shape != out_grid.shape:\n            return None\n        diff = out_grid - in_grid\n        changed = np.where(diff != 0)\n        for i,j in zip(*changed):\n            if i > 0 and in_grid[i-1,j] == out_grid[i,j]:\n                return \"\"\"def p(g):\n return[[g[i-1][j]if i>0 and g[i][j]!=0 else g[i][j]for j in range(len(g[0]))]for i in range(len(g))]\n\"\"\"\n            if j > 0 and in_grid[i,j-1] == out_grid[i,j]:\n                return \"\"\"def p(g):\n return[[g[i][j-1]if j>0 and g[i][j]!=0 else g[i][j]for j in range(len(g[0]))]for i in range(len(g))]\n\"\"\"\n        return None\n\n    def visualize_grid(self, grid: np.ndarray, title: str = \"Grid\", ax=None) -> None:\n        if ax is None:\n            fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n        \n        color_matrix = np.zeros((*grid.shape, 3))\n        for i in range(grid.shape[0]):\n            for j in range(grid.shape[1]):\n                color_hex = ARC_COLORS[int(grid[i, j]) % 10]\n                color_matrix[i, j] = [int(color_hex[i:i+2], 16)/255 for i in (1, 3, 5)]\n        \n        ax.imshow(color_matrix, interpolation='nearest')\n        ax.set_title(title)\n        ax.grid(True, which='both', color='gray', linewidth=0.5)\n        ax.set_xticks(np.arange(-0.5, grid.shape[1], 1), minor=True)\n        ax.set_yticks(np.arange(-0.5, grid.shape[0], 1), minor=True)\n        ax.set_xticklabels([])\n        ax.set_yticklabels([])\n        \n    def visualize_transformation(self, input_grid: np.ndarray, output_grid: np.ndarray, \n                               predicted_grid: Optional[np.ndarray] = None,\n                               pattern_name: str = \"\") -> None:\n        if not self.enable_visuals:\n            return\n            \n        n_plots = 3 if predicted_grid is not None else 2\n        fig, axes = plt.subplots(1, n_plots, figsize=(5*n_plots, 5))\n        \n        self.visualize_grid(input_grid, \"Input\", axes[0])\n        self.visualize_grid(output_grid, \"Expected Output\", axes[1])\n        \n        if predicted_grid is not None:\n            self.visualize_grid(predicted_grid, \"Predicted Output\", axes[2])\n            # Handle shape mismatch\n            if output_grid.shape == predicted_grid.shape:\n                match_pct = np.mean(output_grid == predicted_grid) * 100\n                axes[2].text(0.5, -0.1, f\"Match: {match_pct:.1f}%\", \n                            transform=axes[2].transAxes, ha='center')\n            else:\n                axes[2].text(0.5, -0.1, f\"Shape mismatch: {output_grid.shape} vs {predicted_grid.shape}\", \n                            transform=axes[2].transAxes, ha='center')\n        \n        if pattern_name:\n            fig.suptitle(f\"Pattern: {pattern_name}\", fontsize=14)\n        \n        plt.tight_layout()\n        plt.show()\n\n    def analyze_pattern_distribution(self, task_data: Dict) -> Dict[str, Any]:\n        pattern_counts = defaultdict(int)\n        pattern_categories = defaultdict(int)\n        \n        for handler, name, category in self.pattern_handlers:\n            try:\n                analysis = self.analyze_task(task_data)\n                solution = handler(task_data, analysis)\n                if solution and self.verify_solution(solution, task_data):\n                    pattern_counts[name] += 1\n                    pattern_categories[category] += 1\n            except:\n                continue\n        \n        return {\n            'pattern_counts': dict(pattern_counts),\n            'category_counts': dict(pattern_categories),\n            'total_patterns': sum(pattern_counts.values())\n        }\n\n    def visualize_pattern_analysis(self, analysis_results: List[Dict]) -> None:\n        if not self.enable_visuals:\n            return\n            \n        fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n        \n        ax1 = axes[0, 0]\n        patterns = list(self.pattern_success_rates.keys())[:20]\n        success_rates = [self.pattern_success_rates[p]['successes'] / \n                        max(self.pattern_success_rates[p]['attempts'], 1) * 100 \n                        for p in patterns]\n        \n        ax1.barh(patterns, success_rates)\n        ax1.set_xlabel('Success Rate (%)')\n        ax1.set_title('Pattern Success Rates')\n        ax1.grid(True, alpha=0.3)\n        \n        ax2 = axes[0, 1]\n        categories = defaultdict(int)\n        for results in analysis_results:\n            for cat, count in results.get('category_counts', {}).items():\n                categories[cat] += count\n                \n        if categories:\n            ax2.pie(categories.values(), labels=categories.keys(), autopct='%1.1f%%')\n            ax2.set_title('Pattern Category Distribution')\n        \n        ax3 = axes[1, 0]\n        if self.solution_complexity_scores:\n            complexities = list(self.solution_complexity_scores.values())\n            ax3.hist(complexities, bins=30, edgecolor='black')\n            ax3.set_xlabel('Complexity Score')\n            ax3.set_ylabel('Frequency')\n            ax3.set_title('Solution Complexity Distribution')\n            ax3.grid(True, alpha=0.3)\n        \n        ax4 = axes[1, 1]\n        if self.fitness_history:\n            generations = range(len(self.fitness_history))\n            best_fitness = [gen['best'] for gen in self.fitness_history]\n            avg_fitness = [gen['average'] for gen in self.fitness_history]\n            \n            ax4.plot(generations, best_fitness, 'b-', label='Best Fitness')\n            ax4.plot(generations, avg_fitness, 'r--', label='Average Fitness')\n            ax4.set_xlabel('Generation')\n            ax4.set_ylabel('Fitness Score')\n            ax4.set_title('Genetic Algorithm Progress')\n            ax4.legend()\n            ax4.grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.show()\n        \n    def calculate_solution_complexity(self, solution_code: str) -> float:\n        lines = solution_code.strip().split('\\n')\n        char_count = len(solution_code)\n        line_count = len(lines)\n        \n        loops = sum(1 for line in lines if 'for' in line or 'while' in line)\n        conditionals = sum(1 for line in lines if 'if' in line)\n        comprehensions = sum(1 for line in lines if '[' in line and 'for' in line)\n        \n        complexity = (char_count * 0.01 + \n                     line_count * 2 + \n                     loops * 5 + \n                     conditionals * 3 + \n                     comprehensions * 4)\n        \n        return complexity\n        \n    def genetic_optimize_solution(self, task_data: Dict, initial_solution: str) -> str:\n        self.population = [initial_solution]\n        \n        for _ in range(19):\n            variant = self.mutate_solution(initial_solution)\n            self.population.append(variant)\n        \n        for generation in range(self.genetic_generations):\n            fitness_scores = []\n            for solution in self.population:\n                fitness = self.evaluate_solution_fitness(solution, task_data)\n                fitness_scores.append(fitness)\n            \n            self.fitness_history.append({\n                'best': max(fitness_scores),\n                'average': np.mean(fitness_scores),\n                'worst': min(fitness_scores)\n            })\n            \n            new_population = []\n            \n            elite_count = len(self.population) // 5\n            elite_indices = np.argsort(fitness_scores)[-elite_count:]\n            for idx in elite_indices:\n                new_population.append(self.population[idx])\n            \n            while len(new_population) < len(self.population):\n                parent1 = self.tournament_select(self.population, fitness_scores)\n                parent2 = self.tournament_select(self.population, fitness_scores)\n                \n                if random.random() < 0.7:\n                    child = self.crossover_solutions(parent1, parent2)\n                else:\n                    child = parent1\n                    \n                if random.random() < 0.3:\n                    child = self.mutate_solution(child)\n                    \n                new_population.append(child)\n            \n            self.population = new_population\n        \n        final_fitness = [self.evaluate_solution_fitness(s, task_data) for s in self.population]\n        best_idx = np.argmax(final_fitness)\n        return self.population[best_idx]\n        \n    def evaluate_solution_fitness(self, solution: str, task_data: Dict) -> float:\n        fitness = 0.0\n        \n        if self.verify_solution(solution, task_data):\n            fitness += 100.0\n        \n        char_count = len(solution.replace(' ', '').replace('\\n', ''))\n        fitness += max(0, 50 - char_count * 0.1)\n        \n        complexity = self.calculate_solution_complexity(solution)\n        fitness -= complexity * 0.01\n        \n        generalization_score = self.test_generalization(solution, task_data)\n        fitness += generalization_score * 20\n        \n        return max(0, fitness)\n        \n    def test_generalization(self, solution: str, task_data: Dict) -> float:\n        try:\n            namespace = {}\n            exec(solution, namespace)\n            p = namespace['p']\n            \n            correct = 0\n            total = 0\n            \n            for example in task_data['train']:\n                input_grid = example['input']\n                expected = example['output']\n                actual = p(input_grid)\n                if actual == expected:\n                    correct += 1\n                total += 1\n                \n                noisy_input = self.add_minor_noise(input_grid)\n                try:\n                    noisy_output = p(noisy_input)\n                    if isinstance(noisy_output, list) and len(noisy_output) > 0:\n                        correct += 0.5\n                    total += 1\n                except:\n                    pass\n                    \n            return correct / max(total, 1)\n        except:\n            return 0.0\n            \n    def add_minor_noise(self, grid: List[List[int]]) -> List[List[int]]:\n        noisy = [row[:] for row in grid]\n        h, w = len(grid), len(grid[0]) if grid else 0\n        \n        changes = random.randint(0, min(2, h*w//10))\n        for _ in range(changes):\n            i = random.randint(0, h-1)\n            j = random.randint(0, w-1)\n            colors = {grid[y][x] for y in range(h) for x in range(w)}\n            if len(colors) > 1:\n                noisy[i][j] = random.choice(list(colors - {grid[i][j]}))\n                \n        return noisy\n        \n    def tournament_select(self, population: List[str], fitness_scores: List[float]) -> str:\n        tournament_size = 3\n        indices = random.sample(range(len(population)), tournament_size)\n        tournament_fitness = [fitness_scores[i] for i in indices]\n        winner_idx = indices[np.argmax(tournament_fitness)]\n        return population[winner_idx]\n        \n    def crossover_solutions(self, parent1: str, parent2: str) -> str:\n        lines1 = parent1.strip().split('\\n')\n        lines2 = parent2.strip().split('\\n')\n        \n        if len(lines1) < 3 or len(lines2) < 3:\n            return parent1\n            \n        child_lines = [lines1[0]]\n        \n        body1 = lines1[1:]\n        body2 = lines2[1:]\n        \n        for i in range(max(len(body1), len(body2))):\n            if random.random() < 0.5:\n                if i < len(body1):\n                    child_lines.append(body1[i])\n            else:\n                if i < len(body2):\n                    child_lines.append(body2[i])\n                    \n        return '\\n'.join(child_lines)\n        \n    def mutate_solution(self, solution: str) -> str:\n        lines = solution.strip().split('\\n')\n        mutation_type = random.choice(['simplify', 'compress', 'reorder'])\n        \n        if mutation_type == 'simplify':\n            for i, line in enumerate(lines):\n                if 'for i in range(len(' in line:\n                    lines[i] = line.replace('for i in range(len(', 'for i,_ in enumerate(')\n                elif 'lambda' not in line and ':' in line and '=' in line:\n                    parts = line.split('=', 1)\n                    if len(parts) == 2 and ';' not in line:\n                        lines[i] = parts[0] + '=' + parts[1].strip()\n                        \n        elif mutation_type == 'compress':\n            for i, line in enumerate(lines):\n                if i > 0:\n                    lines[i] = line.replace(' ', '', 1)\n                    \n        elif mutation_type == 'reorder':\n            if len(lines) > 3:\n                idx1, idx2 = random.sample(range(1, len(lines)-1), 2)\n                lines[idx1], lines[idx2] = lines[idx2], lines[idx1]\n                \n        return '\\n'.join(lines)\n        \n    def explain_pattern(self, pattern_name: str, task_data: Dict, \n                       solution: str) -> Dict[str, Any]:\n        explanation = {\n            'pattern_name': pattern_name,\n            'description': '',\n            'key_features': [],\n            'transformation_steps': [],\n            'code_explanation': [],\n            'visual_example': None\n        }\n        \n        for handler, name, category in self.pattern_handlers:\n            if name == pattern_name:\n                explanation['description'] = f\"{name} ({category} pattern)\"\n                explanation['category'] = category\n                break\n                \n        example = task_data['train'][0]\n        input_grid = np.array(example['input'])\n        output_grid = np.array(example['output'])\n        \n        if input_grid.shape != output_grid.shape:\n            explanation['key_features'].append(\n                f\"Shape change: {input_grid.shape}  {output_grid.shape}\"\n            )\n            \n        input_colors = set(input_grid.flatten())\n        output_colors = set(output_grid.flatten())\n        if input_colors != output_colors:\n            explanation['key_features'].append(\n                f\"Color change: {input_colors}  {output_colors}\"\n            )\n            \n        lines = solution.strip().split('\\n')\n        for line in lines:\n            if 'for' in line:\n                explanation['code_explanation'].append(\"Uses iteration\")\n            if 'if' in line:\n                explanation['code_explanation'].append(\"Contains conditional logic\")\n            if 'zip' in line:\n                explanation['code_explanation'].append(\"Combines multiple sequences\")\n            if '[::-1]' in line:\n                explanation['code_explanation'].append(\"Reverses sequences\")\n                \n        return explanation\n        \n    def generate_detailed_report(self, task_id: str, task_data: Dict, \n                               solution: str, pattern_name: str) -> Dict[str, Any]:\n        report = {\n            'task_id': task_id,\n            'pattern': pattern_name,\n            'solution_length': len(solution),\n            'complexity_score': self.calculate_solution_complexity(solution),\n            'verification_status': 'PASSED' if self.verify_solution(solution, task_data) else 'FAILED',\n            'generalization_score': self.test_generalization(solution, task_data),\n            'explanation': self.explain_pattern(pattern_name, task_data, solution)\n        }\n        \n        if pattern_name in self.pattern_success_rates:\n            stats = self.pattern_success_rates[pattern_name]\n            report['pattern_success_rate'] = stats['successes'] / max(stats['attempts'], 1)\n            \n        return report\n    \n    def analyze_task(self, task_data):\n        \"\"\"Improved task analysis with better error handling\"\"\"\n        all_examples = task_data['train'] + task_data.get('test', []) + task_data.get('arc-gen', [])\n        analysis = {\n            'color_changes': defaultdict(set),\n            'shape_changes': set(),\n            'object_properties': [],\n            'symmetry': None,\n            'arithmetic': None,\n            'pattern_metrics': {},\n            'statistical_features': {}\n        }\n        \n        for example in all_examples:\n            in_grid = np.array(example['input'])\n            out_grid = np.array(example['output'])\n            \n            analysis['shape_changes'].add((in_grid.shape, out_grid.shape))\n            \n            for (i,j), val in np.ndenumerate(in_grid):\n                if i < out_grid.shape[0] and j < out_grid.shape[1]:\n                    if in_grid[i,j] != out_grid[i,j]:\n                        analysis['color_changes'][(i,j)].add((int(in_grid[i,j]), int(out_grid[i,j])))\n            \n            analysis['statistical_features']['input_colors'] = len(np.unique(in_grid))\n            analysis['statistical_features']['output_colors'] = len(np.unique(out_grid))\n            analysis['statistical_features']['input_density'] = np.mean(in_grid > 0)\n            analysis['statistical_features']['output_density'] = np.mean(out_grid > 0)\n            \n            analysis['object_properties'].append(self.analyze_objects(in_grid, out_grid))\n            \n            if analysis['symmetry'] is None:\n                analysis['symmetry'] = self.detect_symmetry(in_grid, out_grid)\n            \n            if analysis['arithmetic'] is None:\n                analysis['arithmetic'] = self.detect_arithmetic(in_grid, out_grid)\n        \n        return analysis\n    \n    def analyze_objects(self, in_grid, out_grid):\n        structure = np.ones((3,3), dtype=int)\n        labeled_in, n_in = label(in_grid > 0, structure)\n        labeled_out, n_out = label(out_grid > 0, structure)\n        \n        objects = []\n        for i in range(1, n_in+1):\n            in_obj = (labeled_in == i)\n            out_obj = None\n            if i <= n_out:\n                out_obj = (labeled_out == i)\n            objects.append({\n                'in_size': int(in_obj.sum()),\n                'out_size': int(out_obj.sum()) if out_obj is not None else 0,\n                'position_change': self.detect_position_change(in_obj, out_obj)\n            })\n        return objects\n    \n    def detect_position_change(self, in_obj, out_obj):\n        if out_obj is None:\n            return \"removed\"\n        in_pos = np.argwhere(in_obj).mean(axis=0)\n        out_pos = np.argwhere(out_obj).mean(axis=0)\n        return out_pos - in_pos\n    \n    def detect_symmetry(self, in_grid, out_grid):\n        if np.array_equal(out_grid, np.rot90(in_grid, 1)):\n            return 'rotate_90'\n        if np.array_equal(out_grid, np.rot90(in_grid, 2)):\n            return 'rotate_180'\n        if np.array_equal(out_grid, np.rot90(in_grid, 3)):\n            return 'rotate_270'\n        if np.array_equal(out_grid, np.flipud(in_grid)):\n            return 'flip_vertical'\n        if np.array_equal(out_grid, np.fliplr(in_grid)):\n            return 'flip_horizontal'\n        return None\n    \n    def detect_arithmetic(self, in_grid, out_grid):\n        \"\"\"Fixed arithmetic detection\"\"\"\n        if in_grid.shape != out_grid.shape:\n            return None\n            \n        try:\n            # Check addition\n            diff = out_grid - in_grid\n            if np.all(diff == diff[0,0]):\n                return ('add', int(diff[0,0]))\n            \n            # Check multiplication\n            non_zero_mask = in_grid > 0\n            if np.any(non_zero_mask):\n                with np.errstate(divide='ignore', invalid='ignore'):\n                    safe_in = np.where(in_grid == 0, 1, in_grid)\n                    ratio = out_grid / safe_in\n                    # Only check ratio where input is non-zero\n                    ratio_values = ratio[non_zero_mask]\n                    if len(ratio_values) > 0 and np.all(ratio_values == ratio_values[0]):\n                        return ('multiply', float(ratio_values[0]))\n        except:\n            pass\n        return None\n    \n    def generate_solution(self, task_data):\n        analysis = self.analyze_task(task_data)\n        \n        # Try each pattern handler\n        for handler, name, category in self.pattern_handlers:\n            self.pattern_success_rates[name]['attempts'] += 1\n            \n            try:\n                solution = handler(task_data, analysis)\n                if solution and self.verify_solution(solution, task_data):\n                    self.pattern_success_rates[name]['successes'] += 1\n                    \n                    complexity = self.calculate_solution_complexity(solution)\n                    self.solution_complexity_scores[name] = complexity\n                    \n                    # Optional: genetic optimization\n                    if self.genetic_generations > 0:\n                        solution = self.genetic_optimize_solution(task_data, solution)\n                    \n                    return solution, name\n            except Exception as e:\n                # Silent fail for pattern handlers\n                continue\n        \n        # If no pattern works, try pattern combinations\n        combined_solution = self.try_pattern_combinations(task_data, analysis)\n        if combined_solution:\n            return combined_solution, \"Combined Pattern\"\n        \n        # Fallback to identity\n        return \"\"\"def p(g):\n return [row[:] for row in g]\n\"\"\", \"Identity (Fallback)\"\n    \n    def try_pattern_combinations(self, task_data, analysis):\n        \"\"\"Try combining multiple patterns\"\"\"\n        # Example: Try rotation followed by crop\n        try:\n            inp = task_data['train'][0]['input']\n            out = task_data['train'][0]['output']\n            \n            # Try all rotations\n            for rot in [1, 2, 3]:\n                rotated = np.rot90(np.array(inp), rot).tolist()\n                # Check if rotated matches output shape\n                if len(rotated) == len(out) and len(rotated[0]) == len(out[0]) and rotated == out:\n                    if rot == 1:\n                        return \"\"\"def p(g):\n return [list(r) for r in zip(*g[::-1])]\n\"\"\"\n                    elif rot == 2:\n                        return \"\"\"def p(g):\n return [r[::-1] for r in g[::-1]]\n\"\"\"\n                    elif rot == 3:\n                        return \"\"\"def p(g):\n return [list(r) for r in zip(*g)][::-1]\n\"\"\"\n            \n            # Try flip then scale\n            h_flipped = [r[::-1] for r in inp]\n            if len(out) == 2 * len(h_flipped) and len(out[0]) == 2 * len(h_flipped[0]):\n                # Check if it's scaled h_flipped\n                valid = True\n                for i in range(len(h_flipped)):\n                    for j in range(len(h_flipped[0])):\n                        if out[i*2][j*2] != h_flipped[i][j] or out[i*2+1][j*2] != h_flipped[i][j]:\n                            valid = False\n                            break\n                    if not valid:\n                        break\n                if valid:\n                    return \"\"\"def p(g):\n f=[r[::-1] for r in g]\n return [[f[i//2][j//2] for j in range(len(f[0])*2)] for i in range(len(f)*2)]\n\"\"\"\n        except:\n            pass\n        \n        return None\n    \n    def verify_solution(self, solution_code, task_data):\n        \"\"\"Improved solution verification\"\"\"\n        try:\n            namespace = {}\n            exec(solution_code, namespace)\n            p = namespace['p']\n            \n            # Test on all available examples\n            examples = task_data['train']\n            if 'test' in task_data:\n                examples.extend(task_data['test'])\n            if 'arc-gen' in task_data:\n                examples.extend(task_data['arc-gen'])\n            \n            # For efficiency, test a subset if too many examples\n            if len(examples) > 5:\n                test_indices = random.sample(range(len(examples)), min(5, len(examples)))\n                test_examples = [examples[i] for i in test_indices]\n            else:\n                test_examples = examples\n            \n            for example in test_examples:\n                input_grid = [row[:] for row in example['input']]  # Deep copy\n                expected = example['output']\n                \n                try:\n                    actual = p(input_grid)\n                    if actual != expected:\n                        return False\n                except:\n                    return False\n                    \n            return True\n        except:\n            return False\n\ndef create_enhanced_arc_solutions():\n    generator = EnhancedARCSolutionGenerator(enable_visuals=True, genetic_generations=5)\n    solutions = {}\n    reports = []\n    analysis_results = []\n    \n    print(\" Starting Enhanced ARC Solution Generation...\\n\")\n    \n    for task_num in range(1, 401):\n        task_id = f\"{task_num:03d}\"\n        try:\n            with open(f\"/kaggle/input/google-code-golf-2025/task{task_id}.json\") as f:\n                task_data = json.load(f)\n            \n            pattern_analysis = generator.analyze_pattern_distribution(task_data)\n            analysis_results.append(pattern_analysis)\n            \n            solution, pattern_name = generator.generate_solution(task_data)\n            solutions[task_id] = solution\n            \n            report = generator.generate_detailed_report(task_id, task_data, solution, pattern_name)\n            reports.append(report)\n            \n            # Visualize first few tasks if enabled\n            if task_num <= 5 and generator.enable_visuals:\n                try:\n                    example = task_data['train'][0]\n                    input_grid = np.array(example['input'])\n                    output_grid = np.array(example['output'])\n                    \n                    namespace = {}\n                    exec(solution, namespace)\n                    p = namespace['p']\n                    predicted_grid = np.array(p(example['input']))\n                    \n                    generator.visualize_transformation(\n                        input_grid, output_grid, predicted_grid, pattern_name\n                    )\n                except:\n                    pass  # Skip visualization on error\n            \n            if report['verification_status'] == 'PASSED':\n                print(f\"Task {task_id}  - Pattern: {pattern_name} - \"\n                      f\"Complexity: {report['complexity_score']:.1f}\")\n            else:\n                print(f\"Task {task_id}  - Used fallback\")\n                \n        except Exception as e:\n            print(f\"Error processing task {task_id}: {str(e)}\")\n            traceback.print_exc()\n            solutions[task_id] = \"\"\"def p(g):\n return [row[:] for row in g]\n\"\"\"\n    \n    print(\"\\n Generating analysis visualizations...\")\n    generator.visualize_pattern_analysis(analysis_results)\n    \n    # Create submission\n    os.makedirs(\"/kaggle/working/submission\", exist_ok=True)\n    for task_id, code in solutions.items():\n        with open(f\"/kaggle/working/submission/task{task_id}.py\", \"w\") as f:\n            f.write(code)\n    \n    with zipfile.ZipFile(\"/kaggle/working/submission.zip\", \"w\") as zipf:\n        for task_id in solutions:\n            zipf.write(f\"/kaggle/working/submission/task{task_id}.py\", \n                       f\"task{task_id}.py\")\n    \n    with open(\"/kaggle/working/detailed_reports.json\", \"w\") as f:\n        json.dump(reports, f, indent=2)\n    \n    print(\"\\n Summary Statistics:\")\n    print(f\"Total tasks processed: {len(solutions)}\")\n    print(f\"Successful patterns: {sum(1 for r in reports if r['verification_status'] == 'PASSED')}\")\n    print(f\"Average complexity: {np.mean([r['complexity_score'] for r in reports]):.2f}\")\n    print(f\"Average generalization: {np.mean([r['generalization_score'] for r in reports]):.2%}\")\n    \n    print(\"\\n Top 10 Most Successful Patterns:\")\n    pattern_stats = [(name, stats['successes'], stats['attempts']) \n                     for name, stats in generator.pattern_success_rates.items()\n                     if stats['attempts'] > 0]\n    pattern_stats.sort(key=lambda x: x[1], reverse=True)\n    \n    for i, (name, successes, attempts) in enumerate(pattern_stats[:10]):\n        success_rate = successes / attempts * 100\n        print(f\"{i+1}. {name}: {successes}/{attempts} ({success_rate:.1f}%)\")\n    \n    print(\"\\n Enhanced ARC solutions created: submission.zip\")\n    print(\" Detailed reports saved: detailed_reports.json\")\n\nif __name__ == \"__main__\":\n    create_enhanced_arc_solutions()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T06:49:08.464888Z","iopub.execute_input":"2025-08-01T06:49:08.465373Z","iopub.status.idle":"2025-08-01T06:50:07.724254Z","shell.execute_reply.started":"2025-08-01T06:49:08.465332Z","shell.execute_reply":"2025-08-01T06:50:07.723327Z"}},"outputs":[],"execution_count":null}]}