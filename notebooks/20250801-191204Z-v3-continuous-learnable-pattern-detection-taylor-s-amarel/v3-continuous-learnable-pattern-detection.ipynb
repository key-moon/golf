{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":95282,"databundleVersionId":13245791,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nimport zipfile\nimport numpy as np\nfrom collections import defaultdict, Counter\nfrom scipy.ndimage import convolve, label, distance_transform_edt, binary_erosion, binary_dilation, gaussian_filter, zoom\nfrom scipy.spatial import distance_matrix, ConvexHull\nfrom scipy.stats import mode, entropy, skew, kurtosis\nfrom scipy.signal import find_peaks, correlate2d\nfrom sklearn.neural_network import MLPRegressor, MLPClassifier\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier\nfrom sklearn.decomposition import PCA, NMF, FastICA\nfrom sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.semi_supervised import LabelPropagation, LabelSpreading\nfrom sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport hashlib\nimport itertools\nimport random\nfrom functools import lru_cache\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass GeneticCodeEvolver:\n    \"\"\"Genetic algorithm for evolving code solutions\"\"\"\n    \n    def __init__(self, population_size=100, mutation_rate=0.3, crossover_rate=0.7):\n        self.population_size = population_size\n        self.mutation_rate = mutation_rate\n        self.crossover_rate = crossover_rate\n        self.generation = 0\n        \n        # Code gene pool - building blocks for solutions\n        self.gene_pool = {\n            # Transformations\n            'rot90': \"[list(r)for r in zip(*g[::-1])]\",\n            'rot180': \"[r[::-1]for r in g[::-1]]\",\n            'rot270': \"[list(r)for r in zip(*g)][::-1]\",\n            'fliph': \"[r[::-1]for r in g]\",\n            'flipv': \"g[::-1]\",\n            'trans': \"[list(r)for r in zip(*g)]\",\n            \n            # Scaling\n            'scale2x': \"[[g[i//2][j//2]for j in range(len(g[0])*2)]for i in range(len(g)*2)]\",\n            'scale3x': \"[[g[i//3][j//3]for j in range(len(g[0])*3)]for i in range(len(g)*3)]\",\n            'half': \"[r[::2]for r in g[::2]]\",\n            \n            # Color operations\n            'swap_01': \"[[1 if x==0 else 0 if x==1 else x for x in r]for r in g]\",\n            'inc_color': \"[[(x+1)%10 for x in r]for r in g]\",\n            'dec_color': \"[[(x-1)%10 for x in r]for r in g]\",\n            'max_color': \"[[max(r)]*len(r)for r in g]\",\n            'min_color': \"[[min(r)]*len(r)for r in g]\",\n            \n            # Pattern operations\n            'checker': \"[[(i+j)%2 for j in range(len(g[0]))]for i in range(len(g))]\",\n            'diagonal': \"[[1 if i==j else 0 for j in range(len(g[0]))]for i in range(len(g))]\",\n            'border': \"[[1 if i in[0,len(g)-1]or j in[0,len(g[0])-1]else 0 for j in range(len(g[0]))]for i in range(len(g))]\",\n            \n            # Position-based\n            'pos_sum': \"[[(i+j)%10 for j in range(len(g[0]))]for i in range(len(g))]\",\n            'pos_mul': \"[[(i*j)%10 for j in range(len(g[0]))]for i in range(len(g))]\",\n            'pos_max': \"[[max(i,j)%10 for j in range(len(g[0]))]for i in range(len(g))]\",\n            'pos_min': \"[[min(i,j)%10 for j in range(len(g[0]))]for i in range(len(g))]\",\n            \n            # Complex operations\n            'outline': \"[[g[i][j]if any(i+di<0 or i+di>=len(g)or j+dj<0 or j+dj>=len(g[0])or g[i+di][j+dj]!=g[i][j]for di,dj in[(0,1),(0,-1),(1,0),(-1,0)])else 0 for j in range(len(g[0]))]for i in range(len(g))]\",\n            'fill_holes': \"[[g[i][j]if g[i][j]else max(g[i-1][j]if i>0 else 0,g[i][j-1]if j>0 else 0)for j in range(len(g[0]))]for i in range(len(g))]\",\n            \n            # Conditional operations\n            'if_zero': \"[[0 if g[i][j]==0 else 1 for j in range(len(g[0]))]for i in range(len(g))]\",\n            'if_nonzero': \"[[1 if g[i][j]!=0 else 0 for j in range(len(g[0]))]for i in range(len(g))]\",\n            \n            # Aggregations\n            'row_sum': \"[[sum(r)%10]*len(r)for r in g]\",\n            'col_sum': \"[[(sum(g[i][j]for i in range(len(g)))%10)for j in range(len(g[0]))]for _ in g]\",\n        }\n        \n        # Operation templates that can be combined\n        self.templates = [\n            \"def p(g):return {op1}\",\n            \"def p(g):h=len(g);w=len(g[0]);return {op1}\",\n            \"def p(g):return {op1}if len(g)>5 else {op2}\",\n            \"def p(g):t={op1};return {op2}\",\n            \"def p(g):return[[(g[i][j]{cond})for j in range(len(g[0]))]for i in range(len(g))]\",\n            \"def p(g):m={{k:v for k,v in {mapping}}};return[[m.get(x,x)for x in r]for r in g]\",\n        ]\n        \n        # Conditions for templates\n        self.conditions = [\n            \"+1)%10\",\n            \"*2)%10\", \n            \"if g[i][j]>0 else 0\",\n            \"if i>j else g[i][j]\",\n            \"if (i+j)%2 else 0\",\n            \"+i+j)%10\",\n            \"*i*j)%10\",\n        ]\n        \n    def create_individual(self):\n        \"\"\"Create a random individual (code solution)\"\"\"\n        template = random.choice(self.templates)\n        \n        if '{op1}' in template and '{op2}' in template:\n            op1 = random.choice(list(self.gene_pool.values()))\n            op2 = random.choice(list(self.gene_pool.values()))\n            code = template.format(op1=op1, op2=op2)\n        elif '{op1}' in template:\n            op1 = random.choice(list(self.gene_pool.values()))\n            code = template.format(op1=op1)\n        elif '{cond}' in template:\n            cond = random.choice(self.conditions)\n            code = template.format(cond=cond)\n        elif '{mapping}' in template:\n            # Create random mapping\n            mapping = [(i, random.randint(0, 9)) for i in range(10)]\n            code = template.format(mapping=mapping)\n        else:\n            code = template\n            \n        return code\n    \n    def mutate(self, individual):\n        \"\"\"Mutate an individual\"\"\"\n        if random.random() < self.mutation_rate:\n            # Various mutation strategies\n            mutation_type = random.choice(['replace_gene', 'modify_value', 'add_operation', 'swap_template'])\n            \n            if mutation_type == 'replace_gene':\n                # Replace a gene with another\n                for old_gene, new_gene in [(k, v) for k, v in self.gene_pool.items()]:\n                    if self.gene_pool[old_gene] in individual:\n                        new_key = random.choice(list(self.gene_pool.keys()))\n                        individual = individual.replace(self.gene_pool[old_gene], self.gene_pool[new_key])\n                        break\n                        \n            elif mutation_type == 'modify_value':\n                # Modify numeric values\n                import re\n                numbers = re.findall(r'\\d+', individual)\n                if numbers:\n                    old_num = random.choice(numbers)\n                    new_num = str((int(old_num) + random.randint(-2, 2)) % 10)\n                    individual = individual.replace(old_num, new_num, 1)\n                    \n            elif mutation_type == 'add_operation':\n                # Wrap with additional operation\n                if 'return ' in individual:\n                    op = random.choice(list(self.gene_pool.values()))\n                    individual = individual.replace('return ', f'return {op[:-1]};g=', 1)\n                    \n        return individual\n    \n    def crossover(self, parent1, parent2):\n        \"\"\"Crossover two parents to create offspring\"\"\"\n        if random.random() < self.crossover_rate:\n            # Extract components from parents\n            import re\n            \n            # Try to swap return statements\n            return1 = re.search(r'return (.+?)(?:$|;)', parent1)\n            return2 = re.search(r'return (.+?)(?:$|;)', parent2)\n            \n            if return1 and return2:\n                # Swap return statements\n                child1 = parent1.replace(return1.group(1), return2.group(1))\n                child2 = parent2.replace(return2.group(1), return1.group(1))\n                return child1, child2\n                \n        return parent1, parent2\n    \n    def evolve_population(self, population, fitness_scores):\n        \"\"\"Evolve population based on fitness scores\"\"\"\n        # Sort by fitness\n        sorted_pop = sorted(zip(population, fitness_scores), key=lambda x: x[1], reverse=True)\n        \n        # Keep top performers (elitism)\n        elite_size = self.population_size // 5\n        new_population = [ind for ind, _ in sorted_pop[:elite_size]]\n        \n        # Tournament selection for breeding\n        while len(new_population) < self.population_size:\n            # Tournament selection\n            tournament_size = 5\n            tournament = random.sample(sorted_pop, tournament_size)\n            parent1 = max(tournament, key=lambda x: x[1])[0]\n            \n            tournament = random.sample(sorted_pop, tournament_size)\n            parent2 = max(tournament, key=lambda x: x[1])[0]\n            \n            # Crossover\n            child1, child2 = self.crossover(parent1, parent2)\n            \n            # Mutation\n            child1 = self.mutate(child1)\n            child2 = self.mutate(child2)\n            \n            new_population.extend([child1, child2])\n            \n        self.generation += 1\n        return new_population[:self.population_size]\n\n\nclass HierarchicalPatternMatcher:\n    \"\"\"Hierarchical pattern matching with weighted priorities\"\"\"\n    \n    def __init__(self):\n        self.pattern_hierarchy = {\n            # Level 1: Simple transformations (highest priority)\n            'level1': {\n                'patterns': ['identity', 'rotate', 'flip', 'transpose'],\n                'weight': 1.0,\n                'matchers': {\n                    'identity': self.match_identity,\n                    'rotate': self.match_rotation,\n                    'flip': self.match_flip,\n                    'transpose': self.match_transpose\n                }\n            },\n            # Level 2: Scaling operations\n            'level2': {\n                'patterns': ['scale_up', 'scale_down', 'crop', 'pad'],\n                'weight': 0.8,\n                'matchers': {\n                    'scale_up': self.match_scale_up,\n                    'scale_down': self.match_scale_down,\n                    'crop': self.match_crop,\n                    'pad': self.match_pad\n                }\n            },\n            # Level 3: Color operations\n            'level3': {\n                'patterns': ['color_map', 'color_swap', 'color_fill', 'color_extract'],\n                'weight': 0.6,\n                'matchers': {\n                    'color_map': self.match_color_map,\n                    'color_swap': self.match_color_swap,\n                    'color_fill': self.match_color_fill,\n                    'color_extract': self.match_color_extract\n                }\n            },\n            # Level 4: Pattern operations\n            'level4': {\n                'patterns': ['pattern_fill', 'pattern_repeat', 'pattern_extract'],\n                'weight': 0.4,\n                'matchers': {\n                    'pattern_fill': self.match_pattern_fill,\n                    'pattern_repeat': self.match_pattern_repeat,\n                    'pattern_extract': self.match_pattern_extract\n                }\n            },\n            # Level 5: Complex operations\n            'level5': {\n                'patterns': ['composite', 'conditional', 'recursive'],\n                'weight': 0.2,\n                'matchers': {\n                    'composite': self.match_composite,\n                    'conditional': self.match_conditional,\n                    'recursive': self.match_recursive\n                }\n            }\n        }\n        \n        self.pattern_scores = defaultdict(float)\n        \n    def match_all_patterns(self, examples):\n        \"\"\"Match all patterns and return weighted scores\"\"\"\n        matches = {}\n        \n        for level_name, level_data in self.pattern_hierarchy.items():\n            level_weight = level_data['weight']\n            \n            for pattern_name in level_data['patterns']:\n                matcher = level_data['matchers'][pattern_name]\n                match_result = matcher(examples)\n                \n                if match_result['matched']:\n                    score = match_result['confidence'] * level_weight\n                    matches[pattern_name] = {\n                        'score': score,\n                        'level': level_name,\n                        'details': match_result,\n                        'code': match_result.get('code', None)\n                    }\n                    \n        # Sort by score\n        sorted_matches = sorted(matches.items(), key=lambda x: x[1]['score'], reverse=True)\n        return sorted_matches\n    \n    def match_identity(self, examples):\n        \"\"\"Check if output equals input\"\"\"\n        matched = all(np.array_equal(ex['input'], ex['output']) for ex in examples)\n        return {\n            'matched': matched,\n            'confidence': 1.0 if matched else 0.0,\n            'code': \"def p(g):return g\"\n        }\n    \n    def match_rotation(self, examples):\n        \"\"\"Check for rotation patterns\"\"\"\n        for k in [1, 2, 3]:\n            matched = all(np.array_equal(np.rot90(np.array(ex['input']), k), \n                                       np.array(ex['output'])) for ex in examples)\n            if matched:\n                codes = {\n                    1: \"def p(g):return[list(r)for r in zip(*g[::-1])]\",\n                    2: \"def p(g):return[r[::-1]for r in g[::-1]]\",\n                    3: \"def p(g):return[list(r)for r in zip(*g)][::-1]\"\n                }\n                return {\n                    'matched': True,\n                    'confidence': 1.0,\n                    'rotation': k * 90,\n                    'code': codes[k]\n                }\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_flip(self, examples):\n        \"\"\"Check for flip patterns\"\"\"\n        # Horizontal flip\n        matched_h = all(np.array_equal(np.fliplr(np.array(ex['input'])), \n                                     np.array(ex['output'])) for ex in examples)\n        if matched_h:\n            return {\n                'matched': True,\n                'confidence': 1.0,\n                'direction': 'horizontal',\n                'code': \"def p(g):return[r[::-1]for r in g]\"\n            }\n            \n        # Vertical flip\n        matched_v = all(np.array_equal(np.flipud(np.array(ex['input'])), \n                                     np.array(ex['output'])) for ex in examples)\n        if matched_v:\n            return {\n                'matched': True,\n                'confidence': 1.0,\n                'direction': 'vertical',\n                'code': \"def p(g):return g[::-1]\"\n            }\n            \n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_transpose(self, examples):\n        \"\"\"Check for transpose pattern\"\"\"\n        matched = all(np.array_equal(np.array(ex['input']).T, \n                                   np.array(ex['output'])) for ex in examples)\n        return {\n            'matched': matched,\n            'confidence': 1.0 if matched else 0.0,\n            'code': \"def p(g):return[list(r)for r in zip(*g)]\"\n        }\n    \n    def match_scale_up(self, examples):\n        \"\"\"Check for scale up patterns\"\"\"\n        for scale in [2, 3, 4]:\n            matched = all(\n                np.array(ex['output']).shape[0] == np.array(ex['input']).shape[0] * scale and\n                np.array(ex['output']).shape[1] == np.array(ex['input']).shape[1] * scale\n                for ex in examples\n            )\n            if matched:\n                return {\n                    'matched': True,\n                    'confidence': 0.9,\n                    'scale': scale,\n                    'code': f\"def p(g):return[[g[i//{scale}][j//{scale}]for j in range(len(g[0])*{scale})]for i in range(len(g)*{scale})]\"\n                }\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_scale_down(self, examples):\n        \"\"\"Check for scale down patterns\"\"\"\n        for scale in [2, 3, 4]:\n            matched = all(\n                np.array(ex['output']).shape[0] == np.array(ex['input']).shape[0] // scale and\n                np.array(ex['output']).shape[1] == np.array(ex['input']).shape[1] // scale\n                for ex in examples\n            )\n            if matched:\n                return {\n                    'matched': True,\n                    'confidence': 0.9,\n                    'scale': scale,\n                    'code': f\"def p(g):return[r[::{scale}]for r in g[::{scale}]]\"\n                }\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_crop(self, examples):\n        \"\"\"Check for cropping pattern\"\"\"\n        # Simplified - check if output is smaller than input\n        matched = all(\n            np.array(ex['output']).shape[0] < np.array(ex['input']).shape[0] or\n            np.array(ex['output']).shape[1] < np.array(ex['input']).shape[1]\n            for ex in examples\n        )\n        if matched:\n            # Try to find consistent crop boundaries\n            out_h, out_w = np.array(examples[0]['output']).shape\n            return {\n                'matched': True,\n                'confidence': 0.7,\n                'code': f\"def p(g):return[r[:{out_w}]for r in g[:{out_h}]]\"\n            }\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_pad(self, examples):\n        \"\"\"Check for padding pattern\"\"\"\n        matched = all(\n            np.array(ex['output']).shape[0] > np.array(ex['input']).shape[0] or\n            np.array(ex['output']).shape[1] > np.array(ex['input']).shape[1]\n            for ex in examples\n        )\n        return {'matched': matched, 'confidence': 0.7 if matched else 0.0}\n    \n    def match_color_map(self, examples):\n        \"\"\"Check for color mapping pattern\"\"\"\n        # Try to find consistent color mapping\n        mapping = {}\n        for ex in examples:\n            inp = np.array(ex['input'])\n            out = np.array(ex['output'])\n            \n            if inp.shape != out.shape:\n                return {'matched': False, 'confidence': 0.0}\n                \n            for i in range(inp.shape[0]):\n                for j in range(inp.shape[1]):\n                    if inp[i,j] in mapping:\n                        if mapping[inp[i,j]] != out[i,j]:\n                            return {'matched': False, 'confidence': 0.0}\n                    else:\n                        mapping[inp[i,j]] = out[i,j]\n                        \n        if mapping:\n            return {\n                'matched': True,\n                'confidence': 0.8,\n                'mapping': mapping,\n                'code': f\"def p(g):m={mapping};return[[m.get(x,x)for x in r]for r in g]\"\n            }\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_color_swap(self, examples):\n        \"\"\"Check for color swap pattern\"\"\"\n        # Check if exactly two colors are swapped\n        for ex in examples:\n            inp = np.array(ex['input'])\n            out = np.array(ex['output'])\n            \n            if inp.shape != out.shape:\n                return {'matched': False, 'confidence': 0.0}\n                \n            # Find changed colors\n            unique_in = set(inp.flatten())\n            unique_out = set(out.flatten())\n            \n            if len(unique_in) == 2 and unique_in == unique_out:\n                a, b = sorted(unique_in)\n                if all((inp == a) == (out == b) for ex in examples):\n                    return {\n                        'matched': True,\n                        'confidence': 0.8,\n                        'colors': (a, b),\n                        'code': f\"def p(g):return[[{b}if x=={a}else{a}if x=={b}else x for x in r]for r in g]\"\n                    }\n                    \n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_color_fill(self, examples):\n        \"\"\"Check for color fill pattern\"\"\"\n        # Check if output is single color\n        for ex in examples:\n            out = np.array(ex['output'])\n            if len(np.unique(out)) == 1:\n                color = out[0,0]\n                return {\n                    'matched': True,\n                    'confidence': 0.7,\n                    'color': color,\n                    'code': f\"def p(g):return[[{color}]*len(g[0])for _ in g]\"\n                }\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_color_extract(self, examples):\n        \"\"\"Check for color extraction pattern\"\"\"\n        # Check if output contains subset of input colors\n        for color in range(10):\n            matched = True\n            for ex in examples:\n                inp = np.array(ex['input'])\n                out = np.array(ex['output'])\n                \n                if inp.shape != out.shape:\n                    matched = False\n                    break\n                    \n                # Check if output is input with only 'color' preserved\n                mask = inp == color\n                if not np.array_equal(out[mask], inp[mask]):\n                    matched = False\n                    break\n                if not np.all(out[~mask] == 0):\n                    matched = False\n                    break\n                    \n            if matched:\n                return {\n                    'matched': True,\n                    'confidence': 0.7,\n                    'color': color,\n                    'code': f\"def p(g):return[[x if x=={color}else 0 for x in r]for r in g]\"\n                }\n                \n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_pattern_fill(self, examples):\n        \"\"\"Check for pattern fill (checkerboard, stripes, etc)\"\"\"\n        # Checkerboard pattern\n        matched_checker = True\n        for ex in examples:\n            out = np.array(ex['output'])\n            h, w = out.shape\n            \n            # Check if it's a checkerboard with any two colors\n            colors = np.unique(out)\n            if len(colors) == 2:\n                c1, c2 = colors\n                expected = np.array([[(i+j)%2 for j in range(w)] for i in range(h)])\n                if not (np.array_equal(out, np.where(expected, c1, c2)) or\n                       np.array_equal(out, np.where(expected, c2, c1))):\n                    matched_checker = False\n                    break\n            else:\n                matched_checker = False\n                break\n                \n        if matched_checker:\n            return {\n                'matched': True,\n                'confidence': 0.6,\n                'pattern': 'checkerboard',\n                'code': f\"def p(g):return[[{c1}if(i+j)%2 else {c2} for j in range(len(g[0]))]for i in range(len(g))]\"\n            }\n            \n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_pattern_repeat(self, examples):\n        \"\"\"Check for pattern repetition\"\"\"\n        # Simplified check\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_pattern_extract(self, examples):\n        \"\"\"Check for pattern extraction\"\"\"\n        # Simplified check\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_composite(self, examples):\n        \"\"\"Check for composite operations\"\"\"\n        # This would check for combinations of simpler operations\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_conditional(self, examples):\n        \"\"\"Check for conditional operations\"\"\"\n        # This would check for if-then-else patterns\n        return {'matched': False, 'confidence': 0.0}\n    \n    def match_recursive(self, examples):\n        \"\"\"Check for recursive patterns\"\"\"\n        # This would check for recursive/iterative patterns\n        return {'matched': False, 'confidence': 0.0}\n\n\nclass EnsembleVotingSystem:\n    \"\"\"Ensemble voting system for combining multiple predictions\"\"\"\n    \n    def __init__(self):\n        self.voters = []\n        self.weights = {}\n        self.performance_history = defaultdict(list)\n        \n    def add_voter(self, voter_name, voter_func, initial_weight=1.0):\n        \"\"\"Add a voter to the ensemble\"\"\"\n        self.voters.append({\n            'name': voter_name,\n            'func': voter_func,\n            'weight': initial_weight\n        })\n        self.weights[voter_name] = initial_weight\n        \n    def vote(self, candidates, examples):\n        \"\"\"Combine votes from all voters\"\"\"\n        vote_results = defaultdict(float)\n        \n        for voter in self.voters:\n            voter_votes = voter['func'](candidates, examples)\n            \n            # Apply weights\n            for candidate, score in voter_votes.items():\n                vote_results[candidate] += score * voter['weight']\n                \n        # Normalize scores\n        total_score = sum(vote_results.values())\n        if total_score > 0:\n            vote_results = {k: v/total_score for k, v in vote_results.items()}\n            \n        # Sort by score\n        sorted_results = sorted(vote_results.items(), key=lambda x: x[1], reverse=True)\n        return sorted_results\n    \n    def update_weights(self, voter_name, success):\n        \"\"\"Update voter weights based on performance\"\"\"\n        self.performance_history[voter_name].append(1.0 if success else 0.0)\n        \n        # Calculate new weight based on recent performance\n        if len(self.performance_history[voter_name]) >= 10:\n            recent_performance = self.performance_history[voter_name][-20:]\n            success_rate = sum(recent_performance) / len(recent_performance)\n            \n            # Update weight\n            self.weights[voter_name] = 0.5 + success_rate  # Weight between 0.5 and 1.5\n            \n            # Update voter\n            for voter in self.voters:\n                if voter['name'] == voter_name:\n                    voter['weight'] = self.weights[voter_name]\n                    break\n\n\nclass MetaLearningOptimizer:\n    \"\"\"Meta-learning system to learn which strategies work for which problems\"\"\"\n    \n    def __init__(self):\n        self.problem_features = []\n        self.successful_strategies = []\n        self.strategy_predictor = None\n        self.feature_importance = None\n        \n    def extract_problem_features(self, examples):\n        \"\"\"Extract meta-features from the problem\"\"\"\n        features = []\n        \n        # Size features\n        inp_shape = np.array(examples[0]['input']).shape\n        out_shape = np.array(examples[0]['output']).shape\n        \n        features.extend([\n            inp_shape[0], inp_shape[1],\n            out_shape[0], out_shape[1],\n            out_shape[0] / inp_shape[0],  # Height ratio\n            out_shape[1] / inp_shape[1],  # Width ratio\n        ])\n        \n        # Color features\n        inp_colors = set()\n        out_colors = set()\n        for ex in examples:\n            inp_colors.update(np.array(ex['input']).flatten())\n            out_colors.update(np.array(ex['output']).flatten())\n            \n        features.extend([\n            len(inp_colors),\n            len(out_colors),\n            len(inp_colors & out_colors),  # Common colors\n            len(out_colors - inp_colors),  # New colors\n        ])\n        \n        # Transformation features\n        same_size = all(np.array(ex['input']).shape == np.array(ex['output']).shape \n                       for ex in examples)\n        features.append(1.0 if same_size else 0.0)\n        \n        # Pattern features\n        has_symmetry = any(\n            np.array_equal(np.array(ex['output']), np.fliplr(np.array(ex['output']))) or\n            np.array_equal(np.array(ex['output']), np.flipud(np.array(ex['output'])))\n            for ex in examples\n        )\n        features.append(1.0 if has_symmetry else 0.0)\n        \n        # Complexity features\n        total_cells = sum(np.array(ex['input']).size + np.array(ex['output']).size \n                         for ex in examples)\n        features.append(total_cells)\n        \n        return np.array(features)\n    \n    def record_success(self, problem_features, strategy_name):\n        \"\"\"Record a successful strategy for a problem\"\"\"\n        self.problem_features.append(problem_features)\n        self.successful_strategies.append(strategy_name)\n        \n        # Retrain predictor periodically\n        if len(self.problem_features) >= 50 and len(self.problem_features) % 10 == 0:\n            self.train_predictor()\n            \n    def train_predictor(self):\n        \"\"\"Train the strategy predictor\"\"\"\n        from sklearn.preprocessing import LabelEncoder\n        \n        X = np.array(self.problem_features)\n        \n        # Encode strategy names\n        le = LabelEncoder()\n        y = le.fit_transform(self.successful_strategies)\n        \n        # Train ensemble classifier\n        self.strategy_predictor = RandomForestClassifier(n_estimators=50, random_state=42)\n        self.strategy_predictor.fit(X, y)\n        \n        # Calculate feature importance\n        self.feature_importance = self.strategy_predictor.feature_importances_\n        \n        self.label_encoder = le\n        \n    def predict_best_strategies(self, problem_features, top_k=5):\n        \"\"\"Predict best strategies for a problem\"\"\"\n        if self.strategy_predictor is None:\n            return []\n            \n        # Get probability predictions\n        probs = self.strategy_predictor.predict_proba([problem_features])[0]\n        \n        # Get top k strategies\n        top_indices = np.argsort(probs)[-top_k:][::-1]\n        top_strategies = [\n            (self.label_encoder.inverse_transform([idx])[0], probs[idx])\n            for idx in top_indices\n        ]\n        \n        return top_strategies\n\n\nclass UltraAdvancedGeneticARCSolver:\n    \"\"\"Ultra-advanced solver with genetic algorithms, ensemble voting, and meta-learning\"\"\"\n    \n    def __init__(self):\n        # Initialize all components\n        self.genetic_evolver = GeneticCodeEvolver()\n        self.pattern_matcher = HierarchicalPatternMatcher()\n        self.ensemble_voter = EnsembleVotingSystem()\n        self.meta_learner = MetaLearningOptimizer()\n        \n        # Pattern library (compact solutions)\n        self.pattern_library = {\n            'identity': (\"def p(g):return g\", 18),\n            'rotate_90': (\"def p(g):return[list(r)for r in zip(*g[::-1])]\", 46),\n            'rotate_180': (\"def p(g):return[r[::-1]for r in g[::-1]]\", 40),\n            'rotate_270': (\"def p(g):return[list(r)for r in zip(*g)][::-1]\", 46),\n            'flip_h': (\"def p(g):return[r[::-1]for r in g]\", 34),\n            'flip_v': (\"def p(g):return g[::-1]\", 23),\n            'transpose': (\"def p(g):return[list(r)for r in zip(*g)]\", 40),\n            'scale_2x': (\"def p(g):return[[g[i//2][j//2]for j in range(len(g[0])*2)]for i in range(len(g)*2)]\", 88),\n            'scale_3x': (\"def p(g):return[[g[i//3][j//3]for j in range(len(g[0])*3)]for i in range(len(g)*3)]\", 88),\n            'half_size': (\"def p(g):return[r[::2]for r in g[::2]]\", 39),\n        }\n        \n        # Initialize ensemble voters\n        self._setup_voters()\n        \n        # Success tracking\n        self.success_patterns = defaultdict(int)\n        self.failure_patterns = defaultdict(int)\n        \n        # Model ensemble for complex patterns\n        self.models = self._create_model_ensemble()\n        \n    def _setup_voters(self):\n        \"\"\"Setup voting functions for ensemble\"\"\"\n        \n        def pattern_match_voter(candidates, examples):\n            \"\"\"Vote based on pattern matching\"\"\"\n            votes = {}\n            for candidate in candidates:\n                # Test candidate on examples\n                score = self._test_candidate(candidate, examples)\n                votes[candidate] = score\n            return votes\n        \n        def length_voter(candidates, examples):\n            \"\"\"Vote based on code length (shorter is better)\"\"\"\n            votes = {}\n            max_len = max(len(c) for c in candidates) if candidates else 1\n            for candidate in candidates:\n                votes[candidate] = 1.0 - (len(candidate) / max_len)\n            return votes\n        \n        def complexity_voter(candidates, examples):\n            \"\"\"Vote based on code complexity\"\"\"\n            votes = {}\n            for candidate in candidates:\n                # Simple complexity measure\n                complexity = candidate.count('for') + candidate.count('if') + candidate.count('lambda')\n                votes[candidate] = 1.0 / (1 + complexity)\n            return votes\n        \n        def historical_voter(candidates, examples):\n            \"\"\"Vote based on historical success\"\"\"\n            votes = {}\n            for candidate in candidates:\n                # Check similarity to successful patterns\n                success_score = 0\n                for pattern, count in self.success_patterns.items():\n                    if pattern in candidate:\n                        success_score += count\n                        \n                failure_score = 0\n                for pattern, count in self.failure_patterns.items():\n                    if pattern in candidate:\n                        failure_score += count\n                        \n                votes[candidate] = success_score / (1 + failure_score)\n            return votes\n        \n        # Add voters to ensemble\n        self.ensemble_voter.add_voter('pattern_match', pattern_match_voter, 2.0)\n        self.ensemble_voter.add_voter('length', length_voter, 1.0)\n        self.ensemble_voter.add_voter('complexity', complexity_voter, 0.5)\n        self.ensemble_voter.add_voter('historical', historical_voter, 1.5)\n        \n    def _create_model_ensemble(self):\n        \"\"\"Create ensemble of ML models for complex pattern recognition\"\"\"\n        return {\n            'rf_classifier': RandomForestClassifier(n_estimators=100, random_state=42),\n            'gb_classifier': GradientBoostingClassifier(n_estimators=50, random_state=42),\n            'et_classifier': ExtraTreesClassifier(n_estimators=100, random_state=42),\n            'mlp_classifier': MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),\n            'knn_classifier': KNeighborsClassifier(n_neighbors=5),\n            'svm_classifier': SVC(probability=True, random_state=42),\n        }\n        \n    def _test_candidate(self, candidate, examples):\n        \"\"\"Test a candidate solution on examples\"\"\"\n        try:\n            # Create function from candidate code\n            namespace = {}\n            exec(candidate, namespace)\n            p = namespace.get('p')\n            \n            if p is None:\n                return 0.0\n                \n            # Test on examples\n            correct = 0\n            for ex in examples:\n                try:\n                    result = p([row[:] for row in ex['input']])\n                    if result == ex['output']:\n                        correct += 1\n                except:\n                    pass\n                    \n            return correct / len(examples) if examples else 0.0\n            \n        except:\n            return 0.0\n            \n    def generate_candidates_genetic(self, examples, generations=20):\n        \"\"\"Generate candidates using genetic algorithm\"\"\"\n        # Initialize population\n        population = [self.genetic_evolver.create_individual() \n                     for _ in range(self.genetic_evolver.population_size)]\n        \n        best_candidates = []\n        \n        for gen in range(generations):\n            # Evaluate fitness\n            fitness_scores = []\n            for individual in population:\n                score = self._test_candidate(individual, examples)\n                fitness_scores.append(score)\n                \n            # Track best candidates\n            best_idx = np.argmax(fitness_scores)\n            if fitness_scores[best_idx] > 0:\n                best_candidates.append(population[best_idx])\n                \n            # Evolve population\n            population = self.genetic_evolver.evolve_population(population, fitness_scores)\n            \n            # Early stopping if perfect solution found\n            if max(fitness_scores) == 1.0:\n                break\n                \n        return list(set(best_candidates))  # Remove duplicates\n        \n    def generate_candidates_pattern(self, examples):\n        \"\"\"Generate candidates using pattern matching\"\"\"\n        candidates = []\n        \n        # Try hierarchical pattern matching\n        matches = self.pattern_matcher.match_all_patterns(examples)\n        \n        for pattern_name, match_data in matches[:10]:  # Top 10 matches\n            if match_data['details'].get('code'):\n                candidates.append(match_data['details']['code'])\n                \n        # Add library patterns\n        for name, (code, _) in self.pattern_library.items():\n            candidates.append(code)\n            \n        return candidates\n        \n    def generate_candidates_learned(self, examples):\n        \"\"\"Generate candidates using learned patterns\"\"\"\n        candidates = []\n        \n        # Extract problem features\n        problem_features = self.meta_learner.extract_problem_features(examples)\n        \n        # Get predicted best strategies\n        if self.meta_learner.strategy_predictor is not None:\n            predicted_strategies = self.meta_learner.predict_best_strategies(problem_features)\n            \n            for strategy_name, confidence in predicted_strategies:\n                if strategy_name in self.pattern_library:\n                    candidates.append(self.pattern_library[strategy_name][0])\n                    \n        return candidates\n        \n    def generate_candidates_composite(self, examples):\n        \"\"\"Generate composite candidates by combining simpler operations\"\"\"\n        candidates = []\n        base_ops = [\n            \"g\", \n            \"[r[::-1]for r in g]\",\n            \"g[::-1]\",\n            \"[list(r)for r in zip(*g)]\",\n            \"[[g[i//2][j//2]for j in range(len(g[0])*2)]for i in range(len(g)*2)]\",\n        ]\n        \n        # Try combinations\n        for op1 in base_ops:\n            for op2 in base_ops:\n                if op1 != op2:\n                    # Chain operations\n                    candidates.append(f\"def p(g):g={op1};return {op2}\")\n                    \n        return candidates[:20]  # Limit number\n        \n    def generate_optimized_solution(self, task_data):\n        \"\"\"Generate optimized solution using all techniques\"\"\"\n        examples = task_data['train']\n        \n        # Generate candidates from multiple sources\n        all_candidates = []\n        \n        # 1. Pattern-based candidates\n        pattern_candidates = self.generate_candidates_pattern(examples)\n        all_candidates.extend(pattern_candidates)\n        \n        # 2. Genetic algorithm candidates\n        genetic_candidates = self.generate_candidates_genetic(examples, generations=10)\n        all_candidates.extend(genetic_candidates)\n        \n        # 3. Learned pattern candidates\n        learned_candidates = self.generate_candidates_learned(examples)\n        all_candidates.extend(learned_candidates)\n        \n        # 4. Composite candidates\n        composite_candidates = self.generate_candidates_composite(examples)\n        all_candidates.extend(composite_candidates)\n        \n        # Remove duplicates\n        all_candidates = list(set(all_candidates))\n        \n        # Vote on best candidate\n        if all_candidates:\n            vote_results = self.ensemble_voter.vote(all_candidates, examples)\n            \n            # Test top candidates\n            for candidate, vote_score in vote_results[:10]:\n                test_score = self._test_candidate(candidate, examples)\n                \n                if test_score == 1.0:  # Perfect score\n                    # Record success\n                    problem_features = self.meta_learner.extract_problem_features(examples)\n                    self.meta_learner.record_success(problem_features, 'genetic' if candidate in genetic_candidates else 'pattern')\n                    \n                    # Update success patterns\n                    self.success_patterns[candidate[:20]] += 1\n                    \n                    return candidate\n                    \n        # Fallback solutions\n        fallback_solutions = [\n            \"def p(g):return g\",\n            \"def p(g):return[r[::-1]for r in g[::-1]]\",\n            \"def p(g):return[list(r)for r in zip(*g[::-1])]\",\n            \"def p(g):return[[0]*len(g[0])for _ in g]\",\n            \"def p(g):return[[1]*len(g[0])for _ in g]\",\n        ]\n        \n        # Test fallbacks\n        for fallback in fallback_solutions:\n            if self._test_candidate(fallback, examples) > 0.5:\n                return fallback\n                \n        # Ultimate fallback\n        return \"def p(g):return g\"\n        \n    def analyze_and_learn(self, results):\n        \"\"\"Analyze results and update learning components\"\"\"\n        # Update voter weights based on performance\n        for task_id, (code, success) in results.items():\n            if 'pattern' in code:\n                self.ensemble_voter.update_weights('pattern_match', success)\n            elif len(code) < 50:\n                self.ensemble_voter.update_weights('length', success)\n                \n        # Update pattern success/failure counts\n        for task_id, (code, success) in results.items():\n            pattern_key = code[:30]  # Use first 30 chars as pattern key\n            if success:\n                self.success_patterns[pattern_key] += 1\n            else:\n                self.failure_patterns[pattern_key] += 1\n\n\ndef create_ultra_advanced_genetic_submission():\n    \"\"\"Create submission using ultra-advanced genetic approach\"\"\"\n    solver = UltraAdvancedGeneticARCSolver()\n    solutions = {}\n    results = {}\n    \n    print(\"ðŸ§¬ Generating Ultra-Advanced Genetic ARC Solutions...\")\n    print(\"ðŸŽ¯ Using Genetic Algorithms, Ensemble Voting, and Meta-Learning\")\n    print(\"=\" * 70)\n    \n    successful = 0\n    total_bytes = 0\n    strategy_usage = defaultdict(int)\n    \n    for task_num in range(1, 401):\n        task_id = f\"{task_num:03d}\"\n        task_file = f\"/kaggle/input/google-code-golf-2025/task{task_id}.json\"\n        \n        try:\n            with open(task_file) as f:\n                task_data = json.load(f)\n                \n            # Generate optimized solution\n            code = solver.generate_optimized_solution(task_data)\n            solutions[task_id] = code\n            \n            # Verify solution\n            try:\n                namespace = {}\n                exec(code, namespace)\n                \n                # Test on examples\n                valid = True\n                for ex in task_data['train'][:3]:\n                    p = namespace['p']\n                    result = p([row[:] for row in ex['input']])\n                    if result != ex['output']:\n                        valid = False\n                        break\n                        \n                if valid:\n                    successful += 1\n                    status = \"âœ…\"\n                    results[task_id] = (code, True)\n                else:\n                    status = \"âŒ\"\n                    results[task_id] = (code, False)\n            except:\n                status = \"âš ï¸\"\n                results[task_id] = (code, False)\n                \n            bytes_count = len(code)\n            total_bytes += bytes_count\n            \n            # Progress update\n            if task_num % 25 == 0:\n                print(f\"Progress: {task_num}/400 | Success rate: {successful/task_num:.1%} | \"\n                      f\"Avg bytes: {total_bytes/task_num:.1f}\")\n                \n                # Analyze and learn from results\n                solver.analyze_and_learn(results)\n                \n        except Exception as e:\n            code = \"def p(g):return g\"\n            solutions[task_id] = code\n            total_bytes += len(code)\n            \n    print(f\"\\n{'='*70}\")\n    print(f\"âœ… Completed: {successful}/400 valid solutions ({successful/400:.1%})\")\n    print(f\"ðŸ“Š Total bytes: {total_bytes:,}\")\n    print(f\"ðŸ“ˆ Average bytes per solution: {total_bytes/400:.1f}\")\n    \n    # Final analysis\n    print(f\"\\nðŸ§¬ Genetic Evolution Statistics:\")\n    print(f\"  Final generation: {solver.genetic_evolver.generation}\")\n    print(f\"  Pattern library size: {len(solver.pattern_library)}\")\n    print(f\"  Successful patterns: {len(solver.success_patterns)}\")\n    \n    print(f\"\\nðŸ—³ï¸ Ensemble Voting Weights:\")\n    for voter in solver.ensemble_voter.voters:\n        print(f\"  {voter['name']}: {voter['weight']:.2f}\")\n        \n    # Create submission\n    os.makedirs(\"submission\", exist_ok=True)\n    \n    for task_id, code in solutions.items():\n        with open(f\"submission/task{task_id}.py\", \"w\") as f:\n            f.write(code)\n            \n    with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n        for task_id in solutions:\n            zipf.write(f\"submission/task{task_id}.py\", f\"task{task_id}.py\")\n            \n    print(f\"\\nâœ¨ Ultra-Advanced Genetic submission created: submission.zip\")\n    \n    return solutions\n\nif __name__ == \"__main__\":\n    create_ultra_advanced_genetic_submission()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}