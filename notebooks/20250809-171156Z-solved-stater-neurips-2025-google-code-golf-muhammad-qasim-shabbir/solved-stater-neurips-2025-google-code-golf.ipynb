{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":95282,"databundleVersionId":13245791,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":12654273,"sourceType":"datasetVersion","datasetId":7996413},{"sourceId":12699433,"sourceType":"datasetVersion","datasetId":8025847},{"sourceId":12699445,"sourceType":"datasetVersion","datasetId":8025856},{"sourceId":12708975,"sourceType":"datasetVersion","datasetId":8012546},{"sourceId":12711886,"sourceType":"datasetVersion","datasetId":8034319},{"sourceId":12712009,"sourceType":"datasetVersion","datasetId":8034346}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"############ combination of solution to solve more #########","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:50:28.542525Z","iopub.execute_input":"2025-08-09T16:50:28.542831Z","iopub.status.idle":"2025-08-09T16:50:28.548494Z","shell.execute_reply.started":"2025-08-09T16:50:28.542803Z","shell.execute_reply":"2025-08-09T16:50:28.547268Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Acknowledgment: All credit goes to those notebook\nThis notebook combines my original work with adapted components and ideas inspired by  public Kaggle notebooks output solution used here for ensembling:\n\nhttps://www.kaggle.com/code/bibanh/qwen2-5-32b-arc-local-score\n\nhttps://www.kaggle.com/code/seshurajup/code-golf-ensemble-local-score-391-400-dsl\n\nsolved-127-problems-local-pleaseupvote\n\nhttps://www.kaggle.com/code/jacekwl/a-bit-more-of-code-golf\n\nineurips-2025-google-code-golf-championship1\n\nliah-submission-gcgc-v2\n\n\nI have restructured and integrated the techniques into my own pipeline, with modifications to logic, patterns, and implementation. Much respect to both authors for their contributions Use solution here combined.","metadata":{}},{"cell_type":"code","source":"import os, json, zipfile\nfrom collections import deque, Counter\nimport numpy as np\nfrom tqdm import tqdm\nfrom rich import print as print_rich\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n\nDIR = \"/kaggle\"\n\n# ---------------- PRIMITIVES ----------------\n\ndef rot90_np(g): return np.rot90(g, 1)\ndef rot180_np(g): return np.rot90(g, 2)\ndef rot270_np(g): return np.rot90(g, 3)\ndef fliph_np(g): return np.fliplr(g)\ndef flipv_np(g): return np.flipud(g)\ndef invert_colors_np(g): return 9 - g\ndef identity_np(g): return g\ndef remap_colors_np(g):\n    flat = g.flatten()\n    uniq = np.unique(flat)\n    mapping = {c: i for i, c in enumerate(uniq)}\n    return np.vectorize(mapping.get)(g)\n\ndef majority_fill_np(g):\n    vals, counts = np.unique(g, return_counts=True)\n    fill_val = vals[np.argmax(counts)]\n    out = g.copy()\n    out[out == 0] = fill_val\n    return out\n\nprimitive_code_snippets = {\n    \"identity\": \"\"\"return g\"\"\",\n    \"rot90\": \"\"\"return [list(row) for row in zip(*g[::-1])]\"\"\",\n    \"rot180\": \"\"\"return [row[::-1] for row in g[::-1]]\"\"\",\n    \"rot270\": \"\"\"return [list(row) for row in zip(*g)][::-1]\"\"\",\n    \"fliph\": \"\"\"return [row[::-1] for row in g]\"\"\",\n    \"flipv\": \"\"\"return g[::-1]\"\"\",\n    \"invert_colors\": \"\"\"return [[9 - c for c in row] for row in g]\"\"\",\n    \"remap_colors\": \"\"\"uniq = sorted(set(c for row in g for c in row)); mp = {c:i for i,c in enumerate(uniq)}; return [[mp[c] for c in row] for row in g]\"\"\",\n    \"majority_fill\": \"\"\"flat = [c for row in g for c in row]; fill_val = max(set(flat), key=flat.count); return [[fill_val if c==0 else c for c in row] for row in g]\"\"\"\n}\n\n# ---------------- TRANSFORM CLASS ----------------\nclass Transform:\n    def __init__(self, func, name=None):\n        self.func = func\n        self.name = name or func.__name__\n    def __call__(self, grid):\n        try: return self.func(grid)\n        except: return None\n    def __repr__(self): return f\"Transform({self.name})\"\n    def compose(self, other):\n        def composed(g):\n            r = self(g)\n            return None if r is None else other(r)\n        return Transform(composed, f\"{other.name}∘{self.name}\")\n\n# ---------------- SOLVER ----------------\nclass ARCCombinatorialSolver:\n    def __init__(self, max_depth=3, max_candidates=7000):\n        self.max_depth = max_depth\n        self.max_candidates = max_candidates\n        self.learned_rules = {}\n        self.primitives = [\n            Transform(identity_np,\"identity\"),\n            Transform(rot90_np,\"rot90\"),\n            Transform(rot180_np,\"rot180\"),\n            Transform(rot270_np,\"rot270\"),\n            Transform(fliph_np,\"fliph\"),\n            Transform(flipv_np,\"flipv\"),\n            Transform(invert_colors_np,\"invert_colors\"),\n            Transform(remap_colors_np,\"remap_colors\"),\n            Transform(majority_fill_np,\"majority_fill\")\n        ]\n\n    def match(self, rule, pairs):\n        return all((pred:=rule(inp)) is not None and np.array_equal(pred, out) for inp,out in pairs)\n\n    def score_rule(self, rule, pairs):\n        \"\"\"Count exact matches (higher better), penalize longer names.\"\"\"\n        matches = sum(np.array_equal(rule(inp), out) for inp,out in pairs)\n        return matches, -len(rule.name)\n\n    def bfs_search(self, pairs):\n        q = deque([(Transform(identity_np,\"identity\"),0)])\n        valid_rules = []\n        visited_hashes=set()\n\n        def grid_hash(g): return hash(g.tobytes())\n\n        while q and len(valid_rules) < 5:\n            rule, depth = q.popleft()\n            if depth > self.max_depth: continue\n\n            trans = []\n            fail=False\n            for inp,_ in pairs:\n                out = rule(inp)\n                if out is None: fail=True; break\n                trans.append(out)\n            if fail: continue\n\n            h = tuple(grid_hash(g) for g in trans)\n            if h in visited_hashes: continue\n            visited_hashes.add(h)\n\n            if self.match(rule, pairs):\n                valid_rules.append(rule)\n                continue\n\n            if depth < self.max_depth:\n                for prim in self.primitives:\n                    q.append((rule.compose(prim), depth+1))\n                    if len(q) > self.max_candidates: break\n        if valid_rules:\n            valid_rules.sort(key=lambda r: (-self.score_rule(r,pairs)[0], self.score_rule(r,pairs)[1]))\n        return valid_rules\n\n    def solve(self, task):\n        tid = task.get('id')\n        train_pairs=[(np.array(p['input'],int),np.array(p['output'],int)) for p in task['train']]\n        test_inputs=[np.array(p['input'],int) for p in task['test']]\n\n        if tid in self.learned_rules:\n            rule = self.learned_rules[tid]\n            if self.match(rule, train_pairs):\n                return rule, [rule(inp).tolist() for inp in test_inputs]\n\n        rules = self.bfs_search(train_pairs)\n        if not rules:\n            return Transform(identity_np,\"identity\"), [inp.tolist() for inp in test_inputs]\n        best_rule=rules[0]\n        self.learned_rules[tid]=best_rule\n        return best_rule,[best_rule(inp).tolist() for inp in test_inputs]\n\n# ---------------- CODE GENERATOR ----------------\ndef generate_code(transform):\n    names = transform.name.split(\"∘\")\n    names = list(reversed(names))\n    if names == [\"identity\"]: return \"def p(g):\\n    return g\\n\"\n    code_lines=[\"def p(g):\",\"    res = g\"]\n    for name in names:\n        snippet = primitive_code_snippets.get(name,\"return g\")\n        for line in snippet.strip().split(\"\\n\"):\n            if \"return\" in line: line=line.replace(\"return\",\"res =\")\n            code_lines.append(\"    \"+line.strip())\n    code_lines.append(\"    return res\")\n    return \"\\n\".join(code_lines)\n\n# ---------------- MAIN ----------------\nprint(\"Loading tasks...\")\ntrain_tasks={}\nfor i in tqdm(range(1,401)):\n    tid=f\"{i:03d}\"\n    with open(f\"{DIR}/input/google-code-golf-2025/task{tid}.json\") as f:\n        t=json.load(f); t['id']=tid; train_tasks[tid]=t\n\nsolver=ARCCombinatorialSolver(max_depth=5,max_candidates=20000)\n\nsubmission_dir=f\"{DIR}/working/submissionfile\"\nos.makedirs(submission_dir,exist_ok=True)\n\nsolved=0\nfor tid,task in tqdm(train_tasks.items()):\n    transform,preds=solver.solve(task)\n    code=generate_code(transform)\n    with open(f\"{submission_dir}/task{tid}.py\",\"w\") as f:\n        f.write(code)\n    solved+=1\n\n# print_rich(f\"[green]Generated solutions for {solved} tasks[/green]\")\n# with zipfile.ZipFile(f\"{DIR}/working/submisisonfile.zip\",\"w\") as z:\n#     for i in range(1,401):\n#         tid=f\"{i:03d}\"\n#         z.write(f\"{submission_dir}/task{tid}.py\",arcname=f\"task{tid}.py\")\n# print_rich(f\"[green]Submission zip created[/green]\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:50:28.549607Z","iopub.execute_input":"2025-08-09T16:50:28.550347Z","iopub.status.idle":"2025-08-09T16:50:52.623734Z","shell.execute_reply.started":"2025-08-09T16:50:28.550293Z","shell.execute_reply":"2025-08-09T16:50:52.622738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/arc-generator-predifine-dict-code')\nimport re \nimport ast \nfrom predefined_solution import *\nfrom simple_arc_solution import *\nfrom clean import *\n\ndef generate_general_fallback_solution(task_data):\n    \"\"\"\n    Try simple general transformations and see if any solve the task.\n    \"\"\"\n    from copy import deepcopy\n\n    def all_match(task, func):\n        for pair in task[\"train\"] + task[\"test\"] + task.get(\"arc-gen\", []):\n            try:\n                output = func(pair[\"input\"])\n                if output != pair[\"output\"]:\n                    return False\n            except:\n                return False\n        return True\n\n    candidates = [\n        (\"identity\", lambda g: g),\n        (\"transpose\", lambda g: [list(row) for row in zip(*g)]),\n        (\"hflip\", lambda g: [row[::-1] for row in g]),\n        (\"vflip\", lambda g: g[::-1]),\n        (\"rotate180\", lambda g: [row[::-1] for row in g[::-1]])\n    ]\n\n    for name, fn in candidates:\n        if all_match(task_data, fn):\n            print_rich(f\"[green]Task solved by general fallback: {name}[/green]\")\n            # generate code string for fn\n            if name == \"identity\":\n                return \"def p(g): return g\"\n            elif name == \"transpose\":\n                return \"def p(g): return [list(r) for r in zip(*g)]\"\n            elif name == \"hflip\":\n                return \"def p(g): return [r[::-1] for r in g]\"\n            elif name == \"vflip\":\n                return \"def p(g): return g[::-1]\"\n            elif name == \"rotate180\":\n                return \"def p(g): return [r[::-1] for r in g[::-1]]\"\n\n    return None\n\narc_generator  =  ARCSolutionGenerator()","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-08-09T16:50:52.628797Z","iopub.execute_input":"2025-08-09T16:50:52.629056Z","iopub.status.idle":"2025-08-09T16:50:53.795471Z","shell.execute_reply.started":"2025-08-09T16:50:52.629034Z","shell.execute_reply":"2025-08-09T16:50:53.794462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport zipfile\nimport copy\nimport re\nimport math\nimport ast\nimport string\nfrom collections import Counter\nfrom functools import reduce\nfrom typing import List, Tuple\n\nfrom tqdm import tqdm\nfrom rich import print as print_rich\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n\nDIR = \"/kaggle\"\n\n\ndef check_solution(solution, task_data):\n    try:\n        namespace = {}\n        exec(solution, namespace)\n        if 'p' not in namespace:\n            return False\n        all_examples = task_data['train'] + task_data['test'] + task_data['arc-gen']\n        for example in all_examples:\n            input_grid = copy.deepcopy(example['input'])\n            expected = example['output']\n            try:\n                actual = namespace['p'](input_grid)\n                if actual != expected:\n                    return False\n            except Exception:\n                return False\n        return True\n    except Exception:\n        return False\n\n\nsubmissions = [\n    \"/kaggle/input/d/muhammadqasimshabbir/oh-barnacles/submission\",\n    \"/kaggle/input/solved-127-problems-local-pleaseupvote-submission/submission\",\n    \"/kaggle/input/neurips-2025-google-code-golf-championship1\",\n    \"/kaggle/input/liah-submission-gcgc-v2\",\n    \"/kaggle/input/code-golf-ensemble-local-score-391-400-dsl\",\n    \"/kaggle/working/submisisonfile\",\n]\n\nsimple_solution = \"\"\"def p(g):return g\"\"\"\n\nsolved = 0\ntotal_score = 0\nos.makedirs(f\"{DIR}/working/submission\", exist_ok=True)\nremoved_by_method = Counter()\n\nfor task_num in tqdm(range(1, 401)):\n    task_id = f\"{task_num:03d}\"\n    solutions = []\n    task_data_path = f\"{DIR}/input/google-code-golf-2025/task{task_id}.json\"\n    task_data = json.load(open(task_data_path))\n\n    is_solved = False\n    \n    # First try predefined solutions if available\n    if task_num in PREDEFINED_SOLUTIONS:\n        solution_code = PREDEFINED_SOLUTIONS[task_num]\n        if check_solution(solution_code, task_data):\n            solutions.append(solution_code)\n            is_solved = True\n            print_rich(f\"[yellow]{task_id} - solved by predefined solution dict[/yellow]\")\n    \n    # Then try existing submissions\n    if not is_solved:\n        for submission_path in submissions:\n            task_code_path = f\"{submission_path}/task{task_id}.py\"\n            if not os.path.exists(task_code_path):\n                continue\n            with open(task_code_path, 'r') as f:\n                solution_code = f.read()\n            if check_solution(solution_code, task_data):\n                solutions.append(solution_code)\n                is_solved = True\n            print_rich(f\"[green]{task_id} - solved by sumissions  [/green]\")\n            \n    # If not solved by predefined or existing submissions, try the ARC generator\n    if not is_solved:\n        try:\n            generated_solution = arc_generator.generate_solution(task_data)\n            if arc_generator.verify_solution(generated_solution, task_data):\n                solutions.append(generated_solution)\n                is_solved = True\n                print_rich(f\"[yellow]{task_id} - solved by generator[/yellow]\")\n        except Exception as e:\n            print_rich(f\"[red]Error generating solution for task {task_id}: {str(e)}[/red]\")\n            pass\n            \n    # Fallback: try all predefined solutions if none worked\n    if not is_solved:\n        for key, sol_code in PREDEFINED_SOLUTIONS.items():\n            if check_solution(sol_code, task_data):\n                        solutions.append(sol_code)\n                        is_solved = True\n                        print_rich(f\"[magenta]{task_id} - solved by global predefined dict (task {key})[/magenta]\")\n                        break\n    if not is_solved:\n        general_code = generate_general_fallback_solution(task_data)\n        print_rich(f\"[red]{task_id} - solved by general fallback[red]\")\n        if general_code and check_solution(general_code, task_data):\n            solutions.append(general_code)\n            is_solved = True\n\n    score = 0.001\n    best_solution = simple_solution\n\n    if solutions:\n        # Apply all minimization techniques to each solution\n        minimized_solutions = []\n        for solution in solutions:\n            for method in [remove_spaces, minimize_indentation,\n                         substitute_enumerate, substitute_range,\n                         join_block_lines, strip_trailing_whitespaces,\n                         remove_empty_lines, remove_comments,\n                         shorten_variable_names, def_to_lambda, remove_spaces]:\n                b1 = get_bytes(solution)\n                new_solution = solution\n                try:\n                    new_solution = method(solution)\n                except Exception as e:\n                    print(e)\n                b2 = get_bytes(new_solution)\n\n                if check_solution(new_solution, task_data) and b2 < b1:\n                    solution = new_solution\n                    removed_by_method[method] += (b1 - b2)\n            \n            minimized_solutions.append(solution)\n        \n        best_solution = min(minimized_solutions, key=get_bytes)\n        score = calculate_score(best_solution)\n        if is_solved:\n            solved += 1\n\n    total_score += score\n\n    with open(f\"{DIR}/working/submission/task{task_id}.py\", \"w\") as f:\n        f.write(best_solution)\n\n# Create the submission zip\nwith zipfile.ZipFile(f\"{DIR}/working/submission.zip\", \"w\") as zipf:\n    for task_num in range(1, 401):\n        task_id = f\"{task_num:03d}\"\n        zipf.write(f\"{DIR}/working/submission/task{task_id}.py\", \n                  arcname=f\"task{task_id}.py\")\n\nprint_rich(f\"[green]Total solved: {solved} / 400[/green]\")\nprint_rich(f\"[blue]LB Score: {total_score:.3f}[/blue]\")\n\nfor k, v in removed_by_method.most_common():\n    print(f\"{k.__name__:<30}{v:>5}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T16:50:53.796316Z","iopub.execute_input":"2025-08-09T16:50:53.796821Z","iopub.status.idle":"2025-08-09T16:53:24.318844Z","shell.execute_reply.started":"2025-08-09T16:50:53.796796Z","shell.execute_reply":"2025-08-09T16:53:24.317574Z"},"scrolled":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}