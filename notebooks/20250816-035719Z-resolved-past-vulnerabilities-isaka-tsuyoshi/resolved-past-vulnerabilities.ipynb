{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":95282,"databundleVersionId":13375770,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This is to share, for reference, a vulnerability that existed before the patch was applied. This vulnerability has already been resolved, so it should no longer be an issue.\n\nThis notebook reports a past vulnerability, as previously discussed in [this thread](https://www.kaggle.com/competitions/google-code-golf-2025/discussion/599368). This vulnerability existed before the patch was applied. Since it has already been resolved, it's no longer a concern.\n\nThe previous evaluation system passed or failed submissions based solely on the result of `p(input) == expected`. It relied completely on the `__eq__` method of the `p(input)` object. This created an exploit: by overriding the `__eq__` method to always return `True`, it was possible to create a **task.py** file that would pass every time, regardless of the output.","metadata":{}},{"cell_type":"code","source":"import os\n\n# Create the directory\noutput_dir = 'submission'\nos.makedirs(output_dir, exist_ok=True)\n\n# The code file\n# I intentionally wrote the code for readability, as the primary goal is to clearly report a vulnerability.\ncode_content = \"\"\"\nclass A:\n    def __eq__(self, o):\n        return True\ndef p(g):\n    return A()\"\"\"\n\n\n# I only created 300 files instead of all 400 to prevent **leaderboard pollution**. \n# Even with just 300, a score of 720K+ is achieved. While creating all 400 would result in a score of 960K+, I've chosen not to.\nfor i in range(1, 301):\n    # Format the filename with leading zeros (e.g., 'task001.py')\n    file_name = f'task{i:03d}.py'\n    file_path = os.path.join(output_dir, file_name)\n    \n    # Write the code to the file\n    with open(file_path, 'w') as f:\n        f.write(code_content)\n\nprint(\"300 task files have been created in the directory.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\nfrom pathlib import Path\n\nzip_path = Path(\"/kaggle/working/submission.zip\")\n\nwith zipfile.ZipFile(zip_path, \"w\") as zipf:\n    for file in Path(output_dir).glob(\"*.py\"):\n        zipf.write(file, arcname=file.name)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}