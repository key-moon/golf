{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":95282,"databundleVersionId":13245791,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nimport zipfile\nimport numpy as np\nfrom collections import defaultdict, Counter\nfrom scipy.ndimage import label, binary_dilation, binary_erosion, convolve\nfrom itertools import product, permutations, combinations\nimport math\n\n# ==================== SECTION 1: 1D PATTERNS AND TRANSFORMATIONS ====================\n\ndef handle_1d_raster_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    h, w = inp.shape\n    \n    for order in ['row_major', 'col_major', 'zigzag', 'spiral']:\n        arr_in = to_1d_raster(inp.tolist(), order)\n        arr_out = to_1d_raster(out.tolist(), order)\n        \n        if arr_out == arr_in[::-1]:\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n arr={''.join([\n  f\"[g[i][j] for i in range(h) for j in range(w)]\" if order=='row_major' else\n  f\"[g[i][j] for j in range(w) for i in range(h)]\" if order=='col_major' else\n  f\"[g[i][j] for i in range(h-1,-1,-1) for j in range(w-1,-1,-1)]\" if order=='row_major_rev' else\n  \"[]\"\n ])}\n arr=arr[::-1]\n res=[[0]*w for _ in range(h)]\n for idx,val in enumerate(arr):\n  {\"i,j=idx//w,idx%w;res[i][j]=val\" if order=='row_major' else\n   \"j,i=idx//h,idx%h;res[i][j]=val\" if order=='col_major' else\n   \"\"}\n return res\n\"\"\"\n        \n        if sorted(arr_out) == sorted(arr_in) and arr_out == sorted(arr_in):\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n arr=sorted([g[i][j] for i in range(h) for j in range(w)])\n res=[[0]*w for _ in range(h)]\n for idx,val in enumerate(arr):\n  i,j=idx//w,idx%w\n  res[i][j]=val\n return res\n\"\"\"\n    return None\n\ndef handle_1d_pattern_repeat(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    for repeat in [2, 3, 4]:\n        if arr_out == arr_in * repeat:\n            h_out, w_out = out.shape\n            return f\"\"\"def p(g):\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n arr=arr*{repeat}\n h,w={h_out},{w_out}\n res=[[0]*w for _ in range(h)]\n for idx,val in enumerate(arr[:h*w]):\n  res[idx//w][idx%w]=val\n return res\n\"\"\"\n    return None\n\ndef handle_1d_sort_colors(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    color_groups = defaultdict(list)\n    for i, c in enumerate(arr_in):\n        color_groups[c].append(i)\n    \n    sorted_arr = []\n    for color in sorted(color_groups.keys()):\n        sorted_arr.extend([color] * len(color_groups[color]))\n    \n    if arr_out == sorted_arr:\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n arr=[g[i][j] for i in range(h) for j in range(w)]\n counts={}\n for c in arr:\n  counts[c]=counts.get(c,0)+1\n res=[]\n for c in sorted(counts.keys()):\n  res.extend([c]*counts[c])\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_1d_run_length_decode(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    \n    decoded = []\n    i = 0\n    while i < len(arr_in) - 1:\n        value = arr_in[i]\n        count = arr_in[i+1]\n        if count > 0 and count < 10:\n            decoded.extend([value] * count)\n        i += 2\n    \n    if len(decoded) > 0:\n        oh, ow = out.shape\n        if len(decoded) == oh * ow:\n            test_grid = from_1d_raster(decoded, oh, ow, 'row_major')\n            if test_grid and np.array_equal(np.array(test_grid), out):\n                return f\"\"\"def p(g):\n arr=[g[i][j]for i in range(len(g))for j in range(len(g[0]))]\n d=[]\n i=0\n while i<len(arr)-1:\n  v,c=arr[i],arr[i+1]\n  if c>0 and c<10:\n   d.extend([v]*c)\n  i+=2\n h,w={oh},{ow}\n res=[[0]*w for _ in range(h)]\n for idx,val in enumerate(d[:h*w]):\n  res[idx//w][idx%w]=val\n return res\n\"\"\"\n    return None\n\ndef handle_1d_reverse_segments(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    for seg_size in range(2, min(10, len(arr_in)//2)):\n        test = []\n        for i in range(0, len(arr_in), seg_size):\n            segment = arr_in[i:i+seg_size]\n            test.extend(segment[::-1])\n        \n        if test[:len(arr_out)] == arr_out:\n            h, w = out.shape\n            return f\"\"\"def p(g):\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n res=[]\n for i in range(0,len(arr),{seg_size}):\n  res.extend(arr[i:i+{seg_size}][::-1])\n h,w={h},{w}\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_1d_shuffle_pattern(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    odd_even = []\n    for i in range(1, len(arr_in), 2):\n        odd_even.append(arr_in[i])\n    for i in range(0, len(arr_in), 2):\n        odd_even.append(arr_in[i])\n    \n    if odd_even == arr_out:\n        h, w = out.shape\n        return f\"\"\"def p(g):\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n res=[]\n for i in range(1,len(arr),2):\n  res.append(arr[i])\n for i in range(0,len(arr),2):\n  res.append(arr[i])\n h,w={h},{w}\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_1d_wave_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    n = len(arr_in)\n    indices = list(range(n))\n    wave_indices = sorted(indices, key=lambda i: math.sin(2 * math.pi * i / n))\n    \n    test = [arr_in[i] for i in wave_indices]\n    if test == arr_out:\n        h, w = out.shape\n        return f\"\"\"def p(g):\n import math\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n n=len(arr)\n idx=sorted(range(n),key=lambda i:math.sin(2*math.pi*i/n))\n res=[arr[i] for i in idx]\n h,w={h},{w}\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_1d_compression(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    \n    compressed = []\n    if arr_in:\n        compressed.append(arr_in[0])\n        for i in range(1, len(arr_in)):\n            if arr_in[i] != arr_in[i-1]:\n                compressed.append(arr_in[i])\n    \n    if len(compressed) <= out.shape[0] * out.shape[1]:\n        h, w = out.shape\n        test_grid = from_1d_raster(compressed + [0]*(h*w-len(compressed)), h, w, 'row_major')\n        if test_grid and np.array_equal(np.array(test_grid), out):\n            return f\"\"\"def p(g):\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n c=[]\n if arr:\n  c.append(arr[0])\n  for i in range(1,len(arr)):\n   if arr[i]!=arr[i-1]:\n    c.append(arr[i])\n h,w={h},{w}\n c.extend([0]*(h*w-len(c)))\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(c[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_1d_periodic_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    for period in range(2, min(10, len(arr_in)//2)):\n        test = []\n        for i in range(len(arr_in)):\n            if i % period == 0:\n                test.append(arr_in[i])\n            elif i % period == 1 and i < len(arr_in):\n                test.append((arr_in[i] + 1) % 10)\n            else:\n                test.append(arr_in[i])\n        \n        if test == arr_out:\n            h, w = out.shape\n            return f\"\"\"def p(g):\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n res=[]\n for i in range(len(arr)):\n  if i%{period}==0:\n   res.append(arr[i])\n  elif i%{period}==1:\n   res.append((arr[i]+1)%10)\n  else:\n   res.append(arr[i])\n h,w={h},{w}\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_1d_fibonacci_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    fibs = [0, 1]\n    while fibs[-1] < len(arr_in):\n        fibs.append(fibs[-1] + fibs[-2])\n    \n    test = [0] * len(arr_in)\n    for f in fibs:\n        if f < len(arr_in):\n            test[f] = arr_in[f]\n    \n    if test == arr_out:\n        h, w = out.shape\n        return f\"\"\"def p(g):\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n f=[0,1]\n while f[-1]<len(arr):\n  f.append(f[-1]+f[-2])\n res=[0]*len(arr)\n for i in f:\n  if i<len(arr):\n   res[i]=arr[i]\n h,w={h},{w}\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_1d_prime_positions(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    def is_prime(n):\n        if n < 2: return False\n        for i in range(2, int(n**0.5) + 1):\n            if n % i == 0: return False\n        return True\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    test = []\n    for i in range(len(arr_in)):\n        if is_prime(i):\n            test.append(arr_in[i])\n        else:\n            test.append(0)\n    \n    if test == arr_out:\n        h, w = out.shape\n        return f\"\"\"def p(g):\n def ip(n):\n  if n<2:return False\n  for i in range(2,int(n**0.5)+1):\n   if n%i==0:return False\n  return True\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n res=[]\n for i in range(len(arr)):\n  res.append(arr[i] if ip(i) else 0)\n h,w={h},{w}\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_1d_alternating_ops(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_in = to_1d_raster(inp.tolist(), 'row_major')\n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    \n    test = []\n    for i, val in enumerate(arr_in):\n        if i % 2 == 0:\n            test.append((val + 1) % 10)\n        else:\n            test.append((val - 1) % 10)\n    \n    if test == arr_out:\n        h, w = out.shape\n        return f\"\"\"def p(g):\n arr=[g[i][j] for i in range(len(g)) for j in range(len(g[0]))]\n res=[]\n for i,v in enumerate(arr):\n  if i%2==0:\n   res.append((v+1)%10)\n  else:\n   res.append((v-1)%10)\n h,w={h},{w}\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\n# ==================== SECTION 2: 2D LINEARIZATION PATTERNS ====================\n\ndef handle_diagonal_linearization(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    h, w = inp.shape\n    \n    diagonals = []\n    for d in range(w):\n        diag = []\n        i, j = 0, d\n        while i < h and j < w:\n            diag.append(inp[i, j])\n            i += 1\n            j += 1\n        diagonals.extend(diag)\n    \n    for d in range(1, h):\n        diag = []\n        i, j = d, 0\n        while i < h and j < w:\n            diag.append(inp[i, j])\n            i += 1\n            j += 1\n        diagonals.extend(diag)\n    \n    oh, ow = out.shape\n    if len(diagonals) == oh * ow:\n        test_grid = from_1d_raster(diagonals, oh, ow, 'row_major')\n        if test_grid and np.array_equal(np.array(test_grid), out):\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n d=[]\n for s in range(w):\n  i,j=0,s\n  while i<h and j<w:\n   d.append(g[i][j])\n   i+=1;j+=1\n for s in range(1,h):\n  i,j=s,0\n  while i<h and j<w:\n   d.append(g[i][j])\n   i+=1;j+=1\n oh,ow={oh},{ow}\n res=[[0]*ow for _ in range(oh)]\n for idx,v in enumerate(d[:oh*ow]):\n  res[idx//ow][idx%ow]=v\n return res\n\"\"\"\n    return None\n\ndef handle_hilbert_curve(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape == (2, 2) and out.shape == (1, 4):\n        hilbert_order = [inp[1,0], inp[0,0], inp[0,1], inp[1,1]]\n        if hilbert_order == out[0].tolist():\n            return \"\"\"def p(g):\n if len(g)==2 and len(g[0])==2:\n  return[[g[1][0],g[0][0],g[0][1],g[1][1]]]\n return g\n\"\"\"\n    return None\n\ndef handle_morton_order(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = inp.shape\n    if h == w and h & (h-1) == 0:\n        morton = []\n        \n        def interleave_bits(x, y):\n            result = 0\n            for i in range(16):\n                result |= ((x & (1 << i)) << i) | ((y & (1 << i)) << (i + 1))\n            return result\n        \n        coords = []\n        for i in range(h):\n            for j in range(w):\n                coords.append((interleave_bits(i, j), i, j))\n        \n        coords.sort()\n        morton = [inp[i, j] for _, i, j in coords]\n        \n        oh, ow = out.shape\n        if len(morton) == oh * ow:\n            test_grid = from_1d_raster(morton, oh, ow, 'row_major')\n            if test_grid and np.array_equal(np.array(test_grid), out):\n                return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n def ib(x,y):\n  r=0\n  for i in range(16):\n   r|=((x&(1<<i))<<i)|((y&(1<<i))<<(i+1))\n  return r\n c=[]\n for i in range(h):\n  for j in range(w):\n   c.append((ib(i,j),i,j))\n c.sort()\n m=[g[i][j]for _,i,j in c]\n return[m]\n\"\"\"\n    return None\n\ndef handle_block_linearization(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = inp.shape\n    for bh in range(1, min(h+1, 4)):\n        for bw in range(1, min(w+1, 4)):\n            if h % bh == 0 and w % bw == 0:\n                blocks = []\n                for i in range(0, h, bh):\n                    for j in range(0, w, bw):\n                        for bi in range(bh):\n                            for bj in range(bw):\n                                blocks.append(inp[i+bi, j+bj])\n                \n                oh, ow = out.shape\n                if len(blocks) == oh * ow:\n                    test_grid = from_1d_raster(blocks, oh, ow, 'row_major')\n                    if test_grid and np.array_equal(np.array(test_grid), out):\n                        return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n b=[]\n for i in range(0,h,{bh}):\n  for j in range(0,w,{bw}):\n   for bi in range({bh}):\n    for bj in range({bw}):\n     b.append(g[i+bi][j+bj])\n oh,ow={oh},{ow}\n res=[[0]*ow for _ in range(oh)]\n for idx,v in enumerate(b[:oh*ow]):\n  res[idx//ow][idx%ow]=v\n return res\n\"\"\"\n    return None\n\ndef handle_snake_pattern(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_out = to_1d_raster(out.tolist(), 'row_major')\n    arr_snake = to_1d_raster(inp.tolist(), 'zigzag')\n    \n    if arr_snake == arr_out:\n        h, w = out.shape\n        return f\"\"\"def p(g):\n res=[]\n for i in range(len(g)):\n  if i%2==0:\n   res.extend(g[i])\n  else:\n   res.extend(g[i][::-1])\n h,w={h},{w}\n out=[[0]*w for _ in range(h)]\n for i,v in enumerate(res[:h*w]):\n  out[i//w][i%w]=v\n return out\n\"\"\"\n    return None\n\ndef handle_radial_linearization(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = inp.shape\n    cx, cy = w // 2, h // 2\n    \n    pixels = []\n    for i in range(h):\n        for j in range(w):\n            dist = ((i - cy)**2 + (j - cx)**2)**0.5\n            angle = math.atan2(i - cy, j - cx)\n            pixels.append((dist, angle, inp[i, j]))\n    \n    pixels.sort()\n    radial = [p[2] for p in pixels]\n    \n    oh, ow = out.shape\n    if len(radial) == oh * ow:\n        test_grid = from_1d_raster(radial, oh, ow, 'row_major')\n        if test_grid and np.array_equal(np.array(test_grid), out):\n            return f\"\"\"def p(g):\n import math\n h,w=len(g),len(g[0])\n cx,cy=w//2,h//2\n px=[]\n for i in range(h):\n  for j in range(w):\n   d=((i-cy)**2+(j-cx)**2)**0.5\n   a=math.atan2(i-cy,j-cx)\n   px.append((d,a,g[i][j]))\n px.sort()\n r=[p[2]for p in px]\n oh,ow={oh},{ow}\n res=[[0]*ow for _ in range(oh)]\n for idx,v in enumerate(r[:oh*ow]):\n  res[idx//ow][idx%ow]=v\n return res\n\"\"\"\n    return None\n\n# ==================== SECTION 3: PARITY AND MODULAR PATTERNS ====================\n\ndef handle_odd_even_rows(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    test = np.copy(inp)\n    \n    for i in range(0, len(inp), 2):\n        test[i] = (test[i] + 1) % 10\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n for i in range(0,len(g),2):\n  res[i]=[(x+1)%10 for x in g[i]]\n return res\n\"\"\"\n    \n    test = np.copy(inp)\n    for i in range(1, len(inp), 2):\n        test[i] = 0\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n for i in range(1,len(g),2):\n  res[i]=[0]*len(g[0])\n return res\n\"\"\"\n    return None\n\ndef handle_odd_even_cols(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    test = np.copy(inp)\n    w = inp.shape[1]\n    for j in range(0, w-1, 2):\n        test[:, j], test[:, j+1] = inp[:, j+1].copy(), inp[:, j].copy()\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n w=len(g[0])\n for i in range(len(g)):\n  for j in range(0,w-1,2):\n   res[i][j],res[i][j+1]=g[i][j+1],g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_checkerboard_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    test = np.copy(inp)\n    h, w = inp.shape\n    \n    for i in range(h):\n        for j in range(w):\n            if (i + j) % 2 == 0:\n                test[i, j] = (inp[i, j] * 2) % 10\n            else:\n                test[i, j] = (inp[i, j] + 5) % 10\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n for i in range(len(g)):\n  for j in range(len(g[0])):\n   if(i+j)%2==0:\n    res[i][j]=(g[i][j]*2)%10\n   else:\n    res[i][j]=(g[i][j]+5)%10\n return res\n\"\"\"\n    return None\n\ndef handle_parity_coloring(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    test = np.zeros_like(inp)\n    h, w = inp.shape\n    \n    for i in range(h):\n        for j in range(w):\n            if inp[i, j] != 0:\n                test[i, j] = 1 if (i + j) % 2 == 0 else 2\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[[0]*len(g[0])for _ in g]\n for i in range(len(g)):\n  for j in range(len(g[0])):\n   if g[i][j]!=0:\n    res[i][j]=1 if(i+j)%2==0 else 2\n return res\n\"\"\"\n    return None\n\ndef handle_alternating_blocks(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    if h % 2 == 0 and w % 2 == 0:\n        test = np.copy(inp)\n        \n        for i in range(0, h, 2):\n            for j in range(0, w, 2):\n                block_idx = (i//2 + j//2) % 2\n                if block_idx == 0:\n                    block = inp[i:i+2, j:j+2]\n                    test[i:i+2, j:j+2] = np.rot90(block, 1)\n                else:\n                    block = inp[i:i+2, j:j+2]\n                    test[i:i+2, j:j+2] = np.fliplr(block)\n        \n        if np.array_equal(test, out):\n            return \"\"\"def p(g):\n import numpy as np\n h,w=len(g),len(g[0])\n res=[r[:]for r in g]\n for i in range(0,h,2):\n  for j in range(0,w,2):\n   idx=(i//2+j//2)%2\n   b=[g[i+x][j:j+2]for x in range(2)]\n   if idx==0:\n    r=np.rot90(b,1).tolist()\n   else:\n    r=np.fliplr(b).tolist()\n   for x in range(2):\n    for y in range(2):\n     res[i+x][j+y]=r[x][y]\n return res\n\"\"\"\n    return None\n\ndef handle_modular_arithmetic(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    for mod in range(2, 10):\n        for add in range(0, 10):\n            test = (inp + add) % mod\n            if np.array_equal(test, out):\n                return f\"\"\"def p(g):\n return[[(x+{add})%{mod} for x in r]for r in g]\n\"\"\"\n    \n    for mod in range(2, 10):\n        for mult in range(1, 10):\n            test = (inp * mult) % mod\n            if np.array_equal(test, out):\n                return f\"\"\"def p(g):\n return[[(x*{mult})%{mod} for x in r]for r in g]\n\"\"\"\n    return None\n\n# ==================== SECTION 4: BINARY AND ARITHMETIC PATTERNS ====================\n\ndef handle_xor_patterns(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    for const in range(1, 16):\n        test = inp ^ const\n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n return[[x^{const} for x in r]for r in g]\n\"\"\"\n    \n    test = np.zeros_like(inp)\n    h, w = inp.shape\n    for i in range(h):\n        for j in range(w):\n            test[i, j] = inp[i, j] ^ ((i + j) % 10)\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n return[[g[i][j]^((i+j)%10)for j in range(len(g[0]))]for i in range(len(g))]\n\"\"\"\n    return None\n\ndef handle_binary_operations(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    test = np.zeros_like(inp)\n    for i in range(inp.shape[0]):\n        for j in range(inp.shape[1]):\n            test[i, j] = bin(inp[i, j]).count('1')\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n return[[bin(x).count('1')for x in r]for r in g]\n\"\"\"\n    \n    test = np.zeros_like(inp)\n    for i in range(inp.shape[0]):\n        for j in range(inp.shape[1]):\n            val = inp[i, j]\n            if val < 8:\n                rev = int(bin(val)[2:].zfill(3)[::-1], 2)\n                test[i, j] = rev\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[]\n for r in g:\n  row=[]\n  for x in r:\n   if x<8:\n    row.append(int(bin(x)[2:].zfill(3)[::-1],2))\n   else:\n    row.append(x)\n  res.append(row)\n return res\n\"\"\"\n    return None\n\ndef handle_bit_manipulation(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    for shift in range(1, 4):\n        test = (inp << shift) % 10\n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n return[[(x<<{shift})%10 for x in r]for r in g]\n\"\"\"\n    \n    for shift in range(1, 4):\n        test = inp >> shift\n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n return[[x>>{shift} for x in r]for r in g]\n\"\"\"\n    \n    for bit in range(3):\n        test = inp ^ (1 << bit)\n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n return[[x^(1<<{bit})for x in r]for r in g]\n\"\"\"\n    return None\n\ndef handle_arithmetic_sequences(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_out = out.flatten()\n    if len(arr_out) > 2:\n        diff = arr_out[1] - arr_out[0]\n        is_arithmetic = all(arr_out[i+1] - arr_out[i] == diff for i in range(len(arr_out)-1))\n        \n        if is_arithmetic:\n            start = arr_out[0]\n            h, w = out.shape\n            return f\"\"\"def p(g):\n s,d={start},{diff}\n h,w={h},{w}\n res=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   row.append(s+(i*w+j)*d)\n  res.append(row)\n return res\n\"\"\"\n    return None\n\ndef handle_geometric_sequences(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    arr_out = out.flatten()\n    if len(arr_out) > 2 and arr_out[0] != 0:\n        ratio = arr_out[1] / arr_out[0] if arr_out[0] != 0 else 0\n        is_geometric = all(\n            abs(arr_out[i+1] - arr_out[i] * ratio) < 0.001 \n            for i in range(len(arr_out)-1) \n            if arr_out[i] != 0\n        )\n        \n        if is_geometric:\n            start = arr_out[0]\n            h, w = out.shape\n            return f\"\"\"def p(g):\n s,r={start},{ratio}\n h,w={h},{w}\n res=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   row.append(int(s*(r**(i*w+j))))\n  res.append(row)\n return res\n\"\"\"\n    return None\n\n# ==================== SECTION 5: TEMPLATE AND CONVOLUTION PATTERNS ====================\n\ndef handle_template_matching(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    for th in range(2, 4):\n        for tw in range(2, 4):\n            if th > inp.shape[0] or tw > inp.shape[1]:\n                continue\n            \n            templates = {}\n            for i in range(inp.shape[0] - th + 1):\n                for j in range(inp.shape[1] - tw + 1):\n                    template = tuple(inp[i:i+th, j:j+tw].flatten())\n                    if template not in templates:\n                        templates[template] = len(templates) + 1\n            \n            test = np.copy(inp)\n            for i in range(inp.shape[0] - th + 1):\n                for j in range(inp.shape[1] - tw + 1):\n                    template = tuple(inp[i:i+th, j:j+tw].flatten())\n                    tid = templates[template]\n                    test[i + th//2, j + tw//2] = tid\n            \n            if np.array_equal(test, out):\n                return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n th,tw={th},{tw}\n t={{}}\n for i in range(h-th+1):\n  for j in range(w-tw+1):\n   tmpl=tuple(g[i+x][j+y]for x in range(th)for y in range(tw))\n   if tmpl not in t:\n    t[tmpl]=len(t)+1\n res=[r[:]for r in g]\n for i in range(h-th+1):\n  for j in range(w-tw+1):\n   tmpl=tuple(g[i+x][j+y]for x in range(th)for y in range(tw))\n   res[i+th//2][j+tw//2]=t[tmpl]\n return res\n\"\"\"\n    return None\n\ndef handle_convolution_patterns(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    kernels = [\n        np.array([[1, 1], [1, 1]]),\n        np.array([[1, 0], [0, 1]]),\n        np.array([[0, 1], [1, 0]]),\n        np.array([[1, -1], [-1, 1]]),\n    ]\n    \n    for kernel in kernels:\n        from scipy.ndimage import convolve\n        test = convolve(inp.astype(float), kernel, mode='constant')\n        test = np.abs(test).astype(int) % 10\n        \n        if np.array_equal(test, out):\n            kernel_str = str(kernel.tolist()).replace(' ', '')\n            return f\"\"\"def p(g):\n from scipy.ndimage import convolve\n import numpy as np\n k=np.array({kernel_str})\n t=convolve(np.array(g,float),k,mode='constant')\n return(np.abs(t).astype(int)%10).tolist()\n\"\"\"\n    return None\n\ndef handle_morphological_ops(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    binary_inp = inp > 0\n    \n    from scipy.ndimage import binary_erosion\n    test = binary_erosion(binary_inp).astype(int)\n    if np.array_equal(test * inp.max(), out):\n        return \"\"\"def p(g):\n from scipy.ndimage import binary_erosion\n import numpy as np\n b=np.array(g)>0\n e=binary_erosion(b).astype(int)\n return(e*np.max(g)).tolist()\n\"\"\"\n    \n    from scipy.ndimage import binary_dilation\n    test = binary_dilation(binary_inp).astype(int)\n    if np.array_equal(test * inp.max(), out):\n        return \"\"\"def p(g):\n from scipy.ndimage import binary_dilation\n import numpy as np\n b=np.array(g)>0\n d=binary_dilation(b).astype(int)\n return(d*np.max(g)).tolist()\n\"\"\"\n    return None\n\ndef handle_edge_detection_advanced(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    edges = np.zeros_like(inp)\n    \n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            gx = abs(inp[i,j+1] - inp[i,j-1])\n            gy = abs(inp[i+1,j] - inp[i-1,j])\n            edges[i,j] = min(gx + gy, 9)\n    \n    if np.array_equal(edges, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    edge=False\n    for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n     ni,nj=i+di,j+dj\n     if not(0<=ni<h and 0<=nj<w)or g[ni][nj]==0:\n      edge=True\n      break\n    if edge:\n     res[i][j]=g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_corner_detection(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    corners = np.zeros_like(inp)\n    \n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            if inp[i,j] != 0:\n                neighbors = [\n                    inp[i-1,j], inp[i+1,j],\n                    inp[i,j-1], inp[i,j+1]\n                ]\n                if sum(n != 0 for n in neighbors) == 2:\n                    if (neighbors[0] != 0 and neighbors[2] != 0) or \\\n                       (neighbors[0] != 0 and neighbors[3] != 0) or \\\n                       (neighbors[1] != 0 and neighbors[2] != 0) or \\\n                       (neighbors[1] != 0 and neighbors[3] != 0):\n                        corners[i,j] = inp[i,j]\n    \n    if np.array_equal(corners, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(1,h-1):\n  for j in range(1,w-1):\n   if g[i][j]!=0:\n    n=[g[i-1][j],g[i+1][j],g[i][j-1],g[i][j+1]]\n    c=sum(1 for x in n if x!=0)\n    if c==2:\n     if(n[0]!=0 and n[2]!=0)or(n[0]!=0 and n[3]!=0)or(n[1]!=0 and n[2]!=0)or(n[1]!=0 and n[3]!=0):\n      res[i][j]=g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_pattern_completion_advanced(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape == out.shape:\n        h, w = inp.shape\n        \n        for period in range(1, w//2):\n            test = np.copy(inp)\n            for i in range(h):\n                row = inp[i]\n                for j in range(w):\n                    if row[j] == 0 and j >= period:\n                        test[i,j] = row[j % period]\n            \n            if np.array_equal(test, out):\n                return f\"\"\"def p(g):\n res=[r[:]for r in g]\n h,w=len(g),len(g[0])\n for i in range(h):\n  for j in range(w):\n   if g[i][j]==0 and j>={period}:\n    res[i][j]=g[i][j%{period}]\n return res\n\"\"\"\n    return None\n\n# ==================== SECTION 6: GRAPH AND COMPONENT PATTERNS ====================\n\ndef handle_graph_coloring(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    colors = np.zeros_like(inp)\n    color_id = 1\n    \n    visited = set()\n    \n    for i in range(h):\n        for j in range(w):\n            if inp[i,j] != 0 and (i,j) not in visited:\n                queue = [(i,j)]\n                component = []\n                \n                while queue:\n                    y, x = queue.pop(0)\n                    if (y,x) in visited:\n                        continue\n                    visited.add((y,x))\n                    component.append((y,x))\n                    \n                    for dy, dx in [(0,1), (1,0), (0,-1), (-1,0)]:\n                        ny, nx = y + dy, x + dx\n                        if (0 <= ny < h and 0 <= nx < w and \n                            inp[ny,nx] != 0 and (ny,nx) not in visited):\n                            queue.append((ny,nx))\n                \n                for y, x in component:\n                    colors[y,x] = color_id\n                color_id = (color_id % 9) + 1\n    \n    if np.array_equal(colors, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n c=[[0]*w for _ in range(h)]\n cid=1\n v=set()\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0 and(i,j)not in v:\n    q=[(i,j)]\n    comp=[]\n    while q:\n     y,x=q.pop(0)\n     if(y,x)in v:continue\n     v.add((y,x))\n     comp.append((y,x))\n     for dy,dx in[(0,1),(1,0),(0,-1),(-1,0)]:\n      ny,nx=y+dy,x+dx\n      if 0<=ny<h and 0<=nx<w and g[ny][nx]!=0 and(ny,nx)not in v:\n       q.append((ny,nx))\n    for y,x in comp:\n     c[y][x]=cid\n    cid=(cid%9)+1\n return c\n\"\"\"\n    return None\n\ndef handle_tree_traversal(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape == out.shape:\n        h, w = inp.shape\n        \n        root = None\n        for i in range(h):\n            for j in range(w):\n                if inp[i,j] != 0:\n                    root = (i,j)\n                    break\n            if root:\n                break\n        \n        if root:\n            levels = np.zeros_like(inp)\n            queue = [(root[0], root[1], 1)]\n            visited = set()\n            \n            while queue:\n                y, x, level = queue.pop(0)\n                if (y,x) in visited:\n                    continue\n                visited.add((y,x))\n                levels[y,x] = level\n                \n                for dy, dx in [(1,0), (0,1), (0,-1)]:\n                    ny, nx = y + dy, x + dx\n                    if (0 <= ny < h and 0 <= nx < w and \n                        inp[ny,nx] != 0 and (ny,nx) not in visited):\n                        queue.append((ny,nx, level + 1))\n            \n            if np.array_equal(levels, out):\n                return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n r=None\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    r=(i,j)\n    break\n  if r:break\n if r:\n  l=[[0]*w for _ in range(h)]\n  q=[(r[0],r[1],1)]\n  v=set()\n  while q:\n   y,x,lv=q.pop(0)\n   if(y,x)in v:continue\n   v.add((y,x))\n   l[y][x]=lv\n   for dy,dx in[(1,0),(0,1),(0,-1)]:\n    ny,nx=y+dy,x+dx\n    if 0<=ny<h and 0<=nx<w and g[ny][nx]!=0 and(ny,nx)not in v:\n     q.append((ny,nx,lv+1))\n  return l\n return g\n\"\"\"\n    return None\n\ndef handle_component_labeling(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    from scipy.ndimage import label\n    labeled, n = label(inp > 0)\n    \n    if np.array_equal(labeled, out):\n        return \"\"\"def p(g):\n from scipy.ndimage import label\n import numpy as np\n l,_=label(np.array(g)>0)\n return l.tolist()\n\"\"\"\n    return None\n\ndef handle_minimum_spanning_tree(task_data, analysis):\n    return None\n\ndef handle_graph_isomorphism(task_data, analysis):\n    return None\n\n# ==================== SECTION 7: COLOR MANIPULATION PATTERNS ====================\n\ndef handle_color_gradients(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = out.shape\n    \n    test = np.zeros((h, w), dtype=int)\n    for j in range(w):\n        test[:, j] = (j * 9 // (w-1)) if w > 1 else 0\n    \n    if np.array_equal(test, out):\n        return f\"\"\"def p(g):\n h,w={h},{w}\n return[[(j*9//(w-1))if w>1 else 0 for j in range(w)]for _ in range(h)]\n\"\"\"\n    \n    test = np.zeros((h, w), dtype=int)\n    for i in range(h):\n        test[i, :] = (i * 9 // (h-1)) if h > 1 else 0\n    \n    if np.array_equal(test, out):\n        return f\"\"\"def p(g):\n h,w={h},{w}\n return[[(i*9//(h-1))if h>1 else 0 for j in range(w)]for i in range(h)]\n\"\"\"\n    \n    cx, cy = w // 2, h // 2\n    max_dist = max(h, w)\n    test = np.zeros((h, w), dtype=int)\n    \n    for i in range(h):\n        for j in range(w):\n            dist = int(((i-cy)**2 + (j-cx)**2)**0.5)\n            test[i,j] = min(dist * 9 // max_dist, 9)\n    \n    if np.array_equal(test, out):\n        return f\"\"\"def p(g):\n h,w={h},{w}\n cx,cy={cx},{cy}\n md={max_dist}\n res=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   d=int(((i-cy)**2+(j-cx)**2)**0.5)\n   row.append(min(d*9//md,9))\n  res.append(row)\n return res\n\"\"\"\n    return None\n\ndef handle_color_mixing(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    test = np.zeros_like(inp)\n    \n    for i in range(h):\n        for j in range(w):\n            neighbors = []\n            for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n                ni, nj = i + di, j + dj\n                if 0 <= ni < h and 0 <= nj < w:\n                    neighbors.append(inp[ni,nj])\n            \n            if neighbors:\n                test[i,j] = sum(neighbors) // len(neighbors)\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   n=[]\n   for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n    ni,nj=i+di,j+dj\n    if 0<=ni<h and 0<=nj<w:\n     n.append(g[ni][nj])\n   if n:\n    res[i][j]=sum(n)//len(n)\n return res\n\"\"\"\n    return None\n\ndef handle_palette_reduction(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    unique_out = np.unique(out)\n    if len(unique_out) < len(np.unique(inp)):\n        color_map = {}\n        for val in np.unique(inp):\n            nearest = min(unique_out, key=lambda x: abs(x - val))\n            color_map[int(val)] = int(nearest)\n        \n        test = np.vectorize(lambda x: color_map.get(x, x))(inp)\n        \n        if np.array_equal(test, out):\n            map_str = ','.join(f'{k}:{v}' for k,v in color_map.items())\n            return f\"\"\"def p(g):\n m={{{map_str}}}\n return[[m.get(x,x)for x in r]for r in g]\n\"\"\"\n    return None\n\ndef handle_color_quantization(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    for levels in [2, 3, 4, 5]:\n        test = (inp * levels // 10) * (10 // levels)\n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n return[[(x*{levels}//10)*{10//levels} for x in r]for r in g]\n\"\"\"\n    return None\n\ndef handle_color_spreading(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    spread = np.copy(inp)\n    \n    for iteration in range(3):\n        new_spread = np.copy(spread)\n        \n        for i in range(h):\n            for j in range(w):\n                if spread[i,j] == 0:\n                    for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n                        ni, nj = i + di, j + dj\n                        if 0 <= ni < h and 0 <= nj < w and spread[ni,nj] != 0:\n                            new_spread[i,j] = spread[ni,nj]\n                            break\n        \n        spread = new_spread\n        \n        if np.array_equal(spread, out):\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n s=[r[:]for r in g]\n for _ in range({iteration+1}):\n  ns=[r[:]for r in s]\n  for i in range(h):\n   for j in range(w):\n    if s[i][j]==0:\n     for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n      ni,nj=i+di,j+dj\n      if 0<=ni<h and 0<=nj<w and s[ni][nj]!=0:\n       ns[i][j]=s[ni][nj]\n       break\n  s=ns\n return s\n\"\"\"\n    return None\n\ndef handle_color_waves(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = out.shape\n    \n    test = np.zeros((h, w), dtype=int)\n    for i in range(h):\n        for j in range(w):\n            val = int(4.5 + 4.5 * math.sin(2 * math.pi * j / w))\n            test[i,j] = val\n    \n    if np.array_equal(test, out):\n        return f\"\"\"def p(g):\n import math\n h,w={h},{w}\n res=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   v=int(4.5+4.5*math.sin(2*math.pi*j/w))\n   row.append(v)\n  res.append(row)\n return res\n\"\"\"\n    return None\n\ndef handle_color_count(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    unique_colors = len(np.unique(inp))\n    \n    if np.all(out == unique_colors):\n        return f\"\"\"def p(g):\n colors=set()\n for r in g:\n  for c in r:\n   colors.add(c)\n n=len(colors)\n return[[n]*len(g[0])for _ in g]\n\"\"\"\n    return None\n\ndef handle_color_frequency_sort(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    flat = inp.flatten()\n    counts = Counter(flat)\n    \n    sorted_colors = sorted(counts.keys(), key=lambda x: (-counts[x], x))\n    color_map = {c: i+1 for i, c in enumerate(sorted_colors) if c != 0}\n    color_map[0] = 0\n    \n    test = np.vectorize(lambda x: color_map.get(x, x))(inp)\n    \n    if np.array_equal(test, out):\n        map_str = ','.join(f'{k}:{v}' for k,v in color_map.items())\n        return f\"\"\"def p(g):\n from collections import Counter\n c=Counter(x for r in g for x in r)\n s=sorted(c.keys(),key=lambda x:(-c[x],x))\n m={{c:i+1 for i,c in enumerate(s)if c!=0}}\n m[0]=0\n return[[m.get(x,x)for x in r]for r in g]\n\"\"\"\n    return None\n\ndef handle_replace_most_common(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    counts = Counter(inp.flatten())\n    most_common = counts.most_common(1)[0][0]\n    \n    for new_color in range(10):\n        test = np.where(inp == most_common, new_color, inp)\n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n from collections import Counter\n c=Counter(x for r in g for x in r)\n mc=c.most_common(1)[0][0]\n return[[{new_color} if x==mc else x for x in r]for r in g]\n\"\"\"\n    return None\n\ndef handle_color_propagation(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = inp.shape\n    \n    test = np.copy(inp)\n    for i in range(h):\n        last_color = 0\n        for j in range(w):\n            if inp[i,j] != 0:\n                last_color = inp[i,j]\n            elif last_color != 0:\n                test[i,j] = last_color\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n for i in range(len(g)):\n  lc=0\n  for j in range(len(g[0])):\n   if g[i][j]!=0:\n    lc=g[i][j]\n   elif lc!=0:\n    res[i][j]=lc\n return res\n\"\"\"\n    \n    test = np.copy(inp)\n    for j in range(w):\n        last_color = 0\n        for i in range(h):\n            if inp[i,j] != 0:\n                last_color = inp[i,j]\n            elif last_color != 0:\n                test[i,j] = last_color\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n for j in range(len(g[0])):\n  lc=0\n  for i in range(len(g)):\n   if g[i][j]!=0:\n    lc=g[i][j]\n   elif lc!=0:\n    res[i][j]=lc\n return res\n\"\"\"\n    return None\n\ndef handle_flood_fill(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp[0,0] == 0 and out[0,0] != 0:\n        fill_color = out[0,0]\n        \n        h, w = inp.shape\n        filled = np.copy(inp)\n        to_fill = [(0, 0)]\n        filled[0,0] = fill_color\n        \n        while to_fill:\n            y, x = to_fill.pop()\n            for dy, dx in [(0,1), (1,0), (0,-1), (-1,0)]:\n                ny, nx = y + dy, x + dx\n                if 0 <= ny < h and 0 <= nx < w and filled[ny,nx] == 0:\n                    filled[ny,nx] = fill_color\n                    to_fill.append((ny, nx))\n        \n        if np.array_equal(filled, out):\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[r[:]for r in g]\n fc={fill_color}\n q=[(0,0)]\n res[0][0]=fc\n while q:\n  y,x=q.pop()\n  for dy,dx in[(0,1),(1,0),(0,-1),(-1,0)]:\n   ny,nx=y+dy,x+dx\n   if 0<=ny<h and 0<=nx<w and res[ny][nx]==0:\n    res[ny][nx]=fc\n    q.append((ny,nx))\n return res\n\"\"\"\n    return None\n\ndef handle_color_mapping(task_data, analysis):\n    color_map = {}\n    for pos, changes in analysis['color_changes'].items():\n        if len(changes) == 1:\n            src, dest = next(iter(changes))\n            if src not in color_map:\n                color_map[src] = dest\n            elif color_map[src] != dest:\n                return None\n    \n    if not color_map:\n        return None\n    \n    cases = ','.join([f'{int(s)}:{int(d)}' for s,d in color_map.items()])\n    return f\"\"\"def p(g):\n m={{{cases}}}\n return[[m.get(x,x)for x in r]for r in g]\n\"\"\"\n\n# ==================== SECTION 8: GEOMETRIC TRANSFORMATIONS ====================\n\ndef handle_rotate_90(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if np.array_equal(np.rot90(inp, -1), out):\n        return \"\"\"def p(g):\n return[list(r)for r in zip(*g[::-1])]\n\"\"\"\n    return None\n\ndef handle_rotate_180(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if np.array_equal(np.rot90(inp, 2), out):\n        return \"\"\"def p(g):\n return[r[::-1]for r in g[::-1]]\n\"\"\"\n    return None\n\ndef handle_rotate_270(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if np.array_equal(np.rot90(inp, 1), out):\n        return \"\"\"def p(g):\n return[list(r)for r in zip(*g)][::-1]\n\"\"\"\n    return None\n\ndef handle_flip_horizontal(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if np.array_equal(np.fliplr(inp), out):\n        return \"\"\"def p(g):\n return[r[::-1]for r in g]\n\"\"\"\n    return None\n\ndef handle_flip_vertical(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if np.array_equal(np.flipud(inp), out):\n        return \"\"\"def p(g):\n return g[::-1]\n\"\"\"\n    return None\n\ndef handle_transpose(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(inp.T, out):\n        return \"\"\"def p(g):\n return[list(r)for r in zip(*g)]\n\"\"\"\n    return None\n\ndef handle_rotate_45(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    h, w = inp.shape\n    \n    diagonals = defaultdict(list)\n    for i in range(h):\n        for j in range(w):\n            diagonals[i+j].append(inp[i,j])\n    \n    if len(diagonals) == out.shape[0]:\n        out_rows = []\n        for d in sorted(diagonals.keys()):\n            out_rows.append(diagonals[d])\n        \n        max_len = max(len(row) for row in out_rows)\n        for row in out_rows:\n            row.extend([0] * (max_len - len(row)))\n        \n        if np.array_equal(np.array(out_rows), out):\n            return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n d={}\n for i in range(h):\n  for j in range(w):\n   k=i+j\n   if k not in d:d[k]=[]\n   d[k].append(g[i][j])\n res=[]\n for k in sorted(d.keys()):\n  res.append(d[k])\n m=max(len(r)for r in res)\n for r in res:\n  r.extend([0]*(m-len(r)))\n return res\n\"\"\"\n    return None\n\ndef handle_shear_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = inp.shape\n    \n    for shear in range(1, 4):\n        test = np.zeros_like(out)\n        for i in range(h):\n            for j in range(w):\n                new_j = (j + i * shear) % out.shape[1]\n                if new_j < out.shape[1]:\n                    test[i, new_j] = inp[i, j]\n        \n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*{out.shape[1]} for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   nj=(j+i*{shear})%{out.shape[1]}\n   res[i][nj]=g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_perspective_transform(task_data, analysis):\n    return None\n\ndef handle_upscale(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    for h_scale in range(1, 4):\n        for w_scale in range(1, 4):\n            if (inp.shape[0]*h_scale == out.shape[0] and \n                inp.shape[1]*w_scale == out.shape[1]):\n                test = np.repeat(np.repeat(inp, h_scale, axis=0), w_scale, axis=1)\n                if np.array_equal(test, out):\n                    return f\"\"\"def p(g):\n return[[x for x in row for _ in range({w_scale})]\n        for row in g for _ in range({h_scale})]\n\"\"\"\n    return None\n\ndef handle_downscale(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    for h_scale in range(1, 4):\n        for w_scale in range(1, 4):\n            if (inp.shape[0]//h_scale == out.shape[0] and \n                inp.shape[1]//w_scale == out.shape[1]):\n                test = inp[::h_scale, ::w_scale]\n                if np.array_equal(test, out):\n                    return f\"\"\"def p(g):\n return[row[::{w_scale}]for row in g[::{h_scale}]]\n\"\"\"\n    return None\n\ndef handle_pad_to_square(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    h, w = inp.shape\n    \n    if h != w and out.shape[0] == out.shape[1]:\n        size = max(h, w)\n        if out.shape == (size, size):\n            pad_h = (size - h) // 2\n            pad_w = (size - w) // 2\n            \n            test = np.zeros((size, size), dtype=int)\n            test[pad_h:pad_h+h, pad_w:pad_w+w] = inp\n            \n            if np.array_equal(test, out):\n                return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n s=max(h,w)\n ph,pw=(s-h)//2,(s-w)//2\n res=[[0]*s for _ in range(s)]\n for i in range(h):\n  for j in range(w):\n   res[ph+i][pw+j]=g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_crop_to_content(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    rows, cols = np.where(inp > 0)\n    if len(rows) == 0:\n        return None\n        \n    min_row, max_row = rows.min(), rows.max()\n    min_col, max_col = cols.min(), cols.max()\n    \n    cropped = inp[min_row:max_row+1, min_col:max_col+1]\n    \n    if np.array_equal(cropped, out):\n        return \"\"\"def p(g):\n rows,cols=[],[]\n for i in range(len(g)):\n  for j in range(len(g[0])):\n   if g[i][j]>0:\n    rows.append(i)\n    cols.append(j)\n if not rows:return g\n r0,r1=min(rows),max(rows)+1\n c0,c1=min(cols),max(cols)+1\n return[r[c0:c1]for r in g[r0:r1]]\n\"\"\"\n    return None\n\ndef handle_zoom_center(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    h, w = inp.shape\n    oh, ow = out.shape\n    \n    if oh < h and ow < w:\n        y = (h - oh) // 2\n        x = (w - ow) // 2\n        \n        if np.array_equal(inp[y:y+oh, x:x+ow], out):\n            return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n oh,ow={oh},{ow}\n y,x=(h-oh)//2,(w-ow)//2\n return[r[x:x+ow]for r in g[y:y+oh]]\n\"\"\"\n    return None\n\ndef handle_aspect_ratio_change(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    ih, iw = inp.shape\n    oh, ow = out.shape\n    \n    if oh != ih or ow != iw:\n        test = np.zeros((oh, ow), dtype=int)\n        for i in range(oh):\n            for j in range(ow):\n                src_i = i * ih // oh\n                src_j = j * iw // ow\n                test[i,j] = inp[src_i, src_j]\n        \n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n ih,iw=len(g),len(g[0])\n oh,ow={oh},{ow}\n res=[]\n for i in range(oh):\n  row=[]\n  for j in range(ow):\n   si=i*ih//oh\n   sj=j*iw//ow\n   row.append(g[si][sj])\n  res.append(row)\n return res\n\"\"\"\n    return None\n\n# ==================== SECTION 9: PATTERN REPETITION AND TILING ====================\n\ndef handle_repeat_pattern(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    for h in range(1, min(5, inp.shape[0]+1)):\n        for w in range(1, min(5, inp.shape[1]+1)):\n            pattern = inp[:h,:w]\n            test = np.tile(pattern, (out.shape[0]//h + 1, out.shape[1]//w + 1))\n            test = test[:out.shape[0], :out.shape[1]]\n            if np.array_equal(out, test):\n                oh, ow = out.shape\n                return f\"\"\"def p(g):\n pat=[r[:{w}]for r in g[:{h}]]\n res=[]\n for i in range({oh}):\n  row=[]\n  for j in range({ow}):\n   row.append(pat[i%{h}][j%{w}])\n  res.append(row)\n return res\n\"\"\"\n    return None\n\ndef handle_tile_pattern(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    ih, iw = inp.shape\n    oh, ow = out.shape\n    \n    for th in range(1, min(ih+1, 5)):\n        for tw in range(1, min(iw+1, 5)):\n            if oh % th == 0 and ow % tw == 0:\n                tile = inp[:th, :tw]\n                tiled = np.tile(tile, (oh//th, ow//tw))\n                \n                if np.array_equal(tiled, out):\n                    return f\"\"\"def p(g):\n tile=[r[:{tw}]for r in g[:{th}]]\n h,w={oh},{ow}\n res=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   row.append(tile[i%{th}][j%{tw}])\n  res.append(row)\n return res\n\"\"\"\n    return None\n\ndef handle_mirror_pattern(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    mirrored = np.hstack([inp, np.fliplr(inp)])\n    if np.array_equal(mirrored, out):\n        return \"\"\"def p(g):\n return[r+r[::-1]for r in g]\n\"\"\"\n    \n    mirrored = np.vstack([inp, np.flipud(inp)])\n    if np.array_equal(mirrored, out):\n        return \"\"\"def p(g):\n return g+g[::-1]\n\"\"\"\n    \n    top = np.hstack([inp, np.fliplr(inp)])\n    bottom = np.hstack([np.flipud(inp), np.flipud(np.fliplr(inp))])\n    mirrored = np.vstack([top, bottom])\n    if np.array_equal(mirrored, out):\n        return \"\"\"def p(g):\n t=[r+r[::-1]for r in g]\n b=[r+r[::-1]for r in g[::-1]]\n return t+b\n\"\"\"\n    return None\n\ndef handle_extract_pattern(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    ih, iw = inp.shape\n    oh, ow = out.shape\n    \n    if oh <= ih and ow <= iw:\n        for y in range(ih - oh + 1):\n            for x in range(iw - ow + 1):\n                if np.array_equal(inp[y:y+oh, x:x+ow], out):\n                    if y == 0 and x == 0:\n                        return f\"\"\"def p(g):\n return[r[:{ow}]for r in g[:{oh}]]\n\"\"\"\n                    if y == (ih-oh)//2 and x == (iw-ow)//2:\n                        return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n oh,ow={oh},{ow}\n y,x=(h-oh)//2,(w-ow)//2\n return[r[x:x+ow]for r in g[y:y+oh]]\n\"\"\"\n    return None\n\ndef handle_apply_mask(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    mask = (out != 0)\n    \n    checkerboard = np.indices(inp.shape).sum(axis=0) % 2\n    if np.array_equal(mask, checkerboard):\n        test = np.where(checkerboard, inp, 0)\n        if np.array_equal(test, out):\n            return \"\"\"def p(g):\n return[[g[i][j]if(i+j)%2 else 0 for j in range(len(g[0]))]for i in range(len(g))]\n\"\"\"\n    \n    diag_mask = np.eye(inp.shape[0], inp.shape[1], dtype=bool)\n    if np.array_equal(mask, diag_mask):\n        test = np.where(diag_mask, inp, 0)\n        if np.array_equal(test, out):\n            return \"\"\"def p(g):\n return[[g[i][j]if i==j else 0 for j in range(len(g[0]))]for i in range(len(g))]\n\"\"\"\n    return None\n\ndef handle_pattern_substitution(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape[0] >= 2 and inp.shape[1] >= 2:\n        patterns = {\n            ((0,0),(0,0)): ((1,1),(1,1)),\n            ((1,0),(0,1)): ((2,2),(2,2)),\n            ((0,1),(1,0)): ((3,3),(3,3)),\n        }\n        \n        test = np.copy(inp)\n        for i in range(inp.shape[0]-1):\n            for j in range(inp.shape[1]-1):\n                pattern = ((inp[i,j], inp[i,j+1]), \n                          (inp[i+1,j], inp[i+1,j+1]))\n                \n                if pattern in patterns:\n                    replacement = patterns[pattern]\n                    test[i,j] = replacement[0][0]\n                    test[i,j+1] = replacement[0][1]\n                    test[i+1,j] = replacement[1][0]\n                    test[i+1,j+1] = replacement[1][1]\n        \n        if np.array_equal(test, out):\n            return \"\"\"def p(g):\n res=[r[:]for r in g]\n return res\n\"\"\"\n    return None\n\n# ==================== SECTION 10: OBJECT MANIPULATION PATTERNS ====================\n\ndef handle_count_objects(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    labeled, n = label(inp > 0)\n    \n    if out.shape == (1,1) and out[0,0] == n:\n        return \"\"\"def p(g):\n from scipy.ndimage import label\n import numpy as np\n _,n=label(np.array(g)>0)\n return[[n]]\n\"\"\"\n    \n    if np.all(out == n):\n        return f\"\"\"def p(g):\n from scipy.ndimage import label\n import numpy as np\n _,n=label(np.array(g)>0)\n return[[n]*len(g[0])for _ in g]\n\"\"\"\n    return None\n\ndef handle_largest_object(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    labeled, n = label(inp > 0)\n    if n == 0:\n        return None\n    \n    sizes = [(labeled == i).sum() for i in range(1, n+1)]\n    largest = np.argmax(sizes) + 1\n    \n    result = np.where(labeled == largest, inp, 0)\n    \n    if np.array_equal(result, out):\n        return \"\"\"def p(g):\n from scipy.ndimage import label\n import numpy as np\n arr=np.array(g)\n l,n=label(arr>0)\n if n==0:return g\n sizes=[(l==i).sum()for i in range(1,n+1)]\n largest=np.argmax(sizes)+1\n return np.where(l==largest,arr,0).tolist()\n\"\"\"\n    return None\n\ndef handle_move_objects(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    for dy in range(-3, 4):\n        for dx in range(-3, 4):\n            if dy == 0 and dx == 0:\n                continue\n            \n            test = np.zeros_like(inp)\n            h, w = inp.shape\n            \n            for i in range(h):\n                for j in range(w):\n                    if inp[i,j] != 0:\n                        ni, nj = i + dy, j + dx\n                        if 0 <= ni < h and 0 <= nj < w:\n                            test[ni,nj] = inp[i,j]\n            \n            if np.array_equal(test, out):\n                return f\"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    ni,nj=i+{dy},j+{dx}\n    if 0<=ni<h and 0<=nj<w:\n     res[ni][nj]=g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_gravity(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    \n    test = np.zeros_like(inp)\n    for j in range(w):\n        col = inp[:,j]\n        non_zero = col[col != 0]\n        test[h-len(non_zero):,j] = non_zero\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for j in range(w):\n  nz=[g[i][j]for i in range(h)if g[i][j]!=0]\n  for k,v in enumerate(nz):\n   res[h-len(nz)+k][j]=v\n return res\n\"\"\"\n    \n    test = np.zeros_like(inp)\n    for j in range(w):\n        col = inp[:,j]\n        non_zero = col[col != 0]\n        test[:len(non_zero),j] = non_zero\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for j in range(w):\n  nz=[g[i][j]for i in range(h)if g[i][j]!=0]\n  for k,v in enumerate(nz):\n   res[k][j]=v\n return res\n\"\"\"\n    return None\n\ndef handle_connect_same_color(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    test = np.copy(inp)\n    \n    for color in range(1, 10):\n        positions = np.argwhere(inp == color)\n        if len(positions) < 2:\n            continue\n        \n        for i in range(len(positions)):\n            for j in range(i+1, len(positions)):\n                y1, x1 = positions[i]\n                y2, x2 = positions[j]\n                \n                if y1 == y2:\n                    for x in range(min(x1,x2), max(x1,x2)+1):\n                        test[y1,x] = color\n                elif x1 == x2:\n                    for y in range(min(y1,y2), max(y1,y2)+1):\n                        test[y,x1] = color\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n for c in range(1,10):\n  pos=[(i,j)for i in range(len(g))for j in range(len(g[0]))if g[i][j]==c]\n  for i in range(len(pos)):\n   for j in range(i+1,len(pos)):\n    y1,x1=pos[i]\n    y2,x2=pos[j]\n    if y1==y2:\n     for x in range(min(x1,x2),max(x1,x2)+1):\n      res[y1][x]=c\n    elif x1==x2:\n     for y in range(min(y1,y2),max(y1,y2)+1):\n      res[y][x1]=c\n return res\n\"\"\"\n    return None\n\ndef handle_outline_objects(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    edges = np.zeros_like(inp)\n    \n    for i in range(h):\n        for j in range(w):\n            if inp[i,j] != 0:\n                is_edge = False\n                for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n                    ni, nj = i + di, j + dj\n                    if not (0 <= ni < h and 0 <= nj < w) or inp[ni,nj] == 0:\n                        is_edge = True\n                        break\n                if is_edge:\n                    edges[i,j] = inp[i,j]\n    \n    if np.array_equal(edges, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    edge=False\n    for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n     ni,nj=i+di,j+dj\n     if not(0<=ni<h and 0<=nj<w)or g[ni][nj]==0:\n      edge=True\n      break\n    if edge:\n     res[i][j]=g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_fill_objects(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    from scipy.ndimage import binary_fill_holes\n    \n    test = np.copy(inp)\n    for color in range(1, 10):\n        mask = inp == color\n        if np.any(mask):\n            filled = binary_fill_holes(mask)\n            test[filled] = color\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n from scipy.ndimage import binary_fill_holes\n import numpy as np\n t=np.array(g)\n res=t.copy()\n for c in range(1,10):\n  m=t==c\n  if np.any(m):\n   f=binary_fill_holes(m)\n   res[f]=c\n return res.tolist()\n\"\"\"\n    return None\n\ndef handle_object_intersection(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    intersections = np.zeros_like(inp)\n    \n    for i in range(h):\n        for j in range(w):\n            colors = set()\n            for di in range(-1, 2):\n                for dj in range(-1, 2):\n                    ni, nj = i + di, j + dj\n                    if 0 <= ni < h and 0 <= nj < w and inp[ni,nj] != 0:\n                        colors.add(inp[ni,nj])\n            \n            if len(colors) > 1:\n                intersections[i,j] = len(colors)\n    \n    if np.array_equal(intersections, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   c=set()\n   for di in range(-1,2):\n    for dj in range(-1,2):\n     ni,nj=i+di,j+dj\n     if 0<=ni<h and 0<=nj<w and g[ni][nj]!=0:\n      c.add(g[ni][nj])\n   if len(c)>1:\n    res[i][j]=len(c)\n return res\n\"\"\"\n    return None\n\n# ==================== SECTION 11: LINE AND SYMMETRY PATTERNS ====================\n\ndef handle_draw_lines(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    \n    ch, cw = h // 2, w // 2\n    test = np.copy(inp)\n    \n    if h > 0:\n        test[ch,:] = 1\n    if w > 0:\n        test[:,cw] = 1\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[r[:]for r in g]\n if h>0:\n  res[h//2]=[1]*w\n if w>0:\n  for i in range(h):\n   res[i][w//2]=1\n return res\n\"\"\"\n    \n    test = np.copy(inp)\n    for i in range(min(h,w)):\n        test[i,i] = 1\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n for i in range(min(len(g),len(g[0]))):\n  res[i][i]=1\n return res\n\"\"\"\n    return None\n\ndef handle_detect_lines(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    test = np.zeros_like(inp)\n    \n    for i in range(h):\n        if np.all(inp[i,:] == inp[i,0]) and inp[i,0] != 0:\n            test[i,:] = inp[i,0]\n    \n    for j in range(w):\n        if np.all(inp[:,j] == inp[0,j]) and inp[0,j] != 0:\n            test[:,j] = inp[0,j]\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  if all(g[i][j]==g[i][0]for j in range(w))and g[i][0]!=0:\n   res[i]=[g[i][0]]*w\n for j in range(w):\n  if all(g[i][j]==g[0][j]for i in range(h))and g[0][j]!=0:\n   for i in range(h):\n    res[i][j]=g[0][j]\n return res\n\"\"\"\n    return None\n\ndef handle_extend_lines(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    test = np.copy(inp)\n    \n    for i in range(h):\n        segments = []\n        start = None\n        \n        for j in range(w):\n            if inp[i,j] != 0:\n                if start is None:\n                    start = j\n            else:\n                if start is not None:\n                    segments.append((start, j-1, inp[i,start]))\n                    start = None\n        \n        if start is not None:\n            segments.append((start, w-1, inp[i,start]))\n        \n        for s, e, color in segments:\n            if e - s >= 1:\n                test[i,:] = color\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[r[:]for r in g]\n for i in range(h):\n  segs=[]\n  s=None\n  for j in range(w):\n   if g[i][j]!=0:\n    if s is None:\n     s=j\n   else:\n    if s is not None:\n     segs.append((s,j-1,g[i][s]))\n     s=None\n  if s is not None:\n   segs.append((s,w-1,g[i][s]))\n  for s,e,c in segs:\n   if e-s>=1:\n    res[i]=[c]*w\n return res\n\"\"\"\n    return None\n\ndef handle_line_intersection(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    intersections = np.zeros_like(inp)\n    \n    for i in range(1, h-1):\n        for j in range(1, w-1):\n            if inp[i,j] != 0:\n                if (inp[i-1,j] != 0 and inp[i+1,j] != 0 and\n                    inp[i,j-1] != 0 and inp[i,j+1] != 0):\n                    intersections[i,j] = 9\n    \n    if np.array_equal(intersections, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(1,h-1):\n  for j in range(1,w-1):\n   if g[i][j]!=0:\n    if g[i-1][j]!=0 and g[i+1][j]!=0 and g[i][j-1]!=0 and g[i][j+1]!=0:\n     res[i][j]=9\n return res\n\"\"\"\n    return None\n\ndef handle_perpendicular_lines(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    test = np.copy(inp)\n    \n    for i in range(h):\n        for j in range(w):\n            if inp[i,j] != 0:\n                test[i,:] = inp[i,j]\n                test[:,j] = inp[i,j]\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n h,w=len(g),len(g[0])\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    for k in range(w):\n     res[i][k]=g[i][j]\n    for k in range(h):\n     res[k][j]=g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_make_symmetric(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    \n    test = np.copy(inp)\n    for i in range(h//2):\n        test[h-1-i,:] = test[i,:]\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h=len(g)\n res=[r[:]for r in g]\n for i in range(h//2):\n  res[h-1-i]=res[i][:]\n return res\n\"\"\"\n    \n    test = np.copy(inp)\n    for j in range(w//2):\n        test[:,w-1-j] = test[:,j]\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n w=len(g[0])\n res=[r[:]for r in g]\n for i in range(len(g)):\n  for j in range(w//2):\n   res[i][w-1-j]=res[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_complete_pattern(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape == out.shape:\n        h, w = inp.shape\n        \n        test = np.copy(inp)\n        for i in range(h):\n            for j in range(w):\n                if i < j and inp[i,j] != 0:\n                    test[j,i] = inp[i,j]\n                elif i > j and inp[i,j] != 0:\n                    test[j,i] = inp[i,j]\n        \n        if np.array_equal(test, out):\n            return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[r[:]for r in g]\n for i in range(h):\n  for j in range(w):\n   if i<j and g[i][j]!=0:\n    res[j][i]=g[i][j]\n   elif i>j and g[i][j]!=0:\n    res[j][i]=g[i][j]\n return res\n\"\"\"\n    return None\n\ndef handle_find_symmetry_axis(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    \n    is_vsym = True\n    for i in range(h):\n        for j in range(w//2):\n            if inp[i,j] != inp[i,w-1-j]:\n                is_vsym = False\n                break\n    \n    if is_vsym:\n        test = np.copy(inp)\n        test[:,w//2] = 9\n        if np.array_equal(test, out):\n            return \"\"\"def p(g):\n res=[r[:]for r in g]\n w=len(g[0])\n for i in range(len(g)):\n  res[i][w//2]=9\n return res\n\"\"\"\n    return None\n\ndef handle_rotational_symmetry(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape[0] == inp.shape[1] and out.shape == inp.shape:\n        n = inp.shape[0]\n        test = np.copy(inp)\n        \n        for i in range(n):\n            for j in range(n):\n                if inp[i,j] != 0:\n                    test[i,j] = inp[i,j]\n                    test[j,n-1-i] = inp[i,j]\n                    test[n-1-i,n-1-j] = inp[i,j]\n                    test[n-1-j,i] = inp[i,j]\n        \n        if np.array_equal(test, out):\n            return \"\"\"def p(g):\n n=len(g)\n res=[r[:]for r in g]\n for i in range(n):\n  for j in range(n):\n   if g[i][j]!=0:\n    res[i][j]=g[i][j]\n    res[j][n-1-i]=g[i][j]\n    res[n-1-i][n-1-j]=g[i][j]\n    res[n-1-j][i]=g[i][j]\n return res\n\"\"\"\n    return None\n\n# ==================== SECTION 12: CELLULAR AUTOMATA PATTERNS ====================\n\ndef handle_conway_step(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    test = np.zeros_like(inp)\n    \n    for i in range(h):\n        for j in range(w):\n            neighbors = 0\n            for di in [-1, 0, 1]:\n                for dj in [-1, 0, 1]:\n                    if di == 0 and dj == 0:\n                        continue\n                    ni, nj = i + di, j + dj\n                    if 0 <= ni < h and 0 <= nj < w and inp[ni,nj] != 0:\n                        neighbors += 1\n            \n            if inp[i,j] != 0:\n                if neighbors in [2, 3]:\n                    test[i,j] = inp[i,j]\n            else:\n                if neighbors == 3:\n                    test[i,j] = 1\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   n=0\n   for di in[-1,0,1]:\n    for dj in[-1,0,1]:\n     if di==0 and dj==0:continue\n     ni,nj=i+di,j+dj\n     if 0<=ni<h and 0<=nj<w and g[ni][nj]!=0:\n      n+=1\n   if g[i][j]!=0:\n    if n in[2,3]:\n     res[i][j]=g[i][j]\n   else:\n    if n==3:\n     res[i][j]=1\n return res\n\"\"\"\n    return None\n\ndef handle_cellular_automaton(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    \n    test = np.zeros_like(inp)\n    \n    for i in range(h):\n        for j in range(w):\n            color_counts = defaultdict(int)\n            for di in [-1, 0, 1]:\n                for dj in [-1, 0, 1]:\n                    ni, nj = i + di, j + dj\n                    if 0 <= ni < h and 0 <= nj < w:\n                        color_counts[inp[ni,nj]] += 1\n            \n            most_common = max(color_counts.items(), key=lambda x: x[1])[0]\n            test[i,j] = most_common\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   cc={}\n   for di in[-1,0,1]:\n    for dj in[-1,0,1]:\n     ni,nj=i+di,j+dj\n     if 0<=ni<h and 0<=nj<w:\n      c=g[ni][nj]\n      cc[c]=cc.get(c,0)+1\n   mc=max(cc.items(),key=lambda x:x[1])[0]\n   res[i][j]=mc\n return res\n\"\"\"\n    return None\n\ndef handle_voronoi_regions(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    seeds = []\n    h, w = inp.shape\n    for i in range(h):\n        for j in range(w):\n            if inp[i,j] != 0:\n                seeds.append((i, j, inp[i,j]))\n    \n    if not seeds:\n        return None\n    \n    voronoi = np.zeros_like(inp)\n    for i in range(h):\n        for j in range(w):\n            min_dist = float('inf')\n            nearest_color = 0\n            \n            for si, sj, color in seeds:\n                dist = abs(i - si) + abs(j - sj)\n                if dist < min_dist:\n                    min_dist = dist\n                    nearest_color = color\n            \n            voronoi[i,j] = nearest_color\n    \n    if np.array_equal(voronoi, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n s=[]\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    s.append((i,j,g[i][j]))\n v=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   md=999\n   nc=0\n   for si,sj,c in s:\n    d=abs(i-si)+abs(j-sj)\n    if d<md:\n     md=d\n     nc=c\n   v[i][j]=nc\n return v\n\"\"\"\n    return None\n\ndef handle_fractal_generation(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if out.shape[0] == out.shape[1]:\n        n = out.shape[0]\n        test = np.zeros((n, n), dtype=int)\n        \n        for i in range(n):\n            for j in range(i+1):\n                if j == 0 or j == i:\n                    test[i,j] = 1\n                else:\n                    test[i,j] = (test[i-1,j-1] + test[i-1,j]) % 2\n        \n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n n={n}\n t=[[0]*n for _ in range(n)]\n for i in range(n):\n  for j in range(i+1):\n   if j==0 or j==i:\n    t[i][j]=1\n   else:\n    t[i][j]=(t[i-1][j-1]+t[i-1][j])%2\n return t\n\"\"\"\n    return None\n\ndef handle_maze_solve(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    start = np.argwhere(inp == 2)\n    end = np.argwhere(inp == 3)\n    \n    if len(start) == 1 and len(end) == 1:\n        sy, sx = start[0]\n        ey, ex = end[0]\n        \n        h, w = inp.shape\n        visited = set()\n        queue = [(sy, sx, [(sy, sx)])]\n        path = None\n        \n        while queue and not path:\n            y, x, current_path = queue.pop(0)\n            \n            if (y, x) == (ey, ex):\n                path = current_path\n                break\n            \n            if (y, x) in visited:\n                continue\n            visited.add((y, x))\n            \n            for dy, dx in [(0,1), (1,0), (0,-1), (-1,0)]:\n                ny, nx = y + dy, x + dx\n                if (0 <= ny < h and 0 <= nx < w and \n                    inp[ny,nx] != 1 and (ny,nx) not in visited):\n                    queue.append((ny, nx, current_path + [(ny, nx)]))\n        \n        if path:\n            test = np.copy(inp)\n            for y, x in path[1:-1]:\n                test[y,x] = 4\n            \n            if np.array_equal(test, out):\n                return \"\"\"def p(g):\n import numpy as np\n h,w=len(g),len(g[0])\n inp=np.array(g)\n start=np.argwhere(inp==2)\n end=np.argwhere(inp==3)\n if len(start)==1 and len(end)==1:\n  sy,sx=start[0]\n  ey,ex=end[0]\n  visited=set()\n  queue=[(sy,sx,[(sy,sx)])]\n  path=None\n  while queue and not path:\n   y,x,cp=queue.pop(0)\n   if(y,x)==(ey,ex):\n    path=cp\n    break\n   if(y,x)in visited:\n    continue\n   visited.add((y,x))\n   for dy,dx in[(0,1),(1,0),(0,-1),(-1,0)]:\n    ny,nx=y+dy,x+dx\n    if 0<=ny<h and 0<=nx<w and g[ny][nx]!=1 and(ny,nx)not in visited:\n     queue.append((ny,nx,cp+[(ny,nx)]))\n  if path:\n   res=[r[:]for r in g]\n   for y,x in path[1:-1]:\n    res[y][x]=4\n   return res\n return g\n\"\"\"\n    return None\n\ndef handle_path_finding(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    colors = defaultdict(list)\n    h, w = inp.shape\n    \n    for i in range(h):\n        for j in range(w):\n            if inp[i,j] != 0:\n                colors[inp[i,j]].append((i,j))\n    \n    test = np.copy(inp)\n    \n    for color, points in colors.items():\n        if len(points) == 2:\n            (y1, x1), (y2, x2) = points\n            \n            if y1 == y2:\n                for x in range(min(x1,x2), max(x1,x2)+1):\n                    test[y1,x] = color\n            elif x1 == x2:\n                for y in range(min(y1,y2), max(y1,y2)+1):\n                    test[y,x1] = color\n            else:\n                for y in range(min(y1,y2), max(y1,y2)+1):\n                    test[y,x1] = color\n                for x in range(min(x1,x2), max(x1,x2)+1):\n                    test[y2,x] = color\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n from collections import defaultdict\n h,w=len(g),len(g[0])\n colors=defaultdict(list)\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    colors[g[i][j]].append((i,j))\n res=[r[:]for r in g]\n for c,pts in colors.items():\n  if len(pts)==2:\n   (y1,x1),(y2,x2)=pts\n   if y1==y2:\n    for x in range(min(x1,x2),max(x1,x2)+1):\n     res[y1][x]=c\n   elif x1==x2:\n    for y in range(min(y1,y2),max(y1,y2)+1):\n     res[y][x1]=c\n   else:\n    for y in range(min(y1,y2),max(y1,y2)+1):\n     res[y][x1]=c\n    for x in range(min(x1,x2),max(x1,x2)+1):\n     res[y2][x]=c\n return res\n\"\"\"\n    return None\n\n# ==================== SECTION 13: GRID OPERATIONS ====================\n\ndef handle_split_grid(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = inp.shape\n    oh, ow = out.shape\n    \n    if oh == h//2 and ow == w//2:\n        if np.array_equal(inp[:h//2, :w//2], out):\n            return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n return[r[:w//2]for r in g[:h//2]]\n\"\"\"\n        if np.array_equal(inp[:h//2, w//2:], out):\n            return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n return[r[w//2:]for r in g[:h//2]]\n\"\"\"\n        if np.array_equal(inp[h//2:, :w//2], out):\n            return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n return[r[:w//2]for r in g[h//2:]]\n\"\"\"\n        if np.array_equal(inp[h//2:, w//2:], out):\n            return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n return[r[w//2:]for r in g[h//2:]]\n\"\"\"\n    return None\n\ndef handle_merge_grids(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = inp.shape\n    oh, ow = out.shape\n    \n    if oh == 2*h and ow == 2*w:\n        test = np.vstack([\n            np.hstack([inp, inp]),\n            np.hstack([inp, inp])\n        ])\n        if np.array_equal(test, out):\n            return \"\"\"def p(g):\n return[r+r for r in g]+[r+r for r in g]\n\"\"\"\n    return None\n\ndef handle_overlay_grids(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    \n    test = np.copy(inp)\n    for j in range(0, w, 3):\n        test[:,j] = np.where(test[:,j] == 0, 1, test[:,j])\n    for i in range(0, h, 3):\n        test[i,:] = np.where(test[i,:] == 0, 1, test[i,:])\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n res=[r[:]for r in g]\n h,w=len(g),len(g[0])\n for j in range(0,w,3):\n  for i in range(h):\n   if res[i][j]==0:\n    res[i][j]=1\n for i in range(0,h,3):\n  for j in range(w):\n   if res[i][j]==0:\n    res[i][j]=1\n return res\n\"\"\"\n    return None\n\ndef handle_subtract_grids(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    for color in range(1, 10):\n        test = np.where(inp == color, 0, inp)\n        if np.array_equal(test, out):\n            return f\"\"\"def p(g):\n return[[0 if x=={color} else x for x in r]for r in g]\n\"\"\"\n    \n    return None\n\n# ==================== SECTION 14: COMPLEX TRANSFORMATIONS ====================\n\ndef handle_multi_step_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    for rotation in [1, 2, 3]:\n        rotated = np.rot90(inp, rotation)\n        \n        for scale in [2, 3]:\n            if (rotated.shape[0] * scale == out.shape[0] and\n                rotated.shape[1] * scale == out.shape[1]):\n                \n                scaled = np.repeat(np.repeat(rotated, scale, axis=0), scale, axis=1)\n                \n                if np.array_equal(scaled, out):\n                    return f\"\"\"def p(g):\n import numpy as np\n r=np.rot90(g,{rotation})\n return np.repeat(np.repeat(r,{scale},axis=0),{scale},axis=1).tolist()\n\"\"\"\n    return None\n\ndef handle_conditional_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    if inp.shape != out.shape:\n        return None\n    \n    h, w = inp.shape\n    test = np.zeros_like(inp)\n    \n    for i in range(h):\n        for j in range(w):\n            if inp[i,j] != 0:\n                count = 0\n                for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n                    ni, nj = i + di, j + dj\n                    if 0 <= ni < h and 0 <= nj < w and inp[ni,nj] != 0:\n                        count += 1\n                \n                test[i,j] = count + 1\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n h,w=len(g),len(g[0])\n res=[[0]*w for _ in range(h)]\n for i in range(h):\n  for j in range(w):\n   if g[i][j]!=0:\n    c=0\n    for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n     ni,nj=i+di,j+dj\n     if 0<=ni<h and 0<=nj<w and g[ni][nj]!=0:\n      c+=1\n    res[i][j]=c+1\n return res\n\"\"\"\n    return None\n\ndef handle_recursive_transform(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    h, w = inp.shape\n    \n    test = np.copy(inp)\n    changed = True\n    \n    while changed:\n        changed = False\n        for i in range(1, h-1):\n            for j in range(1, w-1):\n                if test[i,j] == 0:\n                    neighbors = [test[i+di,j+dj] for di,dj in [(0,1),(1,0),(0,-1),(-1,0)]]\n                    \n                    if all(n != 0 for n in neighbors):\n                        color_counts = Counter(neighbors)\n                        test[i,j] = color_counts.most_common(1)[0][0]\n                        changed = True\n    \n    if np.array_equal(test, out):\n        return \"\"\"def p(g):\n from collections import Counter\n h,w=len(g),len(g[0])\n res=[r[:]for r in g]\n changed=True\n while changed:\n  changed=False\n  for i in range(1,h-1):\n   for j in range(1,w-1):\n    if res[i][j]==0:\n     n=[res[i+di][j+dj]for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]]\n     if all(x!=0 for x in n):\n      c=Counter(n)\n      res[i][j]=c.most_common(1)[0][0]\n      changed=True\n return res\n\"\"\"\n    return None\n\ndef handle_learned_transform(task_data, analysis):\n    if len(task_data['train']) < 2:\n        return None\n    return None\n\n# ==================== SECTION 15: HELPER FUNCTIONS ====================\n\ndef to_1d_raster(grid, order='row_major'):\n    h, w = len(grid), len(grid[0]) if grid else 0\n    \n    if order == 'row_major':\n        return [grid[i][j] for i in range(h) for j in range(w)]\n    elif order == 'col_major':\n        return [grid[i][j] for j in range(w) for i in range(h)]\n    elif order == 'row_major_rev':\n        return [grid[i][j] for i in range(h-1,-1,-1) for j in range(w-1,-1,-1)]\n    elif order == 'spiral':\n        result = []\n        top, bottom, left, right = 0, h-1, 0, w-1\n        while top <= bottom and left <= right:\n            for j in range(left, right+1):\n                result.append(grid[top][j])\n            top += 1\n            for i in range(top, bottom+1):\n                result.append(grid[i][right])\n            right -= 1\n            if top <= bottom:\n                for j in range(right, left-1, -1):\n                    result.append(grid[bottom][j])\n                bottom -= 1\n            if left <= right:\n                for i in range(bottom, top-1, -1):\n                    result.append(grid[i][left])\n                left += 1\n        return result\n    elif order == 'zigzag':\n        result = []\n        for i in range(h):\n            if i % 2 == 0:\n                result.extend(grid[i])\n            else:\n                result.extend(grid[i][::-1])\n        return result\n    return []\n\ndef from_1d_raster(arr, h, w, order='row_major'):\n    if len(arr) != h * w:\n        return None\n        \n    grid = [[0]*w for _ in range(h)]\n    \n    if order == 'row_major':\n        for idx, val in enumerate(arr):\n            i, j = idx // w, idx % w\n            grid[i][j] = val\n    elif order == 'col_major':\n        for idx, val in enumerate(arr):\n            j, i = idx // h, idx % h\n            grid[i][j] = val\n    elif order == 'row_major_rev':\n        for idx, val in enumerate(arr):\n            i, j = (h-1) - idx // w, (w-1) - idx % w\n            grid[i][j] = val\n    elif order == 'spiral':\n        idx = 0\n        top, bottom, left, right = 0, h-1, 0, w-1\n        while top <= bottom and left <= right and idx < len(arr):\n            for j in range(left, right+1):\n                if idx < len(arr):\n                    grid[top][j] = arr[idx]\n                    idx += 1\n            top += 1\n            for i in range(top, bottom+1):\n                if idx < len(arr):\n                    grid[i][right] = arr[idx]\n                    idx += 1\n            right -= 1\n            if top <= bottom:\n                for j in range(right, left-1, -1):\n                    if idx < len(arr):\n                        grid[bottom][j] = arr[idx]\n                        idx += 1\n                bottom -= 1\n            if left <= right:\n                for i in range(bottom, top-1, -1):\n                    if idx < len(arr):\n                        grid[i][left] = arr[idx]\n                        idx += 1\n                left += 1\n    elif order == 'zigzag':\n        idx = 0\n        for i in range(h):\n            if i % 2 == 0:\n                for j in range(w):\n                    grid[i][j] = arr[idx]\n                    idx += 1\n            else:\n                for j in range(w-1, -1, -1):\n                    grid[i][j] = arr[idx]\n                    idx += 1\n    \n    return grid\n\n# ==================== SECTION 16: BASIC PATTERNS ====================\n\ndef handle_empty_input(task_data, analysis):\n    inp = np.array(task_data['train'][0]['input'])\n    out = np.array(task_data['train'][0]['output'])\n    \n    if inp.size == 0 or inp.shape[0] == 0:\n        return f\"\"\"def p(g):\n return {out.tolist()}\n\"\"\"\n    return None\n\ndef handle_identity(task_data, analysis):\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(inp, out):\n        return \"\"\"def p(g):\n return g\n\"\"\"\n    return None\n\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport os\nimport zipfile\nimport numpy as np\nfrom collections import defaultdict, Counter\nfrom scipy.ndimage import label, binary_dilation, binary_erosion, convolve\nfrom itertools import product, permutations, combinations\nimport math\nimport time\nfrom functools import lru_cache\nfrom typing import Dict, List, Tuple, Optional, Callable\n\n# Configuration\nDEBUG_MODE = True\nDEBUG_LOG = []\nPERFORMANCE_STATS = defaultdict(lambda: {'calls': 0, 'successes': 0, 'total_time': 0})\nHANDLER_CACHE = {}\n\ndef debug_print(msg, level=\"INFO\"):\n    \"\"\"Enhanced debug printing with levels and timing\"\"\"\n    if DEBUG_MODE:\n        timestamp = time.strftime(\"%H:%M:%S\")\n        formatted_msg = f\"[{timestamp}] [{level}] {msg}\"\n        print(formatted_msg)\n        DEBUG_LOG.append(formatted_msg)\n\ndef cache_key(task_data):\n    \"\"\"Generate a cache key for task data\"\"\"\n    inp = np.array(task_data['train'][0]['input'])\n    out = np.array(task_data['train'][0]['output'])\n    return f\"{inp.shape}_{out.shape}_{hash(inp.tobytes())}_{hash(out.tobytes())}\"\n\ndef extract_function_body(solution_code):\n    \"\"\"Extract the function body from a solution string\"\"\"\n    lines = solution_code.strip().split('\\n')\n    if not lines or not lines[0].startswith('def p(g):'):\n        return \"\"\n    body_lines = []\n    for line in lines[1:]:\n        if line.startswith(' '):\n            body_lines.append(line[1:])\n    return '\\n'.join(body_lines)\n\ndef indent_code(code, spaces):\n    \"\"\"Indent code by specified spaces\"\"\"\n    return '\\n'.join(' ' * spaces + line for line in code.split('\\n'))\n\ndef timed_handler(func):\n    \"\"\"Decorator to time handler execution\"\"\"\n    def wrapper(task_data, analysis):\n        start_time = time.time()\n        result = None\n        try:\n            result = func(task_data, analysis)\n            success = result is not None\n        except Exception as e:\n            success = False\n            debug_print(f\"Handler {func.__name__} failed: {str(e)}\", \"ERROR\")\n        \n        elapsed = time.time() - start_time\n        PERFORMANCE_STATS[func.__name__]['calls'] += 1\n        PERFORMANCE_STATS[func.__name__]['total_time'] += elapsed\n        if success:\n            PERFORMANCE_STATS[func.__name__]['successes'] += 1\n        \n        return result\n    return wrapper\n\ndef analyze_task(task_data):\n    \"\"\"Analyze task to extract patterns and features\"\"\"\n    all_examples = task_data['train'] + task_data['test']\n    analysis = {\n        'color_changes': defaultdict(set),\n        'shape_changes': set(),\n        'symmetry': None,\n        'arithmetic': None,\n        'pattern_types': set(),\n        'color_count': set(),\n        'has_objects': False,\n        'has_lines': False,\n        'has_repeating_patterns': False,\n    }\n    \n    for example in all_examples:\n        in_grid = np.array(example['input'])\n        out_grid = np.array(example['output'])\n        \n        analysis['shape_changes'].add((in_grid.shape, out_grid.shape))\n        analysis['color_count'].add(len(np.unique(in_grid)))\n        \n        if len(np.unique(in_grid)) > 2:\n            analysis['has_objects'] = True\n        \n        for i in range(in_grid.shape[0]):\n            if len(np.unique(in_grid[i,:])) == 1 and in_grid[i,0] != 0:\n                analysis['has_lines'] = True\n        \n        for (i,j), val in np.ndenumerate(in_grid):\n            if i < out_grid.shape[0] and j < out_grid.shape[1]:\n                if in_grid[i,j] != out_grid[i,j]:\n                    analysis['color_changes'][(i,j)].add((int(in_grid[i,j]), int(out_grid[i,j])))\n    \n    return analysis\n\ndef verify_solution(solution_code, task_data):\n    \"\"\"Verify solution against all training examples\"\"\"\n    try:\n        local_namespace = {}\n        exec(solution_code, globals(), local_namespace)\n        \n        if 'p' not in local_namespace:\n            return False\n        \n        p = local_namespace['p']\n        \n        for idx, example in enumerate(task_data['train']):\n            input_grid = example['input']\n            expected = example['output']\n            try:\n                actual = p(input_grid)\n                if actual != expected:\n                    return False\n            except Exception as e:\n                return False\n        return True\n    except Exception as e:\n        return False\n\n# Basic transformation handlers\n@timed_handler\ndef handle_identity(task_data, analysis):\n    \"\"\"Check if output equals input\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(inp, out):\n        return \"\"\"def p(g):\n return g\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_rotate_90(task_data, analysis):\n    \"\"\"Rotate 90 degrees clockwise\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(np.rot90(inp, -1), out):\n        return \"\"\"def p(g):\n return[list(r)for r in zip(*g[::-1])]\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_rotate_180(task_data, analysis):\n    \"\"\"Rotate 180 degrees\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(np.rot90(inp, 2), out):\n        return \"\"\"def p(g):\n return[r[::-1]for r in g[::-1]]\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_rotate_270(task_data, analysis):\n    \"\"\"Rotate 270 degrees clockwise\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(np.rot90(inp, 1), out):\n        return \"\"\"def p(g):\n return[list(r)for r in zip(*g)][::-1]\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_flip_horizontal(task_data, analysis):\n    \"\"\"Flip horizontally\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(np.fliplr(inp), out):\n        return \"\"\"def p(g):\n return[r[::-1]for r in g]\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_flip_vertical(task_data, analysis):\n    \"\"\"Flip vertically\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(np.flipud(inp), out):\n        return \"\"\"def p(g):\n return g[::-1]\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_transpose(task_data, analysis):\n    \"\"\"Transpose matrix\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    if np.array_equal(inp.T, out):\n        return \"\"\"def p(g):\n return[list(r)for r in zip(*g)]\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_color_mapping(task_data, analysis):\n    \"\"\"Map colors based on consistent changes\"\"\"\n    color_map = {}\n    for pos, changes in analysis['color_changes'].items():\n        if len(changes) == 1:\n            src, dest = next(iter(changes))\n            if src not in color_map:\n                color_map[src] = dest\n            elif color_map[src] != dest:\n                return None\n    \n    if not color_map:\n        return None\n    \n    cases = ','.join([f'{int(s)}:{int(d)}' for s,d in color_map.items()])\n    return f\"\"\"def p(g):\n m={{{cases}}}\n return[[m.get(x,x)for x in r]for r in g]\n\"\"\"\n\n@timed_handler\ndef handle_upscale(task_data, analysis):\n    \"\"\"Scale up the grid\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    for h_scale in range(1, 4):\n        for w_scale in range(1, 4):\n            if (inp.shape[0]*h_scale == out.shape[0] and \n                inp.shape[1]*w_scale == out.shape[1]):\n                test = np.repeat(np.repeat(inp, h_scale, axis=0), w_scale, axis=1)\n                if np.array_equal(test, out):\n                    return f\"\"\"def p(g):\n return[[x for x in row for _ in range({w_scale})]\n        for row in g for _ in range({h_scale})]\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_downscale(task_data, analysis):\n    \"\"\"Scale down the grid\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    for h_scale in range(2, 5):\n        for w_scale in range(2, 5):\n            if (inp.shape[0]//h_scale == out.shape[0] and \n                inp.shape[1]//w_scale == out.shape[1]):\n                test = inp[::h_scale, ::w_scale]\n                if np.array_equal(test, out):\n                    return f\"\"\"def p(g):\n return[row[::{w_scale}]for row in g[::{h_scale}]]\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_tile_pattern(task_data, analysis):\n    \"\"\"Tile a pattern to create output\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    ih, iw = inp.shape\n    oh, ow = out.shape\n    \n    for th in range(1, min(ih+1, 5)):\n        for tw in range(1, min(iw+1, 5)):\n            if oh % th == 0 and ow % tw == 0:\n                tile = inp[:th, :tw]\n                tiled = np.tile(tile, (oh//th, ow//tw))\n                \n                if np.array_equal(tiled, out):\n                    return f\"\"\"def p(g):\n tile=[r[:{tw}]for r in g[:{th}]]\n h,w={oh},{ow}\n res=[]\n for i in range(h):\n  row=[]\n  for j in range(w):\n   row.append(tile[i%{th}][j%{tw}])\n  res.append(row)\n return res\n\"\"\"\n    return None\n\n@timed_handler\ndef handle_crop_to_content(task_data, analysis):\n    \"\"\"Crop grid to non-zero content\"\"\"\n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    rows, cols = np.where(inp > 0)\n    if len(rows) == 0:\n        return None\n        \n    min_row, max_row = rows.min(), rows.max()\n    min_col, max_col = cols.min(), cols.max()\n    \n    cropped = inp[min_row:max_row+1, min_col:max_col+1]\n    \n    if np.array_equal(cropped, out):\n        return \"\"\"def p(g):\n rows,cols=[],[]\n for i in range(len(g)):\n  for j in range(len(g[0])):\n   if g[i][j]>0:\n    rows.append(i)\n    cols.append(j)\n if not rows:return g\n r0,r1=min(rows),max(rows)+1\n c0,c1=min(cols),max(cols)+1\n return[r[c0:c1]for r in g[r0:r1]]\n\"\"\"\n    return None\n\n# Enhanced pattern detection\nclass PatternLearner:\n    \"\"\"Learn which handlers work for which patterns\"\"\"\n    def __init__(self):\n        self.handler_success_patterns = defaultdict(lambda: defaultdict(int))\n        self.pattern_features = {}\n        self.global_successes = defaultdict(int)\n        \n    def extract_features(self, task_data):\n        \"\"\"Extract features from task\"\"\"\n        inp = np.array(task_data['train'][0]['input'])\n        out = np.array(task_data['train'][0]['output'])\n        \n        features = {\n            'shape_change': inp.shape != out.shape,\n            'size_ratio': (out.size / inp.size) if inp.size > 0 else 1,\n            'color_count_in': len(np.unique(inp)),\n            'color_count_out': len(np.unique(out)),\n            'has_symmetry': self.check_symmetry(inp),\n            'has_pattern': self.check_pattern(inp),\n            'density': np.sum(inp != 0) / inp.size if inp.size > 0 else 0,\n            'shape_aspect': inp.shape[0] / inp.shape[1] if inp.shape[1] > 0 else 1,\n        }\n        \n        return features\n    \n    def check_symmetry(self, grid):\n        \"\"\"Check if grid has symmetry\"\"\"\n        return (np.array_equal(grid, np.fliplr(grid)) or \n                np.array_equal(grid, np.flipud(grid)) or\n                (grid.shape[0] == grid.shape[1] and np.array_equal(grid, grid.T)))\n    \n    def check_pattern(self, grid):\n        \"\"\"Check if grid has repeating pattern\"\"\"\n        h, w = grid.shape\n        for ph in range(1, min(h//2 + 1, 5)):\n            for pw in range(1, min(w//2 + 1, 5)):\n                if h % ph == 0 and w % pw == 0:\n                    pattern = grid[:ph, :pw]\n                    tiled = np.tile(pattern, (h//ph, w//pw))\n                    if np.array_equal(grid, tiled):\n                        return True\n        return False\n    \n    def update_success(self, handler_name, features, success):\n        \"\"\"Update handler success for given features\"\"\"\n        feature_key = tuple(sorted(features.items()))\n        self.handler_success_patterns[handler_name][feature_key] += (1 if success else -0.1)\n        if success:\n            self.global_successes[handler_name] += 1\n    \n    def get_handler_priority(self, features, handlers):\n        \"\"\"Get handlers prioritized by past success\"\"\"\n        feature_key = tuple(sorted(features.items()))\n        \n        scores = []\n        for handler in handlers:\n            # Combine feature-specific score with global success rate\n            feature_score = self.handler_success_patterns[handler.__name__][feature_key]\n            global_score = self.global_successes[handler.__name__] * 0.1\n            total_score = feature_score + global_score + np.random.normal(0, 0.05)\n            scores.append((total_score, handler))\n        \n        scores.sort(reverse=True, key=lambda x: x[0])\n        return [handler for _, handler in scores]\n\ndef get_all_pattern_handlers():\n    \"\"\"Get all available pattern handlers in priority order\"\"\"\n    # Import handlers from the main file\n    from paste import (\n        handle_1d_raster_transform, handle_1d_pattern_repeat, handle_1d_sort_colors,\n        handle_1d_run_length_decode, handle_1d_reverse_segments, handle_1d_shuffle_pattern,\n        handle_1d_wave_transform, handle_1d_compression, handle_1d_periodic_transform,\n        handle_1d_fibonacci_transform, handle_1d_prime_positions, handle_1d_alternating_ops,\n        handle_diagonal_linearization, handle_hilbert_curve, handle_morton_order,\n        handle_block_linearization, handle_snake_pattern, handle_radial_linearization,\n        handle_odd_even_rows, handle_odd_even_cols, handle_checkerboard_transform,\n        handle_parity_coloring, handle_alternating_blocks, handle_modular_arithmetic,\n        handle_xor_patterns, handle_binary_operations, handle_bit_manipulation,\n        handle_arithmetic_sequences, handle_geometric_sequences, handle_template_matching,\n        handle_convolution_patterns, handle_morphological_ops, handle_edge_detection_advanced,\n        handle_corner_detection, handle_pattern_completion_advanced, handle_graph_coloring,\n        handle_tree_traversal, handle_component_labeling, handle_color_gradients,\n        handle_color_mixing, handle_palette_reduction, handle_color_quantization,\n        handle_color_spreading, handle_color_waves, handle_color_count,\n        handle_color_frequency_sort, handle_replace_most_common, handle_color_propagation,\n        handle_flood_fill, handle_repeat_pattern, handle_mirror_pattern,\n        handle_extract_pattern, handle_apply_mask, handle_pattern_substitution,\n        handle_count_objects, handle_largest_object, handle_move_objects,\n        handle_gravity, handle_connect_same_color, handle_outline_objects,\n        handle_fill_objects, handle_object_intersection, handle_draw_lines,\n        handle_detect_lines, handle_extend_lines, handle_line_intersection,\n        handle_perpendicular_lines, handle_make_symmetric, handle_complete_pattern,\n        handle_find_symmetry_axis, handle_rotational_symmetry, handle_conway_step,\n        handle_cellular_automaton, handle_voronoi_regions, handle_fractal_generation,\n        handle_maze_solve, handle_path_finding, handle_multi_step_transform,\n        handle_conditional_transform, handle_recursive_transform, handle_split_grid,\n        handle_merge_grids, handle_overlay_grids, handle_subtract_grids,\n        handle_empty_input, handle_rotate_45, handle_shear_transform,\n        handle_pad_to_square, handle_zoom_center, handle_aspect_ratio_change\n    )\n    \n    # Basic handlers implemented above\n    basic_handlers = [\n        handle_identity,\n        handle_rotate_90,\n        handle_rotate_180,\n        handle_rotate_270,\n        handle_flip_horizontal,\n        handle_flip_vertical,\n        handle_transpose,\n        handle_color_mapping,\n        handle_upscale,\n        handle_downscale,\n        handle_tile_pattern,\n        handle_crop_to_content,\n    ]\n    \n    # Import all handlers from paste file\n    imported_handlers = [\n        handle_1d_raster_transform, handle_1d_pattern_repeat, handle_1d_sort_colors,\n        handle_1d_run_length_decode, handle_1d_reverse_segments, handle_1d_shuffle_pattern,\n        handle_1d_wave_transform, handle_1d_compression, handle_1d_periodic_transform,\n        handle_1d_fibonacci_transform, handle_1d_prime_positions, handle_1d_alternating_ops,\n        handle_diagonal_linearization, handle_hilbert_curve, handle_morton_order,\n        handle_block_linearization, handle_snake_pattern, handle_radial_linearization,\n        handle_odd_even_rows, handle_odd_even_cols, handle_checkerboard_transform,\n        handle_parity_coloring, handle_alternating_blocks, handle_modular_arithmetic,\n        handle_xor_patterns, handle_binary_operations, handle_bit_manipulation,\n        handle_arithmetic_sequences, handle_geometric_sequences, handle_template_matching,\n        handle_convolution_patterns, handle_morphological_ops, handle_edge_detection_advanced,\n        handle_corner_detection, handle_pattern_completion_advanced, handle_graph_coloring,\n        handle_tree_traversal, handle_component_labeling, handle_color_gradients,\n        handle_color_mixing, handle_palette_reduction, handle_color_quantization,\n        handle_color_spreading, handle_color_waves, handle_color_count,\n        handle_color_frequency_sort, handle_replace_most_common, handle_color_propagation,\n        handle_flood_fill, handle_repeat_pattern, handle_mirror_pattern,\n        handle_extract_pattern, handle_apply_mask, handle_pattern_substitution,\n        handle_count_objects, handle_largest_object, handle_move_objects,\n        handle_gravity, handle_connect_same_color, handle_outline_objects,\n        handle_fill_objects, handle_object_intersection, handle_draw_lines,\n        handle_detect_lines, handle_extend_lines, handle_line_intersection,\n        handle_perpendicular_lines, handle_make_symmetric, handle_complete_pattern,\n        handle_find_symmetry_axis, handle_rotational_symmetry, handle_conway_step,\n        handle_cellular_automaton, handle_voronoi_regions, handle_fractal_generation,\n        handle_maze_solve, handle_path_finding, handle_multi_step_transform,\n        handle_conditional_transform, handle_recursive_transform, handle_split_grid,\n        handle_merge_grids, handle_overlay_grids, handle_subtract_grids,\n        handle_empty_input, handle_rotate_45, handle_shear_transform,\n        handle_pad_to_square, handle_zoom_center, handle_aspect_ratio_change\n    ]\n    \n    # Combine all handlers\n    return basic_handlers + imported_handlers\n\ndef analyze_task_advanced(task_data):\n    \"\"\"Advanced task analysis with pattern detection\"\"\"\n    analysis = analyze_task(task_data)\n    \n    inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n    analysis['transform_type'] = set()\n    \n    # Shape transformations\n    if inp.shape != out.shape:\n        if out.shape[0] > inp.shape[0] or out.shape[1] > inp.shape[1]:\n            analysis['transform_type'].add('expansion')\n        else:\n            analysis['transform_type'].add('reduction')\n    \n    # Rotation detection\n    if inp.shape == out.shape:\n        for k in range(1, 4):\n            if np.array_equal(np.rot90(inp, k), out):\n                analysis['transform_type'].add(f'rotation_{k*90}')\n        \n        if np.array_equal(np.fliplr(inp), out):\n            analysis['transform_type'].add('mirror_horizontal')\n        if np.array_equal(np.flipud(inp), out):\n            analysis['transform_type'].add('mirror_vertical')\n    \n    # Pattern detection\n    if out.shape[0] % inp.shape[0] == 0 and out.shape[1] % inp.shape[1] == 0:\n        analysis['transform_type'].add('tiling')\n    \n    # Color mapping detection\n    unique_in = set(inp.flatten())\n    unique_out = set(out.flatten())\n    if len(unique_in) == len(unique_out) and unique_in != unique_out:\n        analysis['transform_type'].add('color_mapping')\n    \n    return analysis\n\ndef try_handler_combinations(task_data, handlers, max_depth=2):\n    \"\"\"Try combining multiple handlers\"\"\"\n    inp = np.array(task_data['train'][0]['input'])\n    out = np.array(task_data['train'][0]['output'])\n    \n    # Try single handlers first\n    for handler in handlers[:30]:\n        try:\n            solution = handler(task_data, {})\n            if solution and verify_solution(solution, task_data):\n                return solution\n        except:\n            pass\n    \n    # Try two-step combinations\n    if max_depth >= 2:\n        for h1 in handlers[:20]:\n            try:\n                sol1 = h1(task_data, {})\n                if sol1:\n                    # Apply first transformation\n                    local_ns = {}\n                    exec(sol1, globals(), local_ns)\n                    if 'p' in local_ns:\n                        intermediate = local_ns['p'](inp.tolist())\n                        \n                        # Create new task with intermediate result\n                        new_task = {\n                            'train': [{'input': intermediate, 'output': out.tolist()}],\n                            'test': []\n                        }\n                        \n                        # Try second transformation\n                        for h2 in handlers[:20]:\n                            try:\n                                sol2 = h2(new_task, {})\n                                if sol2:\n                                    combined = create_combination(sol1, sol2, h1.__name__, h2.__name__)\n                                    if verify_solution(combined, task_data):\n                                        return combined\n                            except:\n                                pass\n            except:\n                pass\n    \n    return None\n\ndef create_combination(sol1, sol2, name1, name2):\n    \"\"\"Create combined solution\"\"\"\n    body1 = extract_function_body(sol1)\n    body2 = extract_function_body(sol2)\n    \n    return f\"\"\"def p(g):\n # {name1}\n def t1(g):\n{indent_code(body1, 2)}\n # {name2}\n def t2(g):\n{indent_code(body2, 2)}\n return t2(t1(g))\n\"\"\"\n\ndef generate_solution_ultra(task_data, learner):\n    \"\"\"Ultra-enhanced solution generation\"\"\"\n    analysis = analyze_task_advanced(task_data)\n    \n    # Get all handlers\n    all_handlers = get_all_pattern_handlers()\n    \n    # Check cache\n    key = cache_key(task_data)\n    if key in HANDLER_CACHE:\n        return HANDLER_CACHE[key]\n    \n    # Extract features for learning\n    features = learner.extract_features(task_data)\n    \n    # Get prioritized handlers\n    handlers = learner.get_handler_priority(features, all_handlers)\n    \n    # Phase 1: Try single handlers with priority\n    debug_print(\"Phase 1: Trying prioritized single handlers\", \"INFO\")\n    for i, handler in enumerate(handlers):\n        if i > 50 and PERFORMANCE_STATS[handler.__name__]['successes'] == 0:\n            continue  # Skip handlers that have never worked\n        \n        try:\n            solution = handler(task_data, analysis)\n            if solution and verify_solution(solution, task_data):\n                debug_print(f\" Found solution with {handler.__name__}\", \"SUCCESS\")\n                learner.update_success(handler.__name__, features, True)\n                HANDLER_CACHE[key] = solution\n                return solution\n            elif solution:\n                learner.update_success(handler.__name__, features, False)\n        except:\n            pass\n    \n    # Phase 2: Try combinations\n    debug_print(\"Phase 2: Trying handler combinations\", \"INFO\")\n    combination = try_handler_combinations(task_data, handlers, max_depth=2)\n    if combination:\n        HANDLER_CACHE[key] = combination\n        return combination\n    \n    # Fallback\n    fallback = \"\"\"def p(g):\n return g\n\"\"\"\n    HANDLER_CACHE[key] = fallback\n    return fallback\n\ndef create_arc_solutions_ultra(input_dir=\".\", output_dir=\"submission\"):\n    \"\"\"Main execution with learning and optimization\"\"\"\n    solutions = {}\n    os.makedirs(output_dir, exist_ok=True)\n    \n    # Initialize learner\n    learner = PatternLearner()\n    \n    solved_count = 0\n    total_count = 0\n    start_time = time.time()\n    \n    # Process all tasks\n    for task_num in range(1, 401):\n        task_id = f\"{task_num:03d}\"\n        task_file = os.path.join(input_dir, f\"task{task_id}.json\")\n        \n        try:\n            with open(task_file) as f:\n                task_data = json.load(f)\n            \n            # Generate solution\n            solution = generate_solution_ultra(task_data, learner)\n            solutions[task_id] = solution\n            \n            # Verify and update statistics\n            if verify_solution(solution, task_data):\n                print(f\" Task {task_id} solved\")\n                solved_count += 1\n            else:\n                print(f\" Task {task_id} fallback\")\n            \n            total_count += 1\n            \n        except Exception as e:\n            print(f\"Error task {task_id}: {str(e)}\")\n            solutions[task_id] = \"\"\"def p(g):\n return g\n\"\"\"\n            total_count += 1\n    \n    # Save solutions\n    for task_id, code in solutions.items():\n        output_file = os.path.join(output_dir, f\"task{task_id}.py\")\n        with open(output_file, \"w\") as f:\n            f.write(code)\n    \n    # Create submission\n    with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n        for task_id in solutions:\n            file_path = os.path.join(output_dir, f\"task{task_id}.py\")\n            zipf.write(file_path, f\"task{task_id}.py\")\n    \n    # Print results\n    total_time = time.time() - start_time\n    print(f\"\\n{'='*60}\")\n    print(f\"FINAL RESULTS\")\n    print(f\"{'='*60}\")\n    print(f\" Solved: {solved_count}/{total_count} ({solved_count/total_count*100:.1f}%)\")\n    print(f\"  Time: {total_time:.1f}s ({total_time/total_count:.2f}s per task)\")\n    \n    # Performance statistics\n    if PERFORMANCE_STATS:\n        print(f\"\\nTop handlers by success:\")\n        sorted_handlers = sorted(\n            [(k, v) for k, v in PERFORMANCE_STATS.items() if v['successes'] > 0],\n            key=lambda x: x[1]['successes'],\n            reverse=True\n        )[:10]\n        \n        for name, stats in sorted_handlers:\n            success_rate = stats['successes'] / stats['calls'] * 100 if stats['calls'] > 0 else 0\n            print(f\"  {name}: {stats['successes']} ({success_rate:.1f}%)\")\n    \n    print(f\"\\n Created: submission.zip\")\n\nif __name__ == \"__main__\":\n    create_arc_solutions_ultra()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import time\n# from functools import lru_cache\n# from typing import Dict, List, Tuple, Optional, Callable\n# import numpy as np\n# from collections import defaultdict, Counter\n# import json\n# import os\n# import zipfile\n\n# DEBUG_MODE = True\n# DEBUG_LOG = []\n# PERFORMANCE_STATS = defaultdict(lambda: {'calls': 0, 'successes': 0, 'total_time': 0})\n# HANDLER_CACHE = {}\n\n# def debug_print(msg, level=\"INFO\"):\n#     if DEBUG_MODE:\n#         timestamp = time.strftime(\"%H:%M:%S\")\n#         formatted_msg = f\"[{timestamp}] [{level}] {msg}\"\n#         print(formatted_msg)\n#         DEBUG_LOG.append(formatted_msg)\n\n# def cache_key(task_data):\n#     inp = np.array(task_data['train'][0]['input'])\n#     out = np.array(task_data['train'][0]['output'])\n#     return f\"{inp.shape}_{out.shape}_{hash(inp.tobytes())}_{hash(out.tobytes())}\"\n\n# def extract_function_body(solution_code):\n#     lines = solution_code.strip().split('\\n')\n#     if not lines or not lines[0].startswith('def p(g):'):\n#         return \"\"\n#     body_lines = []\n#     for line in lines[1:]:\n#         if line.startswith(' '):\n#             body_lines.append(line[1:])\n#     return '\\n'.join(body_lines)\n\n# def indent_code(code, spaces):\n#     return '\\n'.join(' ' * spaces + line for line in code.split('\\n'))\n\n# def timed_handler(func):\n#     def wrapper(task_data, analysis):\n#         start_time = time.time()\n#         result = None\n#         try:\n#             result = func(task_data, analysis)\n#             success = result is not None\n#         except Exception as e:\n#             success = False\n#             debug_print(f\"Handler {func.__name__} failed: {str(e)}\", \"ERROR\")\n        \n#         elapsed = time.time() - start_time\n#         PERFORMANCE_STATS[func.__name__]['calls'] += 1\n#         PERFORMANCE_STATS[func.__name__]['total_time'] += elapsed\n#         if success:\n#             PERFORMANCE_STATS[func.__name__]['successes'] += 1\n        \n#         return result\n#     return wrapper\n\n# def analyze_task(task_data):\n#     all_examples = task_data['train'] + task_data['test']\n#     analysis = {\n#         'color_changes': defaultdict(set),\n#         'shape_changes': set(),\n#         'symmetry': None,\n#         'arithmetic': None,\n#         'pattern_types': set(),\n#         'color_count': set(),\n#         'has_objects': False,\n#         'has_lines': False,\n#         'has_repeating_patterns': False,\n#     }\n    \n#     for example in all_examples:\n#         in_grid = np.array(example['input'])\n#         out_grid = np.array(example['output'])\n        \n#         analysis['shape_changes'].add((in_grid.shape, out_grid.shape))\n#         analysis['color_count'].add(len(np.unique(in_grid)))\n        \n#         if len(np.unique(in_grid)) > 2:\n#             analysis['has_objects'] = True\n        \n#         for i in range(in_grid.shape[0]):\n#             if len(np.unique(in_grid[i,:])) == 1 and in_grid[i,0] != 0:\n#                 analysis['has_lines'] = True\n        \n#         for (i,j), val in np.ndenumerate(in_grid):\n#             if i < out_grid.shape[0] and j < out_grid.shape[1]:\n#                 if in_grid[i,j] != out_grid[i,j]:\n#                     analysis['color_changes'][(i,j)].add((int(in_grid[i,j]), int(out_grid[i,j])))\n    \n#     return analysis\n\n# def verify_solution(solution_code, task_data):\n#     try:\n#         local_namespace = {}\n#         exec(solution_code, globals(), local_namespace)\n        \n#         if 'p' not in local_namespace:\n#             return False\n        \n#         p = local_namespace['p']\n        \n#         for idx, example in enumerate(task_data['train']):\n#             input_grid = example['input']\n#             expected = example['output']\n#             try:\n#                 actual = p(input_grid)\n#                 if actual != expected:\n#                     debug_print(f\"  Failed on training example {idx}\", \"WARNING\")\n#                     return False\n#             except Exception as e:\n#                 debug_print(f\"  Exception on training example {idx}: {str(e)}\", \"ERROR\")\n#                 return False\n#         return True\n#     except Exception as e:\n#         debug_print(f\"  Verification failed: {str(e)}\", \"ERROR\")\n#         return False\n\n# def get_existing_handlers():\n#     return []\n\n# def handle_rotate_90(task_data, analysis):\n#     return None\n\n# def handle_rotate_180(task_data, analysis):\n#     return None\n\n# def handle_rotate_270(task_data, analysis):\n#     return None\n\n# def handle_flip_horizontal(task_data, analysis):\n#     return None\n\n# def handle_flip_vertical(task_data, analysis):\n#     return None\n\n# def handle_tile_pattern(task_data, analysis):\n#     return None\n\n# def handle_repeat_pattern(task_data, analysis):\n#     return None\n\n# def handle_upscale(task_data, analysis):\n#     return None\n\n# def handle_pad_to_square(task_data, analysis):\n#     return None\n\n# def handle_border_operations(task_data, analysis):\n#     return None\n\n# def handle_downscale(task_data, analysis):\n#     return None\n\n# def handle_crop_to_content(task_data, analysis):\n#     return None\n\n# def handle_extract_pattern(task_data, analysis):\n#     return None\n\n# def handle_color_mapping(task_data, analysis):\n#     return None\n\n# def handle_layered_transform(task_data, analysis):\n#     return None\n\n# def handle_color_cycle(task_data, analysis):\n#     return None\n\n# def analyze_task_advanced(task_data):\n#     analysis = analyze_task(task_data)\n    \n#     inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n#     analysis['transform_type'] = set()\n    \n#     if inp.shape != out.shape:\n#         if out.shape[0] > inp.shape[0] or out.shape[1] > inp.shape[1]:\n#             analysis['transform_type'].add('expansion')\n#         else:\n#             analysis['transform_type'].add('reduction')\n            \n#     if inp.shape == out.shape:\n#         for k in range(1, 4):\n#             if np.array_equal(np.rot90(inp, k), out):\n#                 analysis['transform_type'].add(f'rotation_{k*90}')\n                \n#         if np.array_equal(np.fliplr(inp), out):\n#             analysis['transform_type'].add('mirror_horizontal')\n#         if np.array_equal(np.flipud(inp), out):\n#             analysis['transform_type'].add('mirror_vertical')\n            \n#     if out.shape[0] % inp.shape[0] == 0 and out.shape[1] % inp.shape[1] == 0:\n#         analysis['transform_type'].add('tiling')\n        \n#     unique_in = set(inp.flatten())\n#     unique_out = set(out.flatten())\n#     if len(unique_in) == len(unique_out) and unique_in != unique_out:\n#         analysis['transform_type'].add('color_mapping')\n        \n#     analysis['recommended_handlers'] = recommend_handlers(analysis)\n    \n#     return analysis\n\n# @timed_handler\n# def handle_recursive_pattern_completion(task_data, analysis):\n#     debug_print(f\"Trying handle_recursive_pattern_completion\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             def apply_rules(grid):\n#                 changed = False\n#                 new_grid = np.copy(grid)\n                \n#                 for i in range(1, h-1):\n#                     for j in range(1, w-1):\n#                         if grid[i,j] == 0:\n#                             neighbors = [grid[i-1,j], grid[i+1,j], grid[i,j-1], grid[i,j+1]]\n#                             if len(set(neighbors)) == 1 and neighbors[0] != 0:\n#                                 new_grid[i,j] = neighbors[0]\n#                                 changed = True\n                                \n#                 for i in range(h-2):\n#                     for j in range(w-2):\n#                         pattern = grid[i:i+3, j:j+3]\n#                         if np.sum(pattern == 0) == 1:\n#                             non_zero = pattern[pattern != 0]\n#                             if len(non_zero) > 0:\n#                                 most_common = Counter(non_zero).most_common(1)[0][0]\n#                                 zero_pos = np.where(pattern == 0)\n#                                 new_grid[i+zero_pos[0][0], j+zero_pos[1][0]] = most_common\n#                                 changed = True\n                                \n#                 return new_grid, changed\n            \n#             current = np.copy(inp)\n#             max_iterations = 10\n#             for _ in range(max_iterations):\n#                 current, changed = apply_rules(current)\n#                 if not changed:\n#                     break\n                    \n#             if np.array_equal(current, out):\n#                 debug_print(f\"   Found recursive pattern completion\")\n#                 return \"\"\"def p(g):\n#  import numpy as np\n#  from collections import Counter\n#  h,w=len(g),len(g[0])\n#  def ar(grid):\n#   ch=False\n#   ng=np.copy(grid)\n#   for i in range(1,h-1):\n#    for j in range(1,w-1):\n#     if grid[i,j]==0:\n#      n=[grid[i-1,j],grid[i+1,j],grid[i,j-1],grid[i,j+1]]\n#      if len(set(n))==1 and n[0]!=0:\n#       ng[i,j]=n[0]\n#       ch=True\n#   for i in range(h-2):\n#    for j in range(w-2):\n#     p=grid[i:i+3,j:j+3]\n#     if np.sum(p==0)==1:\n#      nz=p[p!=0]\n#      if len(nz)>0:\n#       mc=Counter(nz).most_common(1)[0][0]\n#       zp=np.where(p==0)\n#       ng[i+zp[0][0],j+zp[1][0]]=mc\n#       ch=True\n#   return ng,ch\n#  c=np.array(g)\n#  for _ in range(10):\n#   c,ch=ar(c)\n#   if not ch:break\n#  return c.tolist()\n# \"\"\"\n#         debug_print(f\"   Not a recursive pattern completion\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_recursive_pattern_completion: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_recursive_growth(task_data, analysis):\n#     debug_print(f\"Trying handle_recursive_growth\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             def grow_step(grid, growth_rule):\n#                 new_grid = np.copy(grid)\n#                 for i in range(h):\n#                     for j in range(w):\n#                         if grid[i,j] != 0:\n#                             for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                                 ni, nj = i + di, j + dj\n#                                 if 0 <= ni < h and 0 <= nj < w and grid[ni,nj] == 0:\n#                                     new_grid[ni,nj] = growth_rule(grid[i,j], i, j, ni, nj)\n#                 return new_grid\n            \n#             for rule_type in ['same', 'increment', 'position_based']:\n#                 if rule_type == 'same':\n#                     growth_rule = lambda val, i, j, ni, nj: val\n#                 elif rule_type == 'increment':\n#                     growth_rule = lambda val, i, j, ni, nj: (val % 9) + 1\n#                 else:\n#                     growth_rule = lambda val, i, j, ni, nj: ((ni + nj) % 9) + 1\n                \n#                 current = np.copy(inp)\n#                 for step in range(5):\n#                     current = grow_step(current, growth_rule)\n#                     if np.array_equal(current, out):\n#                         debug_print(f\"   Found recursive growth with {rule_type} rule\")\n#                         if rule_type == 'same':\n#                             return \"\"\"def p(g):\n#  import numpy as np\n#  h,w=len(g),len(g[0])\n#  def gs(grid):\n#   ng=np.copy(grid)\n#   for i in range(h):\n#    for j in range(w):\n#     if grid[i,j]!=0:\n#      for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#       ni,nj=i+di,j+dj\n#       if 0<=ni<h and 0<=nj<w and grid[ni,nj]==0:\n#        ng[ni,nj]=grid[i,j]\n#   return ng\n#  c=np.array(g)\n#  for _ in range(5):\n#   c=gs(c)\n#  return c.tolist()\n# \"\"\"\n#         debug_print(f\"   Not a recursive growth pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_recursive_growth: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_contextual_transformation(task_data, analysis):\n#     debug_print(f\"Trying handle_contextual_transformation\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             for i in range(h):\n#                 for j in range(w):\n#                     context = []\n#                     for di in range(-1, 2):\n#                         for dj in range(-1, 2):\n#                             ni, nj = i + di, j + dj\n#                             if 0 <= ni < h and 0 <= nj < w:\n#                                 context.append(inp[ni,nj])\n#                             else:\n#                                 context.append(0)\n                    \n#                     context_hash = sum(c * (10 ** idx) for idx, c in enumerate(context)) % 10\n#                     test[i,j] = context_hash\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found contextual transformation\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    ctx=[]\n#    for di in range(-1,2):\n#     for dj in range(-1,2):\n#      ni,nj=i+di,j+dj\n#      if 0<=ni<h and 0<=nj<w:\n#       ctx.append(g[ni][nj])\n#      else:\n#       ctx.append(0)\n#    ch=sum(c*(10**idx)for idx,c in enumerate(ctx))%10\n#    res[i][j]=ch\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a contextual transformation\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_contextual_transformation: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_probabilistic_fill(task_data, analysis):\n#     debug_print(f\"Trying handle_probabilistic_fill\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             color_probs = defaultdict(lambda: defaultdict(int))\n            \n#             for i in range(h):\n#                 for j in range(w):\n#                     if inp[i,j] != 0:\n#                         for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                             ni, nj = i + di, j + dj\n#                             if 0 <= ni < h and 0 <= nj < w:\n#                                 color_probs[inp[i,j]][inp[ni,nj]] += 1\n            \n#             test = np.copy(inp)\n#             for i in range(h):\n#                 for j in range(w):\n#                     if inp[i,j] == 0:\n#                         neighbor_colors = []\n#                         for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                             ni, nj = i + di, j + dj\n#                             if 0 <= ni < h and 0 <= nj < w and inp[ni,nj] != 0:\n#                                 neighbor_colors.append(inp[ni,nj])\n                        \n#                         if neighbor_colors:\n#                             color_scores = defaultdict(int)\n#                             for nc in neighbor_colors:\n#                                 for target, count in color_probs[nc].items():\n#                                     color_scores[target] += count\n                            \n#                             if color_scores:\n#                                 best_color = max(color_scores.items(), key=lambda x: x[1])[0]\n#                                 test[i,j] = best_color\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found probabilistic fill\")\n#                 return \"\"\"def p(g):\n#  from collections import defaultdict\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(h):\n#   for j in range(w):\n#    if g[i][j]==0:\n#     nc=[]\n#     for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#      ni,nj=i+di,j+dj\n#      if 0<=ni<h and 0<=nj<w and g[ni][nj]!=0:\n#       nc.append(g[ni][nj])\n#     if nc:\n#      res[i][j]=max(set(nc),key=nc.count)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a probabilistic fill\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_probabilistic_fill: {str(e)}\")\n#     return None\n\n# def try_adaptive_combinations(task_data, pattern_handlers, analysis):\n#     debug_print(\"=== Trying adaptive pattern combinations ===\", \"INFO\")\n    \n#     recommended = analysis.get('recommended_handlers', [])\n#     if recommended:\n#         debug_print(f\"  Using {len(recommended)} recommended handlers\", \"INFO\")\n        \n#         for handler in recommended:\n#             solution = handler(task_data, analysis)\n#             if solution and verify_solution(solution, task_data):\n#                 debug_print(f\" Recommended handler {handler.__name__} solved it!\", \"SUCCESS\")\n#                 return solution\n    \n#     inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n#     intermediate_candidates = detect_intermediate_states(inp, out)\n    \n#     if intermediate_candidates:\n#         debug_print(f\"  Found {len(intermediate_candidates)} possible intermediate states\", \"INFO\")\n        \n#         for intermediate in intermediate_candidates:\n#             step1_handlers = find_transformation(inp, intermediate, pattern_handlers[:20])\n            \n#             if step1_handlers:\n#                 step2_handlers = find_transformation(intermediate, out, pattern_handlers[:20])\n                \n#                 if step2_handlers:\n#                     combined = create_multi_step_combination(\n#                         step1_handlers[0][1], \n#                         step2_handlers[0][1],\n#                         step1_handlers[0][0].__name__,\n#                         step2_handlers[0][0].__name__\n#                     )\n                    \n#                     if verify_solution(combined, task_data):\n#                         debug_print(f\" Found multi-step combination!\", \"SUCCESS\")\n#                         return combined\n    \n#     return None\n\n# def detect_intermediate_states(inp, out):\n#     candidates = []\n    \n#     if inp.shape == out.shape:\n#         for k in range(1, 4):\n#             candidates.append(np.rot90(inp, k))\n            \n#         candidates.append(np.fliplr(inp))\n#         candidates.append(np.flipud(inp))\n        \n#         unique_colors = np.unique(inp)\n#         if len(unique_colors) <= 5:\n#             shifted = np.copy(inp)\n#             for color in unique_colors:\n#                 if color != 0:\n#                     shifted[inp == color] = (color % 9) + 1\n#             candidates.append(shifted)\n    \n#     return candidates\n\n# class PatternLearner:\n#     def __init__(self):\n#         self.handler_success_patterns = defaultdict(lambda: defaultdict(int))\n#         self.pattern_features = {}\n        \n#     def extract_features(self, task_data):\n#         inp = np.array(task_data['train'][0]['input'])\n#         out = np.array(task_data['train'][0]['output'])\n        \n#         features = {\n#             'shape_change': inp.shape != out.shape,\n#             'size_ratio': (out.size / inp.size) if inp.size > 0 else 1,\n#             'color_count_in': len(np.unique(inp)),\n#             'color_count_out': len(np.unique(out)),\n#             'has_symmetry': self.check_symmetry(inp),\n#             'has_pattern': self.check_pattern(inp),\n#             'density': np.sum(inp != 0) / inp.size,\n#             'shape_aspect': inp.shape[0] / inp.shape[1] if inp.shape[1] > 0 else 1,\n#         }\n        \n#         return features\n    \n#     def check_symmetry(self, grid):\n#         return (np.array_equal(grid, np.fliplr(grid)) or \n#                 np.array_equal(grid, np.flipud(grid)) or\n#                 (grid.shape[0] == grid.shape[1] and np.array_equal(grid, grid.T)))\n    \n#     def check_pattern(self, grid):\n#         h, w = grid.shape\n#         for ph in range(1, h//2 + 1):\n#             for pw in range(1, w//2 + 1):\n#                 if h % ph == 0 and w % pw == 0:\n#                     pattern = grid[:ph, :pw]\n#                     tiled = np.tile(pattern, (h//ph, w//pw))\n#                     if np.array_equal(grid, tiled):\n#                         return True\n#         return False\n    \n#     def update_success(self, handler_name, features, success):\n#         feature_key = tuple(sorted(features.items()))\n#         self.handler_success_patterns[handler_name][feature_key] += (1 if success else -1)\n    \n#     def get_handler_priority(self, features, handlers):\n#         feature_key = tuple(sorted(features.items()))\n        \n#         scores = []\n#         for handler in handlers:\n#             score = self.handler_success_patterns[handler.__name__][feature_key]\n#             score += np.random.normal(0, 0.1)\n#             scores.append((score, handler))\n        \n#         scores.sort(reverse=True, key=lambda x: x[0])\n        \n#         return [handler for _, handler in scores]\n\n# def generate_solution_enhanced(task_data, pattern_learner=None):\n#     global DEBUG_LOG, HANDLER_CACHE\n#     DEBUG_LOG = []\n    \n#     analysis = analyze_task_advanced(task_data)\n    \n#     debug_print(f\"\\n{'='*60}\", \"INFO\")\n#     debug_print(f\"Advanced Analysis Results:\", \"INFO\")\n#     debug_print(f\"  Transform types: {analysis['transform_type']}\", \"INFO\")\n#     debug_print(f\"  Recommended handlers: {len(analysis.get('recommended_handlers', []))}\", \"INFO\")\n    \n#     pattern_handlers = get_all_handlers()\n    \n#     if analysis.get('recommended_handlers'):\n#         debug_print(\"\\n=== PHASE 0: Trying recommended handlers ===\", \"INFO\")\n#         for handler in analysis['recommended_handlers']:\n#             solution = handler(task_data, analysis)\n#             if solution and verify_solution(solution, task_data):\n#                 debug_print(f\" Recommended handler {handler.__name__} solved it!\", \"SUCCESS\")\n#                 return solution\n    \n#     debug_print(\"\\n=== PHASE 1: Intelligent handler selection ===\", \"INFO\")\n    \n#     if pattern_learner:\n#         features = pattern_learner.extract_features(task_data)\n#         prioritized_handlers = pattern_learner.get_handler_priority(features, pattern_handlers)\n#     else:\n#         prioritized_handlers = pattern_handlers\n    \n#     for idx, handler in enumerate(prioritized_handlers[:50]):\n#         solution = handler(task_data, analysis)\n        \n#         if solution and verify_solution(solution, task_data):\n#             debug_print(f\" Handler {handler.__name__} solved it!\", \"SUCCESS\")\n            \n#             if pattern_learner:\n#                 features = pattern_learner.extract_features(task_data)\n#                 pattern_learner.update_success(handler.__name__, features, True)\n                \n#             return solution\n    \n#     debug_print(\"\\n=== PHASE 2: Adaptive combinations ===\", \"INFO\")\n    \n#     combination_solution = try_adaptive_combinations(task_data, pattern_handlers, analysis)\n#     if combination_solution:\n#         return combination_solution\n    \n#     debug_print(\"\\n=== PHASE 3: Recursive transformation search ===\", \"INFO\")\n    \n#     solution = recursive_transformation_search(\n#         task_data, \n#         pattern_handlers[:30], \n#         max_depth=3,\n#         analysis=analysis\n#     )\n#     if solution:\n#         return solution\n    \n#     debug_print(\"\\n=== PHASE 4: Exhaustive search ===\", \"INFO\")\n    \n#     for handler in prioritized_handlers[50:]:\n#         solution = handler(task_data, analysis)\n#         if solution and verify_solution(solution, task_data):\n#             return solution\n    \n#     return \"\"\"def p(g):\n#  return g\n# \"\"\"\n\n# def recursive_transformation_search(task_data, handlers, max_depth=3, current_depth=0, analysis=None):\n#     if current_depth >= max_depth:\n#         return None\n        \n#     inp = np.array(task_data['train'][0]['input'])\n#     out = np.array(task_data['train'][0]['output'])\n    \n#     for handler in handlers[:10]:\n#         try:\n#             solution = handler(task_data, analysis or {})\n#             if solution:\n#                 local_namespace = {}\n#                 exec(solution, globals(), local_namespace)\n#                 if 'p' in local_namespace:\n#                     intermediate = local_namespace['p'](inp.tolist())\n                    \n#                     if intermediate == out.tolist():\n#                         return solution\n                    \n#                     new_task = {\n#                         'train': [{'input': intermediate, 'output': out.tolist()}],\n#                         'test': []\n#                     }\n                    \n#                     next_solution = recursive_transformation_search(\n#                         new_task, \n#                         handlers, \n#                         max_depth, \n#                         current_depth + 1,\n#                         analysis\n#                     )\n                    \n#                     if next_solution:\n#                         return create_recursive_combination(solution, next_solution, handler.__name__)\n#         except:\n#             pass\n            \n#     return None\n\n# def create_recursive_combination(sol1, sol2, name1):\n#     body1 = extract_function_body(sol1)\n#     body2 = extract_function_body(sol2)\n    \n#     return f\"\"\"def p(g):\n#  def t1(g):\n# {indent_code(body1, 2)}\n \n#  def t2(g):\n# {indent_code(body2, 2)}\n \n#  intermediate = t1(g)\n#  return t2(intermediate)\n# \"\"\"\n\n# def get_all_handlers():\n#     return [\n#         handle_recursive_pattern_completion,\n#         handle_recursive_growth,\n#         handle_contextual_transformation,\n#         handle_probabilistic_fill,\n#     ] + get_existing_handlers()\n\n# def find_transformation(inp, out, handlers):\n#     mock_task = {\n#         'train': [{'input': inp.tolist(), 'output': out.tolist()}],\n#         'test': []\n#     }\n    \n#     matches = []\n#     for handler in handlers:\n#         try:\n#             solution = handler(mock_task, {})\n#             if solution and verify_solution(solution, mock_task):\n#                 matches.append((handler, solution))\n#         except:\n#             pass\n            \n#     return matches\n\n# def create_multi_step_combination(sol1, sol2, name1, name2):\n#     body1 = extract_function_body(sol1)\n#     body2 = extract_function_body(sol2)\n    \n#     return f\"\"\"def p(g):\n#  def t1(g):\n# {indent_code(body1, 2)}\n \n#  def t2(g):\n# {indent_code(body2, 2)}\n \n#  intermediate = t1(g)\n#  return t2(intermediate)\n# \"\"\"\n\n# def recommend_handlers(analysis):\n#     recommendations = []\n    \n#     handler_patterns = {\n#         'rotation_90': [handle_rotate_90],\n#         'rotation_180': [handle_rotate_180],\n#         'rotation_270': [handle_rotate_270],\n#         'mirror_horizontal': [handle_flip_horizontal],\n#         'mirror_vertical': [handle_flip_vertical],\n#         'tiling': [handle_tile_pattern, handle_repeat_pattern],\n#         'expansion': [handle_upscale, handle_pad_to_square, handle_border_operations],\n#         'reduction': [handle_downscale, handle_crop_to_content, handle_extract_pattern],\n#         'color_mapping': [handle_color_mapping, handle_layered_transform, handle_color_cycle],\n#     }\n    \n#     for pattern_type in analysis['transform_type']:\n#         if pattern_type in handler_patterns:\n#             recommendations.extend(handler_patterns[pattern_type])\n            \n#     return recommendations\n\n# learner = PatternLearner()\n\n# def create_arc_solutions_ultra(input_dir=\".\", output_dir=\"submission\"):\n#     solutions = {}\n    \n#     os.makedirs(output_dir, exist_ok=True)\n    \n#     solved_count = 0\n#     total_count = 0\n    \n#     for task_num in range(1, 401):\n#         task_id = f\"{task_num:03d}\"\n#         task_file = os.path.join(input_dir, f\"task{task_id}.json\")\n        \n#         try:\n#             with open(task_file) as f:\n#                 task_data = json.load(f)\n            \n#             solution = generate_solution_enhanced(task_data, learner)\n#             solutions[task_id] = solution\n            \n#             if verify_solution(solution, task_data):\n#                 print(f\" Task {task_id} solved\")\n#                 solved_count += 1\n                \n#                 features = learner.extract_features(task_data)\n#                 for line in solution.split('\\n'):\n#                     if '# Step 1:' in line or ' Found' in DEBUG_LOG:\n#                         handler_name = line.split(':')[1].strip()\n#                         learner.update_success(handler_name, features, True)\n#                         break\n#             else:\n#                 print(f\" Task {task_id} fallback\")\n            \n#             total_count += 1\n            \n#         except Exception as e:\n#             print(f\"Error task {task_id}: {str(e)}\")\n#             solutions[task_id] = \"\"\"def p(g):\n#  return g\n# \"\"\"\n#             total_count += 1\n    \n#     for task_id, code in solutions.items():\n#         output_file = os.path.join(output_dir, f\"task{task_id}.py\")\n#         with open(output_file, \"w\") as f:\n#             f.write(code)\n    \n#     with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n#         for task_id in solutions:\n#             file_path = os.path.join(output_dir, f\"task{task_id}.py\")\n#             zipf.write(file_path, f\"task{task_id}.py\")\n    \n#     print(f\"\\n{'='*60}\")\n#     print(f\"FINAL RESULTS\")\n#     print(f\"{'='*60}\")\n#     print(f\" Solved: {solved_count}/{total_count} ({solved_count/total_count*100:.1f}%)\")\n#     print(f\"\\n Created: submission.zip\")\n\n# if __name__ == \"__main__\":\n#     create_arc_solutions_ultra(input_dir='/kaggle/input/google-code-golf-2025')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-02T20:24:37.297484Z","iopub.execute_input":"2025-08-02T20:24:37.297802Z","iopub.status.idle":"2025-08-02T20:24:37.387156Z","shell.execute_reply.started":"2025-08-02T20:24:37.297775Z","shell.execute_reply":"2025-08-02T20:24:37.386158Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # ==================== SECTION 17: CORE FUNCTIONALITY ====================\n\n# def analyze_task_advanced(task_data):\n#     \"\"\"Advanced task analysis with pattern detection and handler recommendations\"\"\"\n#     analysis = analyze_task(task_data)  # Keep existing analysis\n    \n#     # Add pattern detection\n#     inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n#     # Detect transformation types\n#     analysis['transform_type'] = set()\n    \n#     # Shape transformations\n#     if inp.shape != out.shape:\n#         if out.shape[0] > inp.shape[0] or out.shape[1] > inp.shape[1]:\n#             analysis['transform_type'].add('expansion')\n#         else:\n#             analysis['transform_type'].add('reduction')\n            \n#     # Symmetry detection\n#     if inp.shape == out.shape:\n#         # Check for rotational relationship\n#         for k in range(1, 4):\n#             if np.array_equal(np.rot90(inp, k), out):\n#                 analysis['transform_type'].add(f'rotation_{k*90}')\n                \n#         # Check for mirror\n#         if np.array_equal(np.fliplr(inp), out):\n#             analysis['transform_type'].add('mirror_horizontal')\n#         if np.array_equal(np.flipud(inp), out):\n#             analysis['transform_type'].add('mirror_vertical')\n            \n#     # Pattern repetition detection\n#     if out.shape[0] % inp.shape[0] == 0 and out.shape[1] % inp.shape[1] == 0:\n#         analysis['transform_type'].add('tiling')\n        \n#     # Color transformation detection\n#     unique_in = set(inp.flatten())\n#     unique_out = set(out.flatten())\n#     if len(unique_in) == len(unique_out) and unique_in != unique_out:\n#         analysis['transform_type'].add('color_mapping')\n        \n#     # Recommend handlers based on analysis\n#     analysis['recommended_handlers'] = recommend_handlers(analysis)\n    \n#     return analysis\n\n# @timed_handler\n# def handle_recursive_pattern_completion(task_data, analysis):\n#     \"\"\"Recursively complete patterns until no changes occur\"\"\"\n#     debug_print(f\"Trying handle_recursive_pattern_completion\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Define recursive completion rules\n#             def apply_rules(grid):\n#                 changed = False\n#                 new_grid = np.copy(grid)\n                \n#                 # Rule 1: If a cell is surrounded by same color, fill it\n#                 for i in range(1, h-1):\n#                     for j in range(1, w-1):\n#                         if grid[i,j] == 0:\n#                             neighbors = [grid[i-1,j], grid[i+1,j], grid[i,j-1], grid[i,j+1]]\n#                             if len(set(neighbors)) == 1 and neighbors[0] != 0:\n#                                 new_grid[i,j] = neighbors[0]\n#                                 changed = True\n                                \n#                 # Rule 2: Complete patterns\n#                 for i in range(h-2):\n#                     for j in range(w-2):\n#                         # Check 3x3 patterns\n#                         pattern = grid[i:i+3, j:j+3]\n#                         if np.sum(pattern == 0) == 1:  # One empty cell\n#                             # Find most common non-zero value\n#                             non_zero = pattern[pattern != 0]\n#                             if len(non_zero) > 0:\n#                                 most_common = Counter(non_zero).most_common(1)[0][0]\n#                                 zero_pos = np.where(pattern == 0)\n#                                 new_grid[i+zero_pos[0][0], j+zero_pos[1][0]] = most_common\n#                                 changed = True\n                                \n#                 return new_grid, changed\n            \n#             # Apply rules recursively\n#             current = np.copy(inp)\n#             max_iterations = 10\n#             for _ in range(max_iterations):\n#                 current, changed = apply_rules(current)\n#                 if not changed:\n#                     break\n                    \n#             if np.array_equal(current, out):\n#                 debug_print(f\"   Found recursive pattern completion\")\n#                 return \"\"\"def p(g):\n#  import numpy as np\n#  from collections import Counter\n#  h,w=len(g),len(g[0])\n#  def ar(grid):\n#   ch=False\n#   ng=np.copy(grid)\n#   for i in range(1,h-1):\n#    for j in range(1,w-1):\n#     if grid[i,j]==0:\n#      n=[grid[i-1,j],grid[i+1,j],grid[i,j-1],grid[i,j+1]]\n#      if len(set(n))==1 and n[0]!=0:\n#       ng[i,j]=n[0]\n#       ch=True\n#   for i in range(h-2):\n#    for j in range(w-2):\n#     p=grid[i:i+3,j:j+3]\n#     if np.sum(p==0)==1:\n#      nz=p[p!=0]\n#      if len(nz)>0:\n#       mc=Counter(nz).most_common(1)[0][0]\n#       zp=np.where(p==0)\n#       ng[i+zp[0][0],j+zp[1][0]]=mc\n#       ch=True\n#   return ng,ch\n#  c=np.array(g)\n#  for _ in range(10):\n#   c,ch=ar(c)\n#   if not ch:break\n#  return c.tolist()\n# \"\"\"\n#         debug_print(f\"   Not a recursive pattern completion\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_recursive_pattern_completion: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_recursive_growth(task_data, analysis):\n#     \"\"\"Recursively grow patterns from seed points\"\"\"\n#     debug_print(f\"Trying handle_recursive_growth\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             def grow_step(grid, growth_rule):\n#                 new_grid = np.copy(grid)\n#                 for i in range(h):\n#                     for j in range(w):\n#                         if grid[i,j] != 0:\n#                             # Apply growth rule to neighbors\n#                             for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                                 ni, nj = i + di, j + dj\n#                                 if 0 <= ni < h and 0 <= nj < w and grid[ni,nj] == 0:\n#                                     new_grid[ni,nj] = growth_rule(grid[i,j], i, j, ni, nj)\n#                 return new_grid\n            \n#             # Try different growth rules\n#             for rule_type in ['same', 'increment', 'position_based']:\n#                 if rule_type == 'same':\n#                     growth_rule = lambda val, i, j, ni, nj: val\n#                 elif rule_type == 'increment':\n#                     growth_rule = lambda val, i, j, ni, nj: (val % 9) + 1\n#                 else:\n#                     growth_rule = lambda val, i, j, ni, nj: ((ni + nj) % 9) + 1\n                \n#                 current = np.copy(inp)\n#                 for step in range(5):\n#                     current = grow_step(current, growth_rule)\n#                     if np.array_equal(current, out):\n#                         debug_print(f\"   Found recursive growth with {rule_type} rule\")\n#                         if rule_type == 'same':\n#                             return \"\"\"def p(g):\n#  import numpy as np\n#  h,w=len(g),len(g[0])\n#  def gs(grid):\n#   ng=np.copy(grid)\n#   for i in range(h):\n#    for j in range(w):\n#     if grid[i,j]!=0:\n#      for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#       ni,nj=i+di,j+dj\n#       if 0<=ni<h and 0<=nj<w and grid[ni,nj]==0:\n#        ng[ni,nj]=grid[i,j]\n#   return ng\n#  c=np.array(g)\n#  for _ in range(5):\n#   c=gs(c)\n#  return c.tolist()\n# \"\"\"\n#         debug_print(f\"   Not a recursive growth pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_recursive_growth: {str(e)}\")\n#     return None\n\n# def analyze_task_advanced(task_data):\n#     \"\"\"Advanced task analysis with pattern detection and handler recommendations\"\"\"\n#     analysis = analyze_task(task_data)  # Keep existing analysis\n    \n#     # Add pattern detection\n#     inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n#     # Detect transformation types\n#     analysis['transform_type'] = set()\n    \n#     # Shape transformations\n#     if inp.shape != out.shape:\n#         if out.shape[0] > inp.shape[0] or out.shape[1] > inp.shape[1]:\n#             analysis['transform_type'].add('expansion')\n#         else:\n#             analysis['transform_type'].add('reduction')\n            \n#     # Symmetry detection\n#     if inp.shape == out.shape:\n#         # Check for rotational relationship\n#         for k in range(1, 4):\n#             if np.array_equal(np.rot90(inp, k), out):\n#                 analysis['transform_type'].add(f'rotation_{k*90}')\n                \n#         # Check for mirror\n#         if np.array_equal(np.fliplr(inp), out):\n#             analysis['transform_type'].add('mirror_horizontal')\n#         if np.array_equal(np.flipud(inp), out):\n#             analysis['transform_type'].add('mirror_vertical')\n            \n#     # Pattern repetition detection\n#     if out.shape[0] % inp.shape[0] == 0 and out.shape[1] % inp.shape[1] == 0:\n#         analysis['transform_type'].add('tiling')\n        \n#     # Color transformation detection\n#     unique_in = set(inp.flatten())\n#     unique_out = set(out.flatten())\n#     if len(unique_in) == len(unique_out) and unique_in != unique_out:\n#         analysis['transform_type'].add('color_mapping')\n        \n#     # Recommend handlers based on analysis\n#     analysis['recommended_handlers'] = recommend_handlers(analysis)\n    \n#     return analysis\n\n# def try_adaptive_combinations(task_data, pattern_handlers, analysis):\n#     \"\"\"Try adaptive combinations based on pattern analysis\"\"\"\n#     debug_print(\"=== Trying adaptive pattern combinations ===\", \"INFO\")\n    \n#     # Use recommended handlers first\n#     recommended = analysis.get('recommended_handlers', [])\n#     if recommended:\n#         debug_print(f\"  Using {len(recommended)} recommended handlers\", \"INFO\")\n        \n#         for handler in recommended:\n#             solution = handler(task_data, analysis)\n#             if solution and verify_solution(solution, task_data):\n#                 debug_print(f\" Recommended handler {handler.__name__} solved it!\", \"SUCCESS\")\n#                 return solution\n    \n#     # Try multi-step combinations (3+ transformations)\n#     inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n    \n#     # Detect intermediate states\n#     intermediate_candidates = detect_intermediate_states(inp, out)\n    \n#     if intermediate_candidates:\n#         debug_print(f\"  Found {len(intermediate_candidates)} possible intermediate states\", \"INFO\")\n        \n#         for intermediate in intermediate_candidates:\n#             # Find transformation from input to intermediate\n#             step1_handlers = find_transformation(inp, intermediate, pattern_handlers[:20])\n            \n#             if step1_handlers:\n#                 # Find transformation from intermediate to output\n#                 step2_handlers = find_transformation(intermediate, out, pattern_handlers[:20])\n                \n#                 if step2_handlers:\n#                     combined = create_multi_step_combination(\n#                         step1_handlers[0][1], \n#                         step2_handlers[0][1],\n#                         step1_handlers[0][0].__name__,\n#                         step2_handlers[0][0].__name__\n#                     )\n                    \n#                     if verify_solution(combined, task_data):\n#                         debug_print(f\" Found multi-step combination!\", \"SUCCESS\")\n#                         return combined\n    \n#     return None\n\n# def detect_intermediate_states(inp, out):\n#     \"\"\"Detect possible intermediate transformation states\"\"\"\n#     candidates = []\n    \n#     # Common intermediate states\n#     if inp.shape == out.shape:\n#         # Rotations as intermediate\n#         for k in range(1, 4):\n#             candidates.append(np.rot90(inp, k))\n            \n#         # Flips as intermediate\n#         candidates.append(np.fliplr(inp))\n#         candidates.append(np.flipud(inp))\n        \n#         # Color transformations as intermediate\n#         unique_colors = np.unique(inp)\n#         if len(unique_colors) <= 5:\n#             # Try shifting all colors\n#             shifted = np.copy(inp)\n#             for color in unique_colors:\n#                 if color != 0:\n#                     shifted[inp == color] = (color % 9) + 1\n#             candidates.append(shifted)\n    \n#     return candidates\n\n# class PatternLearner:\n#     \"\"\"Learn which handlers work for which patterns\"\"\"\n#     def __init__(self):\n#         self.handler_success_patterns = defaultdict(lambda: defaultdict(int))\n#         self.pattern_features = {}\n        \n#     def extract_features(self, task_data):\n#         \"\"\"Extract features from task\"\"\"\n#         inp = np.array(task_data['train'][0]['input'])\n#         out = np.array(task_data['train'][0]['output'])\n        \n#         features = {\n#             'shape_change': inp.shape != out.shape,\n#             'size_ratio': (out.size / inp.size) if inp.size > 0 else 1,\n#             'color_count_in': len(np.unique(inp)),\n#             'color_count_out': len(np.unique(out)),\n#             'has_symmetry': self.check_symmetry(inp),\n#             'has_pattern': self.check_pattern(inp),\n#             'density': np.sum(inp != 0) / inp.size,\n#             'shape_aspect': inp.shape[0] / inp.shape[1] if inp.shape[1] > 0 else 1,\n#         }\n        \n#         return features\n    \n#     def check_symmetry(self, grid):\n#         \"\"\"Check if grid has symmetry\"\"\"\n#         return (np.array_equal(grid, np.fliplr(grid)) or \n#                 np.array_equal(grid, np.flipud(grid)) or\n#                 (grid.shape[0] == grid.shape[1] and np.array_equal(grid, grid.T)))\n    \n#     def check_pattern(self, grid):\n#         \"\"\"Check if grid has repeating pattern\"\"\"\n#         h, w = grid.shape\n#         for ph in range(1, h//2 + 1):\n#             for pw in range(1, w//2 + 1):\n#                 if h % ph == 0 and w % pw == 0:\n#                     pattern = grid[:ph, :pw]\n#                     tiled = np.tile(pattern, (h//ph, w//pw))\n#                     if np.array_equal(grid, tiled):\n#                         return True\n#         return False\n    \n#     def update_success(self, handler_name, features, success):\n#         \"\"\"Update handler success for given features\"\"\"\n#         feature_key = tuple(sorted(features.items()))\n#         self.handler_success_patterns[handler_name][feature_key] += (1 if success else -1)\n    \n#     def get_handler_priority(self, features, handlers):\n#         \"\"\"Get handlers prioritized by past success\"\"\"\n#         feature_key = tuple(sorted(features.items()))\n        \n#         scores = []\n#         for handler in handlers:\n#             score = self.handler_success_patterns[handler.__name__][feature_key]\n#             # Add some randomness to explore\n#             score += np.random.normal(0, 0.1)\n#             scores.append((score, handler))\n        \n#         # Sort by score descending\n#         scores.sort(reverse=True, key=lambda x: x[0])\n        \n#         return [handler for _, handler in scores]\n\n# def generate_solution_enhanced(task_data, pattern_learner=None):\n#     \"\"\"Enhanced solution generation with intelligent selection and combinations\"\"\"\n#     global DEBUG_LOG, HANDLER_CACHE\n#     DEBUG_LOG = []\n    \n#     # Advanced analysis\n#     analysis = analyze_task_advanced(task_data)\n    \n#     debug_print(f\"\\n{'='*60}\", \"INFO\")\n#     debug_print(f\"Advanced Analysis Results:\", \"INFO\")\n#     debug_print(f\"  Transform types: {analysis['transform_type']}\", \"INFO\")\n#     debug_print(f\"  Recommended handlers: {len(analysis.get('recommended_handlers', []))}\", \"INFO\")\n    \n#     # Get all handlers (including new recursive ones)\n#     pattern_handlers = get_all_handlers()\n    \n#     # Phase 0: Try recommended handlers first\n#     if analysis.get('recommended_handlers'):\n#         debug_print(\"\\n=== PHASE 0: Trying recommended handlers ===\", \"INFO\")\n#         for handler in analysis['recommended_handlers']:\n#             solution = handler(task_data, analysis)\n#             if solution and verify_solution(solution, task_data):\n#                 debug_print(f\" Recommended handler {handler.__name__} solved it!\", \"SUCCESS\")\n#                 return solution\n    \n#     # Phase 1: Intelligent handler selection\n#     debug_print(\"\\n=== PHASE 1: Intelligent handler selection ===\", \"INFO\")\n    \n#     if pattern_learner:\n#         features = pattern_learner.extract_features(task_data)\n#         prioritized_handlers = pattern_learner.get_handler_priority(features, pattern_handlers)\n#     else:\n#         prioritized_handlers = pattern_handlers\n    \n#     # Try handlers with early stopping\n#     for idx, handler in enumerate(prioritized_handlers[:50]):  # Limit first pass\n#         solution = handler(task_data, analysis)\n        \n#         if solution and verify_solution(solution, task_data):\n#             debug_print(f\" Handler {handler.__name__} solved it!\", \"SUCCESS\")\n            \n#             if pattern_learner:\n#                 features = pattern_learner.extract_features(task_data)\n#                 pattern_learner.update_success(handler.__name__, features, True)\n                \n#             return solution\n    \n#     # Phase 2: Adaptive combinations\n#     debug_print(\"\\n=== PHASE 2: Adaptive combinations ===\", \"INFO\")\n    \n#     combination_solution = try_adaptive_combinations(task_data, pattern_handlers, analysis)\n#     if combination_solution:\n#         return combination_solution\n    \n#     # Phase 3: Recursive search with backtracking\n#     debug_print(\"\\n=== PHASE 3: Recursive transformation search ===\", \"INFO\")\n    \n#     solution = recursive_transformation_search(\n#         task_data, \n#         pattern_handlers[:30], \n#         max_depth=3,\n#         analysis=analysis\n#     )\n#     if solution:\n#         return solution\n    \n#     # Phase 4: Try remaining handlers\n#     debug_print(\"\\n=== PHASE 4: Exhaustive search ===\", \"INFO\")\n    \n#     for handler in prioritized_handlers[50:]:\n#         solution = handler(task_data, analysis)\n#         if solution and verify_solution(solution, task_data):\n#             return solution\n    \n#     # Fallback\n#     return \"\"\"def p(g):\n#  return g\n# \"\"\"\n\n# def recursive_transformation_search(task_data, handlers, max_depth=3, current_depth=0, analysis=None):\n#     \"\"\"Recursively search for transformation combinations\"\"\"\n#     if current_depth >= max_depth:\n#         return None\n        \n#     inp = np.array(task_data['train'][0]['input'])\n#     out = np.array(task_data['train'][0]['output'])\n    \n#     # Try each handler\n#     for handler in handlers[:10]:  # Limit to prevent explosion\n#         try:\n#             solution = handler(task_data, analysis or {})\n#             if solution:\n#                 # Create a mock execution to get intermediate result\n#                 local_namespace = {}\n#                 exec(solution, globals(), local_namespace)\n#                 if 'p' in local_namespace:\n#                     intermediate = local_namespace['p'](inp.tolist())\n                    \n#                     if intermediate == out.tolist():\n#                         return solution\n                    \n#                     # Create new task with intermediate as input\n#                     new_task = {\n#                         'train': [{'input': intermediate, 'output': out.tolist()}],\n#                         'test': []\n#                     }\n                    \n#                     # Recursive search\n#                     next_solution = recursive_transformation_search(\n#                         new_task, \n#                         handlers, \n#                         max_depth, \n#                         current_depth + 1,\n#                         analysis\n#                     )\n                    \n#                     if next_solution:\n#                         # Combine solutions\n#                         return create_recursive_combination(solution, next_solution, handler.__name__)\n#         except:\n#             pass\n            \n#     return None\n\n# def generate_solution_enhanced(task_data, pattern_learner=None):\n#     \"\"\"Enhanced solution generation with intelligent selection and combinations\"\"\"\n#     global DEBUG_LOG, HANDLER_CACHE\n#     DEBUG_LOG = []\n    \n#     # Advanced analysis\n#     analysis = analyze_task_advanced(task_data)\n    \n#     debug_print(f\"\\n{'='*60}\", \"INFO\")\n#     debug_print(f\"Advanced Analysis Results:\", \"INFO\")\n#     debug_print(f\"  Transform types: {analysis['transform_type']}\", \"INFO\")\n#     debug_print(f\"  Recommended handlers: {len(analysis.get('recommended_handlers', []))}\", \"INFO\")\n    \n#     # Get all handlers (including new recursive ones)\n#     pattern_handlers = get_all_handlers()\n    \n#     # Phase 0: Try recommended handlers first\n#     if analysis.get('recommended_handlers'):\n#         debug_print(\"\\n=== PHASE 0: Trying recommended handlers ===\", \"INFO\")\n#         for handler in analysis['recommended_handlers']:\n#             solution = handler(task_data, analysis)\n#             if solution and verify_solution(solution, task_data):\n#                 debug_print(f\" Recommended handler {handler.__name__} solved it!\", \"SUCCESS\")\n#                 return solution\n    \n#     # Phase 1: Intelligent handler selection\n#     debug_print(\"\\n=== PHASE 1: Intelligent handler selection ===\", \"INFO\")\n    \n#     if pattern_learner:\n#         features = pattern_learner.extract_features(task_data)\n#         prioritized_handlers = pattern_learner.get_handler_priority(features, pattern_handlers)\n#     else:\n#         prioritized_handlers = pattern_handlers\n    \n#     # Try handlers with early stopping\n#     for idx, handler in enumerate(prioritized_handlers[:50]):  # Limit first pass\n#         solution = handler(task_data, analysis)\n        \n#         if solution and verify_solution(solution, task_data):\n#             debug_print(f\" Handler {handler.__name__} solved it!\", \"SUCCESS\")\n            \n#             if pattern_learner:\n#                 features = pattern_learner.extract_features(task_data)\n#                 pattern_learner.update_success(handler.__name__, features, True)\n                \n#             return solution\n    \n#     # Phase 2: Adaptive combinations\n#     debug_print(\"\\n=== PHASE 2: Adaptive combinations ===\", \"INFO\")\n    \n#     combination_solution = try_adaptive_combinations(task_data, pattern_handlers, analysis)\n#     if combination_solution:\n#         return combination_solution\n    \n#     # Phase 3: Recursive search with backtracking\n#     debug_print(\"\\n=== PHASE 3: Recursive transformation search ===\", \"INFO\")\n    \n#     solution = recursive_transformation_search(\n#         task_data, \n#         pattern_handlers[:30], \n#         max_depth=3,\n#         analysis=analysis\n#     )\n#     if solution:\n#         return solution\n    \n#     # Phase 4: Try remaining handlers\n#     debug_print(\"\\n=== PHASE 4: Exhaustive search ===\", \"INFO\")\n    \n#     for handler in prioritized_handlers[50:]:\n#         solution = handler(task_data, analysis)\n#         if solution and verify_solution(solution, task_data):\n#             return solution\n    \n#     # Fallback\n#     return \"\"\"def p(g):\n#  return g\n# \"\"\"\n\n# def recursive_transformation_search(task_data, handlers, max_depth=3, current_depth=0, analysis=None):\n#     \"\"\"Recursively search for transformation combinations\"\"\"\n#     if current_depth >= max_depth:\n#         return None\n        \n#     inp = np.array(task_data['train'][0]['input'])\n#     out = np.array(task_data['train'][0]['output'])\n    \n#     # Try each handler\n#     for handler in handlers[:10]:  # Limit to prevent explosion\n#         try:\n#             solution = handler(task_data, analysis or {})\n#             if solution:\n#                 # Create a mock execution to get intermediate result\n#                 local_namespace = {}\n#                 exec(solution, globals(), local_namespace)\n#                 if 'p' in local_namespace:\n#                     intermediate = local_namespace['p'](inp.tolist())\n                    \n#                     if intermediate == out.tolist():\n#                         return solution\n                    \n#                     # Create new task with intermediate as input\n#                     new_task = {\n#                         'train': [{'input': intermediate, 'output': out.tolist()}],\n#                         'test': []\n#                     }\n                    \n#                     # Recursive search\n#                     next_solution = recursive_transformation_search(\n#                         new_task, \n#                         handlers, \n#                         max_depth, \n#                         current_depth + 1,\n#                         analysis\n#                     )\n                    \n#                     if next_solution:\n#                         # Combine solutions\n#                         return create_recursive_combination(solution, next_solution, handler.__name__)\n#         except:\n#             pass\n            \n#     return None\n\n# def create_recursive_combination(sol1, sol2, name1):\n#     \"\"\"Create a recursive combination of solutions\"\"\"\n#     body1 = extract_function_body(sol1)\n#     body2 = extract_function_body(sol2)\n    \n#     return f\"\"\"def p(g):\n#  # Step 1: {name1}\n#  def t1(g):\n# {indent_code(body1, 2)}\n \n#  # Step 2: Recursive transformation\n#  def t2(g):\n# {indent_code(body2, 2)}\n \n#  intermediate = t1(g)\n#  return t2(intermediate)\n# \"\"\"\n\n# def get_all_handlers():\n#     \"\"\"Get all handlers including new ones\"\"\"\n#     return [\n#         # ... all existing handlers ...\n#         handle_recursive_pattern_completion,\n#         handle_recursive_growth,\n#         # Add more recursive handlers here\n#     ] + get_existing_handlers()  # This would be your current handler list\n\n# @timed_handler\n# def handle_contextual_transformation(task_data, analysis):\n#     \"\"\"Transform based on local context\"\"\"\n#     debug_print(f\"Trying handle_contextual_transformation\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             # Transform each cell based on its context\n#             for i in range(h):\n#                 for j in range(w):\n#                     # Get 3x3 context\n#                     context = []\n#                     for di in range(-1, 2):\n#                         for dj in range(-1, 2):\n#                             ni, nj = i + di, j + dj\n#                             if 0 <= ni < h and 0 <= nj < w:\n#                                 context.append(inp[ni,nj])\n#                             else:\n#                                 context.append(0)\n                    \n#                     # Apply context-based transformation\n#                     context_hash = sum(c * (10 ** idx) for idx, c in enumerate(context)) % 10\n#                     test[i,j] = context_hash\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found contextual transformation\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    ctx=[]\n#    for di in range(-1,2):\n#     for dj in range(-1,2):\n#      ni,nj=i+di,j+dj\n#      if 0<=ni<h and 0<=nj<w:\n#       ctx.append(g[ni][nj])\n#      else:\n#       ctx.append(0)\n#    ch=sum(c*(10**idx)for idx,c in enumerate(ctx))%10\n#    res[i][j]=ch\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a contextual transformation\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_contextual_transformation: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_probabilistic_fill(task_data, analysis):\n#     \"\"\"Fill based on probabilistic rules\"\"\"\n#     debug_print(f\"Trying handle_probabilistic_fill\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Analyze color probabilities\n#             color_probs = defaultdict(lambda: defaultdict(int))\n            \n#             for i in range(h):\n#                 for j in range(w):\n#                     if inp[i,j] != 0:\n#                         # Count neighbors\n#                         for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                             ni, nj = i + di, j + dj\n#                             if 0 <= ni < h and 0 <= nj < w:\n#                                 color_probs[inp[i,j]][inp[ni,nj]] += 1\n            \n#             # Apply probabilistic rules\n#             test = np.copy(inp)\n#             for i in range(h):\n#                 for j in range(w):\n#                     if inp[i,j] == 0:\n#                         # Get neighbor colors\n#                         neighbor_colors = []\n#                         for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                             ni, nj = i + di, j + dj\n#                             if 0 <= ni < h and 0 <= nj < w and inp[ni,nj] != 0:\n#                                 neighbor_colors.append(inp[ni,nj])\n                        \n#                         if neighbor_colors:\n#                             # Choose based on probability\n#                             color_scores = defaultdict(int)\n#                             for nc in neighbor_colors:\n#                                 for target, count in color_probs[nc].items():\n#                                     color_scores[target] += count\n                            \n#                             if color_scores:\n#                                 best_color = max(color_scores.items(), key=lambda x: x[1])[0]\n#                                 test[i,j] = best_color\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found probabilistic fill\")\n#                 # Return simplified version\n#                 return \"\"\"def p(g):\n#  from collections import defaultdict\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  # Simplified probabilistic fill\n#  for i in range(h):\n#   for j in range(w):\n#    if g[i][j]==0:\n#     nc=[]\n#     for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#      ni,nj=i+di,j+dj\n#      if 0<=ni<h and 0<=nj<w and g[ni][nj]!=0:\n#       nc.append(g[ni][nj])\n#     if nc:\n#      res[i][j]=max(set(nc),key=nc.count)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a probabilistic fill\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_probabilistic_fill: {str(e)}\")\n#     return None\n\n# def create_recursive_combination(sol1, sol2, name1):\n#     \"\"\"Create a recursive combination of solutions\"\"\"\n#     body1 = extract_function_body(sol1)\n#     body2 = extract_function_body(sol2)\n    \n#     return f\"\"\"def p(g):\n#  # Step 1: {name1}\n#  def t1(g):\n# {indent_code(body1, 2)}\n \n#  # Step 2: Recursive transformation\n#  def t2(g):\n# {indent_code(body2, 2)}\n \n#  intermediate = t1(g)\n#  return t2(intermediate)\n# \"\"\"\n\n# def get_all_handlers():\n#     \"\"\"Get all handlers including new ones\"\"\"\n#     return [\n#         # ... all existing handlers ...\n#         handle_recursive_pattern_completion,\n#         handle_recursive_growth,\n#         # Add more recursive handlers here\n#     ] + get_existing_handlers()  # This would be your current handler list\n\n# def find_transformation(inp, out, handlers):\n#     \"\"\"Find handlers that transform inp to out\"\"\"\n#     mock_task = {\n#         'train': [{'input': inp.tolist(), 'output': out.tolist()}],\n#         'test': []\n#     }\n    \n#     matches = []\n#     for handler in handlers:\n#         try:\n#             solution = handler(mock_task, {})\n#             if solution and verify_solution(solution, mock_task):\n#                 matches.append((handler, solution))\n#         except:\n#             pass\n            \n#     return matches\n\n# def recommend_handlers(analysis):\n#     \"\"\"Recommend handlers based on pattern analysis\"\"\"\n#     recommendations = []\n    \n#     handler_patterns = {\n#         'rotation_90': [handle_rotate_90],\n#         'rotation_180': [handle_rotate_180],\n#         'rotation_270': [handle_rotate_270],\n#         'mirror_horizontal': [handle_flip_horizontal],\n#         'mirror_vertical': [handle_flip_vertical],\n#         'tiling': [handle_tile_pattern, handle_repeat_pattern],\n#         'expansion': [handle_upscale, handle_pad_to_square, handle_border_operations],\n#         'reduction': [handle_downscale, handle_crop_to_content, handle_extract_pattern],\n#         'color_mapping': [handle_color_mapping, handle_layered_transform, handle_color_cycle],\n#     }\n    \n#     for pattern_type in analysis['transform_type']:\n#         if pattern_type in handler_patterns:\n#             recommendations.extend(handler_patterns[pattern_type])\n            \n#     return recommendations\n\n# # Initialize pattern learner\n# learner = PatternLearner()\n\n# # Enhanced main execution\n# def create_arc_solutions_ultra(input_dir=\".\", output_dir=\"submission\"):\n#     \"\"\"Ultra-enhanced main execution with learning\"\"\"\n#     solutions = {}\n    \n#     os.makedirs(output_dir, exist_ok=True)\n    \n#     solved_count = 0\n#     total_count = 0\n    \n#     for task_num in range(1, 401):\n#         task_id = f\"{task_num:03d}\"\n#         task_file = os.path.join(input_dir, f\"task{task_id}.json\")\n        \n#         try:\n#             with open(task_file) as f:\n#                 task_data = json.load(f)\n            \n#             # Use enhanced generator with learning\n#             solution = generate_solution_enhanced(task_data, learner)\n#             solutions[task_id] = solution\n            \n#             if verify_solution(solution, task_data):\n#                 print(f\" Task {task_id} solved\")\n#                 solved_count += 1\n                \n#                 # Update learner with success\n#                 features = learner.extract_features(task_data)\n#                 # Extract handler name from solution if possible\n#                 for line in solution.split('\\n'):\n#                     if '# Step 1:' in line or ' Found' in DEBUG_LOG:\n#                         handler_name = line.split(':')[1].strip()\n#                         learner.update_success(handler_name, features, True)\n#                         break\n#             else:\n#                 print(f\" Task {task_id} fallback\")\n            \n#             total_count += 1\n            \n#         except Exception as e:\n#             print(f\"Error task {task_id}: {str(e)}\")\n#             solutions[task_id] = \"\"\"def p(g):\n#  return g\n# \"\"\"\n#             total_count += 1\n    \n#     # Save solutions and create submission\n#     # ... rest of the code ...\n    \n# def recommend_handlers(analysis):\n#     \"\"\"Recommend handlers based on pattern analysis\"\"\"\n#     recommendations = []\n    \n#     handler_patterns = {\n#         'rotation_90': [handle_rotate_90],\n#         'rotation_180': [handle_rotate_180],\n#         'rotation_270': [handle_rotate_270],\n#         'mirror_horizontal': [handle_flip_horizontal],\n#         'mirror_vertical': [handle_flip_vertical],\n#         'tiling': [handle_tile_pattern, handle_repeat_pattern],\n#         'expansion': [handle_upscale, handle_pad_to_square, handle_border_operations],\n#         'reduction': [handle_downscale, handle_crop_to_content, handle_extract_pattern],\n#         'color_mapping': [handle_color_mapping, handle_layered_transform, handle_color_cycle],\n#     }\n    \n#     for pattern_type in analysis['transform_type']:\n#         if pattern_type in handler_patterns:\n#             recommendations.extend(handler_patterns[pattern_type])\n            \n#     return recommendations\n\n# import time\n# from functools import lru_cache\n# from typing import Dict, List, Tuple, Optional, Callable\n# import numpy as np\n# from collections import defaultdict, Counter\n# import json\n# import os\n# import zipfile\n\n# # Debug mode configuration\n# DEBUG_MODE = True\n# DEBUG_LOG = []\n# PERFORMANCE_STATS = defaultdict(lambda: {'calls': 0, 'successes': 0, 'total_time': 0})\n\n# def debug_print(msg, level=\"INFO\"):\n#     \"\"\"Enhanced debug printing with levels and timing\"\"\"\n#     if DEBUG_MODE:\n#         timestamp = time.strftime(\"%H:%M:%S\")\n#         formatted_msg = f\"[{timestamp}] [{level}] {msg}\"\n#         print(formatted_msg)\n#         DEBUG_LOG.append(formatted_msg)\n\n# # Cache for handler results to avoid recomputation\n# HANDLER_CACHE = {}\n\n# def cache_key(task_data):\n#     \"\"\"Generate a cache key for task data\"\"\"\n#     inp = np.array(task_data['train'][0]['input'])\n#     out = np.array(task_data['train'][0]['output'])\n#     return f\"{inp.shape}_{out.shape}_{hash(inp.tobytes())}_{hash(out.tobytes())}\"\n\n# # Pattern combination helpers\n# def extract_function_body(solution_code):\n#     \"\"\"Extract the function body from a solution string\"\"\"\n#     lines = solution_code.strip().split('\\n')\n#     if not lines or not lines[0].startswith('def p(g):'):\n#         return \"\"\n#     # Skip the def line and get the body\n#     body_lines = []\n#     for line in lines[1:]:\n#         if line.startswith(' '):\n#             body_lines.append(line[1:])  # Remove one space of indentation\n#     return '\\n'.join(body_lines)\n\n# def indent_code(code, spaces):\n#     \"\"\"Indent code by specified spaces\"\"\"\n#     return '\\n'.join(' ' * spaces + line for line in code.split('\\n'))\n\n# # Enhanced pattern handlers with performance tracking\n# def timed_handler(func):\n#     \"\"\"Decorator to time handler execution\"\"\"\n#     def wrapper(task_data, analysis):\n#         start_time = time.time()\n#         result = None\n#         try:\n#             result = func(task_data, analysis)\n#             success = result is not None\n#         except Exception as e:\n#             success = False\n#             debug_print(f\"Handler {func.__name__} failed: {str(e)}\", \"ERROR\")\n        \n#         elapsed = time.time() - start_time\n#         PERFORMANCE_STATS[func.__name__]['calls'] += 1\n#         PERFORMANCE_STATS[func.__name__]['total_time'] += elapsed\n#         if success:\n#             PERFORMANCE_STATS[func.__name__]['successes'] += 1\n        \n#         return result\n#     return wrapper\n\n# # Additional pattern handlers to add before analyze_task\n\n# @timed_handler\n# def handle_diagonal_mirror(task_data, analysis):\n#     \"\"\"Mirror along main diagonal or anti-diagonal\"\"\"\n#     debug_print(f\"Trying handle_diagonal_mirror\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape and inp.shape[0] == inp.shape[1]:\n#             n = inp.shape[0]\n            \n#             # Main diagonal mirror\n#             test = np.zeros_like(inp)\n#             for i in range(n):\n#                 for j in range(n):\n#                     if inp[i,j] != 0:\n#                         test[i,j] = inp[i,j]\n#                         test[j,i] = inp[i,j]\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found diagonal mirror pattern (size={n}x{n})\")\n#                 return \"\"\"def p(g):\n#  n=len(g)\n#  res=[r[:]for r in g]\n#  for i in range(n):\n#   for j in range(n):\n#    if g[i][j]!=0:\n#     res[j][i]=g[i][j]\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a diagonal mirror pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_diagonal_mirror: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_color_inversion(task_data, analysis):\n#     \"\"\"Invert colors (e.g., 9-x for each color x)\"\"\"\n#     debug_print(f\"Trying handle_color_inversion\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             test = 9 - inp\n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found color inversion (9-x)\")\n#                 return \"\"\"def p(g):\n#  return[[9-x for x in r]for r in g]\n# \"\"\"\n#         debug_print(f\"   Not a color inversion pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_color_inversion: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_distance_coloring(task_data, analysis):\n#     \"\"\"Color based on Manhattan/Euclidean distance from specific points\"\"\"\n#     debug_print(f\"Trying handle_distance_coloring\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Find non-zero points in input\n#             seeds = [(i, j) for i in range(h) for j in range(w) if inp[i,j] != 0]\n            \n#             if seeds:\n#                 test = np.zeros_like(inp)\n#                 for i in range(h):\n#                     for j in range(w):\n#                         min_dist = min(abs(i-si) + abs(j-sj) for si, sj in seeds)\n#                         test[i,j] = min(min_dist, 9)\n                \n#                 if np.array_equal(test, out):\n#                     debug_print(f\"   Found distance coloring with {len(seeds)} seed points\")\n#                     return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  seeds=[(i,j)for i in range(h)for j in range(w)if g[i][j]!=0]\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    md=min(abs(i-si)+abs(j-sj)for si,sj in seeds)\n#    res[i][j]=min(md,9)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a distance coloring pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_distance_coloring: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_neighbor_sum_mod(task_data, analysis):\n#     \"\"\"Color based on sum of neighbors modulo some value\"\"\"\n#     debug_print(f\"Trying handle_neighbor_sum_mod\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             for mod in range(2, 10):\n#                 test = np.zeros_like(inp)\n#                 for i in range(h):\n#                     for j in range(w):\n#                         neighbor_sum = 0\n#                         for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                             ni, nj = i + di, j + dj\n#                             if 0 <= ni < h and 0 <= nj < w:\n#                                 neighbor_sum += inp[ni,nj]\n#                         test[i,j] = neighbor_sum % mod\n                \n#                 if np.array_equal(test, out):\n#                     debug_print(f\"   Found neighbor sum mod {mod}\")\n#                     return f\"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    ns=0\n#    for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#     ni,nj=i+di,j+dj\n#     if 0<=ni<h and 0<=nj<w:\n#      ns+=g[ni][nj]\n#    res[i][j]=ns%{mod}\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a neighbor sum mod pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_neighbor_sum_mod: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_wave_propagation(task_data, analysis):\n#     \"\"\"Propagate values outward like waves\"\"\"\n#     debug_print(f\"Trying handle_wave_propagation\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Try different wave propagation patterns\n#             for steps in range(1, 4):\n#                 current = np.copy(inp)\n#                 for _ in range(steps):\n#                     next_grid = np.copy(current)\n#                     for i in range(h):\n#                         for j in range(w):\n#                             if current[i,j] == 0:\n#                                 for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                                     ni, nj = i + di, j + dj\n#                                     if 0 <= ni < h and 0 <= nj < w and current[ni,nj] != 0:\n#                                         next_grid[i,j] = (current[ni,nj] + 1) % 10\n#                                         break\n#                     current = next_grid\n                \n#                 if np.array_equal(current, out):\n#                     debug_print(f\"   Found wave propagation with {steps} steps\")\n#                     return f\"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  c=[r[:]for r in g]\n#  for _ in range({steps}):\n#   n=[r[:]for r in c]\n#   for i in range(h):\n#    for j in range(w):\n#     if c[i][j]==0:\n#      for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#       ni,nj=i+di,j+dj\n#       if 0<=ni<h and 0<=nj<w and c[ni][nj]!=0:\n#        n[i][j]=(c[ni][nj]+1)%10\n#        break\n#   c=n\n#  return c\n# \"\"\"\n#         debug_print(f\"   Not a wave propagation pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_wave_propagation: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_quadrant_operations(task_data, analysis):\n#     \"\"\"Apply different operations to different quadrants\"\"\"\n#     debug_print(f\"Trying handle_quadrant_operations\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             mh, mw = h // 2, w // 2\n            \n#             test = np.copy(inp)\n            \n#             # Try different operations per quadrant\n#             # Top-left: +1, Top-right: +2, Bottom-left: +3, Bottom-right: +4\n#             test[:mh, :mw] = (inp[:mh, :mw] + 1) % 10\n#             test[:mh, mw:] = (inp[:mh, mw:] + 2) % 10\n#             test[mh:, :mw] = (inp[mh:, :mw] + 3) % 10\n#             test[mh:, mw:] = (inp[mh:, mw:] + 4) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found quadrant operations (+1,+2,+3,+4)\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  mh,mw=h//2,w//2\n#  res=[r[:]for r in g]\n#  for i in range(mh):\n#   for j in range(mw):\n#    res[i][j]=(g[i][j]+1)%10\n#  for i in range(mh):\n#   for j in range(mw,w):\n#    res[i][j]=(g[i][j]+2)%10\n#  for i in range(mh,h):\n#   for j in range(mw):\n#    res[i][j]=(g[i][j]+3)%10\n#  for i in range(mh,h):\n#   for j in range(mw,w):\n#    res[i][j]=(g[i][j]+4)%10\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a quadrant operations pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_quadrant_operations: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_ring_operations(task_data, analysis):\n#     \"\"\"Apply operations to concentric rings\"\"\"\n#     debug_print(f\"Trying handle_ring_operations\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Color based on ring distance from edge\n#             for i in range(h):\n#                 for j in range(w):\n#                     ring = min(i, j, h-1-i, w-1-j)\n#                     test[i,j] = (inp[i,j] + ring) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found ring operations\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    r=min(i,j,h-1-i,w-1-j)\n#    row.append((g[i][j]+r)%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a ring operations pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_ring_operations: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_pattern_frequency(task_data, analysis):\n#     \"\"\"Replace patterns based on their frequency\"\"\"\n#     debug_print(f\"Trying handle_pattern_frequency\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Count 2x2 patterns\n#             patterns = defaultdict(list)\n#             for i in range(h-1):\n#                 for j in range(w-1):\n#                     pattern = (inp[i,j], inp[i,j+1], inp[i+1,j], inp[i+1,j+1])\n#                     patterns[pattern].append((i, j))\n            \n#             # Replace most common pattern with specific value\n#             if patterns:\n#                 most_common = max(patterns.items(), key=lambda x: len(x[1]))\n#                 test = np.copy(inp)\n                \n#                 for i, j in most_common[1]:\n#                     test[i:i+2, j:j+2] = 5\n                \n#                 if np.array_equal(test, out):\n#                     debug_print(f\"   Found pattern frequency replacement\")\n#                     return \"\"\"def p(g):\n#  from collections import defaultdict\n#  h,w=len(g),len(g[0])\n#  pats=defaultdict(list)\n#  for i in range(h-1):\n#   for j in range(w-1):\n#    pat=(g[i][j],g[i][j+1],g[i+1][j],g[i+1][j+1])\n#    pats[pat].append((i,j))\n#  if pats:\n#   mc=max(pats.items(),key=lambda x:len(x[1]))\n#   res=[r[:]for r in g]\n#   for i,j in mc[1]:\n#    res[i][j]=5\n#    res[i][j+1]=5\n#    res[i+1][j]=5\n#    res[i+1][j+1]=5\n#   return res\n#  return g\n# \"\"\"\n#         debug_print(f\"   Not a pattern frequency replacement\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_pattern_frequency: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_sliding_window_ops(task_data, analysis):\n#     \"\"\"Apply operations using sliding windows\"\"\"\n#     debug_print(f\"Trying handle_sliding_window_ops\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # 3x3 sliding window - set center to max of window\n#             test = np.copy(inp)\n#             for i in range(1, h-1):\n#                 for j in range(1, w-1):\n#                     window_max = 0\n#                     for di in range(-1, 2):\n#                         for dj in range(-1, 2):\n#                             window_max = max(window_max, inp[i+di, j+dj])\n#                     test[i,j] = window_max\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found sliding window max operation\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(1,h-1):\n#   for j in range(1,w-1):\n#    wm=0\n#    for di in range(-1,2):\n#     for dj in range(-1,2):\n#      wm=max(wm,g[i+di][j+dj])\n#    res[i][j]=wm\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a sliding window operation\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_sliding_window_ops: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_cross_product_transform(task_data, analysis):\n#     \"\"\"Transform based on row/column products\"\"\"\n#     debug_print(f\"Trying handle_cross_product_transform\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Set each cell to (row_sum * col_sum) % 10\n#             row_sums = [sum(inp[i,:]) for i in range(h)]\n#             col_sums = [sum(inp[:,j]) for j in range(w)]\n            \n#             test = np.zeros_like(inp)\n#             for i in range(h):\n#                 for j in range(w):\n#                     test[i,j] = (row_sums[i] * col_sums[j]) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found cross product transform\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  rs=[sum(g[i])for i in range(h)]\n#  cs=[sum(g[i][j]for i in range(h))for j in range(w)]\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    row.append((rs[i]*cs[j])%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a cross product transform\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_cross_product_transform: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_spiral_fill(task_data, analysis):\n#     \"\"\"Fill grid in spiral pattern\"\"\"\n#     debug_print(f\"Trying handle_spiral_fill\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n#         test = np.zeros((h, w), dtype=int)\n        \n#         # Generate spiral pattern with incrementing values\n#         val = 1\n#         top, bottom, left, right = 0, h-1, 0, w-1\n        \n#         while top <= bottom and left <= right:\n#             for j in range(left, right+1):\n#                 test[top][j] = val % 10\n#                 val += 1\n#             top += 1\n            \n#             for i in range(top, bottom+1):\n#                 test[i][right] = val % 10\n#                 val += 1\n#             right -= 1\n            \n#             if top <= bottom:\n#                 for j in range(right, left-1, -1):\n#                     test[bottom][j] = val % 10\n#                     val += 1\n#                 bottom -= 1\n            \n#             if left <= right:\n#                 for i in range(bottom, top-1, -1):\n#                     test[i][left] = val % 10\n#                     val += 1\n#                 left += 1\n        \n#         if np.array_equal(test, out):\n#             debug_print(f\"   Found spiral fill pattern\")\n#             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  res=[[0]*w for _ in range(h)]\n#  v=1\n#  t,b,l,r=0,h-1,0,w-1\n#  while t<=b and l<=r:\n#   for j in range(l,r+1):\n#    res[t][j]=v%10\n#    v+=1\n#   t+=1\n#   for i in range(t,b+1):\n#    res[i][r]=v%10\n#    v+=1\n#   r-=1\n#   if t<=b:\n#    for j in range(r,l-1,-1):\n#     res[b][j]=v%10\n#     v+=1\n#    b-=1\n#   if l<=r:\n#    for i in range(b,t-1,-1):\n#     res[i][l]=v%10\n#     v+=1\n#    l+=1\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a spiral fill pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_spiral_fill: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_border_operations(task_data, analysis):\n#     \"\"\"Add or manipulate borders\"\"\"\n#     debug_print(f\"Trying handle_border_operations\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         # Add border\n#         if out.shape[0] == inp.shape[0] + 2 and out.shape[1] == inp.shape[1] + 2:\n#             for border_val in range(1, 10):\n#                 test = np.full((inp.shape[0]+2, inp.shape[1]+2), border_val)\n#                 test[1:-1, 1:-1] = inp\n#                 if np.array_equal(test, out):\n#                     debug_print(f\"   Found border addition with value {border_val}\")\n#                     return f\"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[{border_val}]*(w+2)for _ in range(h+2)]\n#  for i in range(h):\n#   for j in range(w):\n#    res[i+1][j+1]=g[i][j]\n#  return res\n# \"\"\"\n        \n#         # Remove border\n#         if inp.shape[0] == out.shape[0] + 2 and inp.shape[1] == out.shape[1] + 2:\n#             if np.array_equal(inp[1:-1, 1:-1], out):\n#                 debug_print(f\"   Found border removal\")\n#                 return \"\"\"def p(g):\n#  return[r[1:-1]for r in g[1:-1]]\n# \"\"\"\n#         debug_print(f\"   Not a border operation\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_border_operations: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_corner_operations(task_data, analysis):\n#     \"\"\"Special operations on corners\"\"\"\n#     debug_print(f\"Trying handle_corner_operations\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Set corners to specific value\n#             for val in range(1, 10):\n#                 test[0,0] = val\n#                 test[0,w-1] = val\n#                 test[h-1,0] = val\n#                 test[h-1,w-1] = val\n                \n#                 if np.array_equal(test, out):\n#                     debug_print(f\"   Found corner operations with value {val}\")\n#                     return f\"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  res[0][0]={val}\n#  res[0][w-1]={val}\n#  res[h-1][0]={val}\n#  res[h-1][w-1]={val}\n#  return res\n# \"\"\"\n#                 test = np.copy(inp)\n#         debug_print(f\"   Not a corner operation\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_corner_operations: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_chess_pattern(task_data, analysis):\n#     \"\"\"Create chess-like patterns\"\"\"\n#     debug_print(f\"Trying handle_chess_pattern\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n        \n#         # Standard chess pattern\n#         for c1 in range(10):\n#             for c2 in range(10):\n#                 if c1 != c2:\n#                     test = np.zeros((h, w), dtype=int)\n#                     for i in range(h):\n#                         for j in range(w):\n#                             test[i,j] = c1 if (i+j) % 2 == 0 else c2\n                    \n#                     if np.array_equal(test, out):\n#                         debug_print(f\"   Found chess pattern with colors {c1},{c2}\")\n#                         return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  return[[{c1} if(i+j)%2==0 else {c2} for j in range(w)]for i in range(h)]\n# \"\"\"\n#         debug_print(f\"   Not a chess pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_chess_pattern: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_diamond_pattern(task_data, analysis):\n#     \"\"\"Create diamond/rhombus patterns\"\"\"\n#     debug_print(f\"Trying handle_diamond_pattern\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n#         cx, cy = w // 2, h // 2\n        \n#         test = np.zeros((h, w), dtype=int)\n#         for i in range(h):\n#             for j in range(w):\n#                 manhattan_dist = abs(i - cy) + abs(j - cx)\n#                 test[i,j] = manhattan_dist % 10\n        \n#         if np.array_equal(test, out):\n#             debug_print(f\"   Found diamond pattern\")\n#             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  cx,cy={cx},{cy}\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    d=abs(i-cy)+abs(j-cx)\n#    row.append(d%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a diamond pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_diamond_pattern: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_triangular_numbers(task_data, analysis):\n#     \"\"\"Fill with triangular number patterns\"\"\"\n#     debug_print(f\"Trying handle_triangular_numbers\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n#         test = np.zeros((h, w), dtype=int)\n        \n#         # Fill with triangular numbers\n#         val = 0\n#         for i in range(h):\n#             for j in range(w):\n#                 test[i,j] = val % 10\n#                 val += (i * w + j + 1)\n        \n#         if np.array_equal(test, out):\n#             debug_print(f\"   Found triangular numbers pattern\")\n#             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  res=[]\n#  v=0\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    row.append(v%10)\n#    v+=i*w+j+1\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a triangular numbers pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_triangular_numbers: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_color_cycle(task_data, analysis):\n#     \"\"\"Cycle colors by fixed amount\"\"\"\n#     debug_print(f\"Trying handle_color_cycle\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             for shift in range(1, 10):\n#                 test = np.zeros_like(inp)\n#                 for i in range(inp.shape[0]):\n#                     for j in range(inp.shape[1]):\n#                         if inp[i,j] != 0:\n#                             test[i,j] = ((inp[i,j] - 1 + shift) % 9) + 1\n#                         else:\n#                             test[i,j] = 0\n                \n#                 if np.array_equal(test, out):\n#                     debug_print(f\"   Found color cycle with shift {shift}\")\n#                     return f\"\"\"def p(g):\n#  return[[((x-1+{shift})%9)+1 if x!=0 else 0 for x in r]for r in g]\n# \"\"\"\n#         debug_print(f\"   Not a color cycle pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_color_cycle: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_connectivity_color(task_data, analysis):\n#     \"\"\"Color based on connectivity\"\"\"\n#     debug_print(f\"Trying handle_connectivity_color\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             for i in range(h):\n#                 for j in range(w):\n#                     if inp[i,j] != 0:\n#                         # Count connected neighbors\n#                         count = 0\n#                         for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                             ni, nj = i + di, j + dj\n#                             if 0 <= ni < h and 0 <= nj < w and inp[ni,nj] != 0:\n#                                 count += 1\n#                         test[i,j] = count + 1\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found connectivity coloring\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    if g[i][j]!=0:\n#     c=0\n#     for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#      ni,nj=i+di,j+dj\n#      if 0<=ni<h and 0<=nj<w and g[ni][nj]!=0:\n#       c+=1\n#     res[i][j]=c+1\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a connectivity coloring pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_connectivity_color: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_layered_transform(task_data, analysis):\n#     \"\"\"Transform different color layers differently\"\"\"\n#     debug_print(f\"Trying handle_layered_transform\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             test = np.copy(inp)\n            \n#             # Try shifting each color layer\n#             unique_colors = np.unique(inp)\n#             shifts = {}\n            \n#             # Check if it's a simple per-color shift\n#             for color in unique_colors:\n#                 if color == 0:\n#                     continue\n                \n#                 mask = (inp == color)\n#                 out_vals = out[mask]\n                \n#                 if len(np.unique(out_vals)) == 1:\n#                     shifts[int(color)] = int(out_vals[0])\n            \n#             if shifts:\n#                 for i in range(inp.shape[0]):\n#                     for j in range(inp.shape[1]):\n#                         if inp[i,j] in shifts:\n#                             test[i,j] = shifts[inp[i,j]]\n                \n#                 if np.array_equal(test, out):\n#                     shift_str = ','.join(f'{k}:{v}' for k,v in shifts.items())\n#                     debug_print(f\"   Found layered transform with mapping {{{shift_str}}}\")\n#                     return f\"\"\"def p(g):\n#  m={{{shift_str}}}\n#  return[[m.get(x,x)for x in r]for r in g]\n# \"\"\"\n#         debug_print(f\"   Not a layered transform\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_layered_transform: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_local_symmetry(task_data, analysis):\n#     \"\"\"Complete local symmetry patterns\"\"\"\n#     debug_print(f\"Trying handle_local_symmetry\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Try to complete 3x3 symmetric patterns\n#             for i in range(1, h-1):\n#                 for j in range(1, w-1):\n#                     if inp[i,j] == 0:\n#                         # Check if surrounding forms symmetric pattern\n#                         vals = []\n#                         for di, dj in [(-1,-1), (-1,0), (-1,1), (0,-1), (0,1), (1,-1), (1,0), (1,1)]:\n#                             vals.append(inp[i+di, j+dj])\n                        \n#                         # Check various symmetries\n#                         if vals[0] == vals[7] and vals[1] == vals[6] and vals[2] == vals[5] and vals[3] == vals[4]:\n#                             # Point symmetric\n#                             if vals[0] != 0:\n#                                 test[i,j] = vals[0]\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found local symmetry completion\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(1,h-1):\n#   for j in range(1,w-1):\n#    if g[i][j]==0:\n#     v=[]\n#     for di,dj in[(-1,-1),(-1,0),(-1,1),(0,-1),(0,1),(1,-1),(1,0),(1,1)]:\n#      v.append(g[i+di][j+dj])\n#     if v[0]==v[7] and v[1]==v[6] and v[2]==v[5] and v[3]==v[4] and v[0]!=0:\n#      res[i][j]=v[0]\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a local symmetry pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_local_symmetry: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_shape_detection(task_data, analysis):\n#     \"\"\"Detect and transform specific shapes\"\"\"\n#     debug_print(f\"Trying handle_shape_detection\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Detect 2x2 squares and fill them\n#             for i in range(h-1):\n#                 for j in range(w-1):\n#                     square = inp[i:i+2, j:j+2]\n#                     if np.sum(square > 0) == 3:  # 3 out of 4 filled\n#                         # Find the empty spot and fill it\n#                         for di in range(2):\n#                             for dj in range(2):\n#                                 if square[di,dj] == 0:\n#                                     # Get the color from neighbors\n#                                     color = square[1-di, dj] if square[1-di, dj] != 0 else square[di, 1-dj]\n#                                     test[i+di, j+dj] = color\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found shape detection and completion\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(h-1):\n#   for j in range(w-1):\n#    s=[g[i+x][j+y]for x in range(2)for y in range(2)]\n#    if sum(1 for x in s if x>0)==3:\n#     for di in range(2):\n#      for dj in range(2):\n#       if g[i+di][j+dj]==0:\n#        c=g[i+1-di][j+dj]if g[i+1-di][j+dj]!=0 else g[i+di][j+1-dj]\n#        res[i+di][j+dj]=c\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a shape detection pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_shape_detection: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_directional_fill(task_data, analysis):\n#     \"\"\"Fill in specific directions until hitting boundary\"\"\"\n#     debug_print(f\"Trying handle_directional_fill\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Try filling right from non-zero values\n#             test = np.copy(inp)\n#             for i in range(h):\n#                 for j in range(w):\n#                     if inp[i,j] != 0:\n#                         # Fill right\n#                         for jj in range(j+1, w):\n#                             if inp[i,jj] == 0:\n#                                 test[i,jj] = inp[i,j]\n#                             else:\n#                                 break\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found directional fill (rightward)\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(h):\n#   for j in range(w):\n#    if g[i][j]!=0:\n#     for jj in range(j+1,w):\n#      if g[i][jj]==0:\n#       res[i][jj]=g[i][j]\n#      else:\n#       break\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a directional fill pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_directional_fill: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_boundary_trace(task_data, analysis):\n#     \"\"\"Trace boundaries of objects\"\"\"\n#     debug_print(f\"Trying handle_boundary_trace\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             # Find boundaries and trace them\n#             for i in range(h):\n#                 for j in range(w):\n#                     if inp[i,j] != 0:\n#                         is_boundary = False\n#                         # Check 8-connectivity\n#                         for di in [-1, 0, 1]:\n#                             for dj in [-1, 0, 1]:\n#                                 if di == 0 and dj == 0:\n#                                     continue\n#                                 ni, nj = i + di, j + dj\n#                                 if ni < 0 or ni >= h or nj < 0 or nj >= w or inp[ni,nj] == 0:\n#                                     is_boundary = True\n#                                     break\n#                             if is_boundary:\n#                                 break\n                        \n#                         if is_boundary:\n#                             test[i,j] = inp[i,j]\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found boundary trace\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    if g[i][j]!=0:\n#     b=False\n#     for di in[-1,0,1]:\n#      for dj in[-1,0,1]:\n#       if di==0 and dj==0:continue\n#       ni,nj=i+di,j+dj\n#       if ni<0 or ni>=h or nj<0 or nj>=w or g[ni][nj]==0:\n#        b=True\n#        break\n#      if b:break\n#     if b:\n#      res[i][j]=g[i][j]\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a boundary trace pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_boundary_trace: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_color_gradient_fill(task_data, analysis):\n#     \"\"\"Fill with color gradients between points\"\"\"\n#     debug_print(f\"Trying handle_color_gradient_fill\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Find pairs of same color and gradient fill between them\n#             colors = defaultdict(list)\n#             for i in range(h):\n#                 for j in range(w):\n#                     if inp[i,j] != 0:\n#                         colors[inp[i,j]].append((i,j))\n            \n#             for color, positions in colors.items():\n#                 if len(positions) == 2:\n#                     (y1, x1), (y2, x2) = positions\n                    \n#                     # Fill between them with gradient\n#                     if y1 == y2:  # Horizontal line\n#                         for x in range(min(x1, x2), max(x1, x2) + 1):\n#                             dist_ratio = abs(x - x1) / max(abs(x2 - x1), 1)\n#                             test[y1, x] = int(color * (1 - dist_ratio * 0.5)) % 10\n#                     elif x1 == x2:  # Vertical line\n#                         for y in range(min(y1, y2), max(y1, y2) + 1):\n#                             dist_ratio = abs(y - y1) / max(abs(y2 - y1), 1)\n#                             test[y, x1] = int(color * (1 - dist_ratio * 0.5)) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found color gradient fill\")\n#                 return \"\"\"def p(g):\n#  from collections import defaultdict\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  colors=defaultdict(list)\n#  for i in range(h):\n#   for j in range(w):\n#    if g[i][j]!=0:\n#     colors[g[i][j]].append((i,j))\n#  for c,pos in colors.items():\n#   if len(pos)==2:\n#    (y1,x1),(y2,x2)=pos\n#    if y1==y2:\n#     for x in range(min(x1,x2),max(x1,x2)+1):\n#      dr=abs(x-x1)/max(abs(x2-x1),1)\n#      res[y1][x]=int(c*(1-dr*0.5))%10\n#    elif x1==x2:\n#     for y in range(min(y1,y2),max(y1,y2)+1):\n#      dr=abs(y-y1)/max(abs(y2-y1),1)\n#      res[y][x1]=int(c*(1-dr*0.5))%10\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a color gradient fill pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_color_gradient_fill: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_pattern_interpolation(task_data, analysis):\n#     \"\"\"Interpolate patterns between key points\"\"\"\n#     debug_print(f\"Trying handle_pattern_interpolation\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Simple linear interpolation between non-zero values\n#             # Horizontal interpolation\n#             for i in range(h):\n#                 last_val = 0\n#                 last_pos = -1\n#                 for j in range(w):\n#                     if inp[i,j] != 0:\n#                         if last_val != 0 and last_pos >= 0:\n#                             # Interpolate between last_pos and j\n#                             for jj in range(last_pos + 1, j):\n#                                 ratio = (jj - last_pos) / (j - last_pos)\n#                                 test[i,jj] = int(last_val + ratio * (inp[i,j] - last_val)) % 10\n#                         last_val = inp[i,j]\n#                         last_pos = j\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found pattern interpolation\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(h):\n#   lv=0\n#   lp=-1\n#   for j in range(w):\n#    if g[i][j]!=0:\n#     if lv!=0 and lp>=0:\n#      for jj in range(lp+1,j):\n#       r=(jj-lp)/(j-lp)\n#       res[i][jj]=int(lv+r*(g[i][j]-lv))%10\n#     lv=g[i][j]\n#     lp=j\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a pattern interpolation\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_pattern_interpolation: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_region_growing(task_data, analysis):\n#     \"\"\"Grow regions from seed points\"\"\"\n#     debug_print(f\"Trying handle_region_growing\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Grow each color region by one pixel\n#             for color in range(1, 10):\n#                 positions = np.argwhere(inp == color)\n#                 for y, x in positions:\n#                     for dy, dx in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                         ny, nx = y + dy, x + dx\n#                         if 0 <= ny < h and 0 <= nx < w and inp[ny,nx] == 0:\n#                             test[ny,nx] = color\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found region growing\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for c in range(1,10):\n#   pos=[(i,j)for i in range(h)for j in range(w)if g[i][j]==c]\n#   for y,x in pos:\n#    for dy,dx in[(0,1),(1,0),(0,-1),(-1,0)]:\n#     ny,nx=y+dy,x+dx\n#     if 0<=ny<h and 0<=nx<w and g[ny][nx]==0:\n#      res[ny][nx]=c\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a region growing pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_region_growing: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_symmetry_detection_fill(task_data, analysis):\n#     \"\"\"Detect partial symmetry and complete it\"\"\"\n#     debug_print(f\"Trying handle_symmetry_detection_fill\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Try vertical symmetry completion\n#             test = np.copy(inp)\n#             for i in range(h):\n#                 for j in range(w//2):\n#                     if inp[i,j] != 0 and inp[i,w-1-j] == 0:\n#                         test[i,w-1-j] = inp[i,j]\n#                     elif inp[i,j] == 0 and inp[i,w-1-j] != 0:\n#                         test[i,j] = inp[i,w-1-j]\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found symmetry detection and completion\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(h):\n#   for j in range(w//2):\n#    if g[i][j]!=0 and g[i][w-1-j]==0:\n#     res[i][w-1-j]=g[i][j]\n#    elif g[i][j]==0 and g[i][w-1-j]!=0:\n#     res[i][j]=g[i][w-1-j]\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a symmetry detection fill pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_symmetry_detection_fill: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_pixel_sorting(task_data, analysis):\n#     \"\"\"Sort pixels in each row or column\"\"\"\n#     debug_print(f\"Trying handle_pixel_sorting\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             # Try sorting each row\n#             test = np.array([sorted(row) for row in inp])\n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found row sorting\")\n#                 return \"\"\"def p(g):\n#  return[sorted(r)for r in g]\n# \"\"\"\n            \n#             # Try sorting each column\n#             test = np.array([sorted(col) for col in inp.T]).T\n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found column sorting\")\n#                 return \"\"\"def p(g):\n#  import numpy as np\n#  return np.array([sorted(c)for c in np.array(g).T]).T.tolist()\n# \"\"\"\n#         debug_print(f\"   Not a pixel sorting pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_pixel_sorting: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_fractal_pattern(task_data, analysis):\n#     \"\"\"Generate fractal-like patterns\"\"\"\n#     debug_print(f\"Trying handle_fractal_pattern\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n        \n#         # Sierpinski-like pattern\n#         test = np.zeros((h, w), dtype=int)\n#         for i in range(h):\n#             for j in range(w):\n#                 if i & j == 0:\n#                     test[i,j] = 1\n        \n#         if np.array_equal(test, out):\n#             debug_print(f\"   Found fractal pattern (Sierpinski-like)\")\n#             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  return[[1 if i&j==0 else 0 for j in range(w)]for i in range(h)]\n# \"\"\"\n#         debug_print(f\"   Not a fractal pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_fractal_pattern: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_position_encoding(task_data, analysis):\n#     \"\"\"Encode position information in output\"\"\"\n#     debug_print(f\"Trying handle_position_encoding\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n        \n#         # Try various position encodings\n#         # Row + Column mod 10\n#         test = np.zeros((h, w), dtype=int)\n#         for i in range(h):\n#             for j in range(w):\n#                 test[i,j] = (i + j) % 10\n        \n#         if np.array_equal(test, out):\n#             debug_print(f\"   Found position encoding (i+j mod 10)\")\n#             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  return[[(i+j)%10 for j in range(w)]for i in range(h)]\n# \"\"\"\n        \n#         # Row * Column mod 10\n#         test = np.zeros((h, w), dtype=int)\n#         for i in range(h):\n#             for j in range(w):\n#                 test[i,j] = (i * j) % 10\n        \n#         if np.array_equal(test, out):\n#             debug_print(f\"   Found position encoding (i*j mod 10)\")\n#             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  return[[(i*j)%10 for j in range(w)]for i in range(h)]\n# \"\"\"\n#         debug_print(f\"   Not a position encoding pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_position_encoding: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_path_tracing(task_data, analysis):\n#     \"\"\"Trace paths between connected components\"\"\"\n#     debug_print(f\"Trying handle_path_tracing\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Find all non-zero positions\n#             positions = [(i,j) for i in range(h) for j in range(w) if inp[i,j] != 0]\n            \n#             # Try connecting adjacent same-color pixels\n#             for i, (y1, x1) in enumerate(positions):\n#                 for y2, x2 in positions[i+1:]:\n#                     if inp[y1,x1] == inp[y2,x2]:\n#                         # Connect if adjacent (including diagonally)\n#                         if abs(y1-y2) <= 1 and abs(x1-x2) <= 1:\n#                             # Draw line between them\n#                             if y1 == y2:\n#                                 for x in range(min(x1,x2), max(x1,x2)+1):\n#                                     test[y1,x] = inp[y1,x1]\n#                             elif x1 == x2:\n#                                 for y in range(min(y1,y2), max(y1,y2)+1):\n#                                     test[y,x1] = inp[y1,x1]\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found path tracing\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  pos=[(i,j)for i in range(h)for j in range(w)if g[i][j]!=0]\n#  for i,(y1,x1)in enumerate(pos):\n#   for y2,x2 in pos[i+1:]:\n#    if g[y1][x1]==g[y2][x2]:\n#     if abs(y1-y2)<=1 and abs(x1-x2)<=1:\n#      if y1==y2:\n#       for x in range(min(x1,x2),max(x1,x2)+1):\n#        res[y1][x]=g[y1][x1]\n#      elif x1==x2:\n#       for y in range(min(y1,y2),max(y1,y2)+1):\n#        res[y][x1]=g[y1][x1]\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a path tracing pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_path_tracing: {str(e)}\")\n#     return None\n\n# # NEW HANDLERS START HERE\n\n# @timed_handler\n# def handle_mask_arithmetic(task_data, analysis):\n#     \"\"\"Apply arithmetic operations with specific masks\"\"\"\n#     debug_print(f\"Trying handle_mask_arithmetic\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Try diagonal mask operations\n#             test = np.copy(inp)\n#             for i in range(h):\n#                 for j in range(w):\n#                     if i == j:  # Main diagonal\n#                         test[i,j] = (inp[i,j] * 2) % 10\n#                     elif i + j == h - 1:  # Anti-diagonal\n#                         test[i,j] = (inp[i,j] + 3) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found mask arithmetic (diagonal *2, anti-diagonal +3)\")\n#                 return \"\"\"def p(g):\n#  h=len(g)\n#  res=[r[:]for r in g]\n#  for i in range(h):\n#   for j in range(len(g[0])):\n#    if i==j:\n#     res[i][j]=(g[i][j]*2)%10\n#    elif i+j==h-1:\n#     res[i][j]=(g[i][j]+3)%10\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a mask arithmetic pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_mask_arithmetic: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_wraparound_shift(task_data, analysis):\n#     \"\"\"Shift with wraparound at edges\"\"\"\n#     debug_print(f\"Trying handle_wraparound_shift\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Try circular shift right\n#             for shift in range(1, w):\n#                 test = np.zeros_like(inp)\n#                 for i in range(h):\n#                     for j in range(w):\n#                         test[i,(j+shift)%w] = inp[i,j]\n                \n#                 if np.array_equal(test, out):\n#                     debug_print(f\"   Found wraparound shift (right by {shift})\")\n#                     return f\"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    res[i][(j+{shift})%w]=g[i][j]\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a wraparound shift pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_wraparound_shift: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_1d_interleave(task_data, analysis):\n#     \"\"\"Interleave elements in 1D representation\"\"\"\n#     debug_print(f\"Trying handle_1d_interleave\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         arr_in = to_1d_raster(inp.tolist(), 'row_major')\n#         arr_out = to_1d_raster(out.tolist(), 'row_major')\n        \n#         # Try interleaving first half and second half\n#         if len(arr_in) % 2 == 0:\n#             half = len(arr_in) // 2\n#             interleaved = []\n#             for i in range(half):\n#                 interleaved.append(arr_in[i])\n#                 interleaved.append(arr_in[half + i])\n            \n#             if interleaved == arr_out:\n#                 h, w = out.shape\n#                 debug_print(f\"   Found 1D interleave pattern\")\n#                 return f\"\"\"def p(g):\n#  arr=[g[i][j]for i in range(len(g))for j in range(len(g[0]))]\n#  half=len(arr)//2\n#  res=[]\n#  for i in range(half):\n#   res.append(arr[i])\n#   res.append(arr[half+i])\n#  h,w={h},{w}\n#  out=[[0]*w for _ in range(h)]\n#  for i,v in enumerate(res):\n#   out[i//w][i%w]=v\n#  return out\n# \"\"\"\n#         debug_print(f\"   Not a 1D interleave pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_1d_interleave: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_diagonal_stripes(task_data, analysis):\n#     \"\"\"Create diagonal stripe patterns\"\"\"\n#     debug_print(f\"Trying handle_diagonal_stripes\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n        \n#         # Try diagonal stripes\n#         for stripe_width in range(1, 5):\n#             for c1 in range(10):\n#                 for c2 in range(10):\n#                     if c1 != c2:\n#                         test = np.zeros((h, w), dtype=int)\n#                         for i in range(h):\n#                             for j in range(w):\n#                                 if ((i + j) // stripe_width) % 2 == 0:\n#                                     test[i,j] = c1\n#                                 else:\n#                                     test[i,j] = c2\n                        \n#                         if np.array_equal(test, out):\n#                             debug_print(f\"   Found diagonal stripes (width={stripe_width}, colors={c1},{c2})\")\n#                             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    if((i+j)//{stripe_width})%2==0:\n#     row.append({c1})\n#    else:\n#     row.append({c2})\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a diagonal stripes pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_diagonal_stripes: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_cellular_rule(task_data, analysis):\n#     \"\"\"Apply custom cellular automaton rules\"\"\"\n#     debug_print(f\"Trying handle_cellular_rule\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             # Rule: cell becomes sum of all 8 neighbors mod 10\n#             for i in range(h):\n#                 for j in range(w):\n#                     total = 0\n#                     for di in [-1, 0, 1]:\n#                         for dj in [-1, 0, 1]:\n#                             if di == 0 and dj == 0:\n#                                 continue\n#                             ni, nj = (i + di) % h, (j + dj) % w  # Wraparound\n#                             total += inp[ni,nj]\n#                     test[i,j] = total % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found cellular rule (sum of 8 neighbors mod 10)\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    t=0\n#    for di in[-1,0,1]:\n#     for dj in[-1,0,1]:\n#      if di==0 and dj==0:continue\n#      ni,nj=(i+di)%h,(j+dj)%w\n#      t+=g[ni][nj]\n#    res[i][j]=t%10\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a cellular rule pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_cellular_rule: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_prime_mask(task_data, analysis):\n#     \"\"\"Apply operations based on prime number positions\"\"\"\n#     debug_print(f\"Trying handle_prime_mask\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             def is_prime(n):\n#                 if n < 2: return False\n#                 for i in range(2, int(n**0.5) + 1):\n#                     if n % i == 0: return False\n#                 return True\n            \n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             for i in range(h):\n#                 for j in range(w):\n#                     pos = i * w + j\n#                     if is_prime(pos):\n#                         test[i,j] = (inp[i,j] + 1) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found prime mask pattern\")\n#                 return \"\"\"def p(g):\n#  def ip(n):\n#   if n<2:return False\n#   for i in range(2,int(n**0.5)+1):\n#    if n%i==0:return False\n#   return True\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(h):\n#   for j in range(w):\n#    if ip(i*w+j):\n#     res[i][j]=(g[i][j]+1)%10\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a prime mask pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_prime_mask: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_bit_pattern_mask(task_data, analysis):\n#     \"\"\"Apply operations based on bit patterns\"\"\"\n#     debug_print(f\"Trying handle_bit_pattern_mask\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Apply operation if position has odd number of 1s in binary\n#             for i in range(h):\n#                 for j in range(w):\n#                     pos = i * w + j\n#                     if bin(pos).count('1') % 2 == 1:\n#                         test[i,j] = (inp[i,j] * 3) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found bit pattern mask\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(h):\n#   for j in range(w):\n#    if bin(i*w+j).count('1')%2==1:\n#     res[i][j]=(g[i][j]*3)%10\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a bit pattern mask\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_bit_pattern_mask: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_symmetric_operations(task_data, analysis):\n#     \"\"\"Apply operations that maintain symmetry\"\"\"\n#     debug_print(f\"Trying handle_symmetric_operations\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Apply operation to maintain vertical symmetry\n#             for i in range(h):\n#                 for j in range(w//2):\n#                     val = (inp[i,j] + inp[i,w-1-j]) % 10\n#                     test[i,j] = val\n#                     test[i,w-1-j] = val\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found symmetric operations\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  for i in range(h):\n#   for j in range(w//2):\n#    v=(g[i][j]+g[i][w-1-j])%10\n#    res[i][j]=v\n#    res[i][w-1-j]=v\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a symmetric operations pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_symmetric_operations: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_distance_transform(task_data, analysis):\n#     \"\"\"Transform based on distance from edges\"\"\"\n#     debug_print(f\"Trying handle_distance_transform\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             for i in range(h):\n#                 for j in range(w):\n#                     edge_dist = min(i, j, h-1-i, w-1-j)\n#                     test[i,j] = (inp[i,j] + edge_dist * 2) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found distance transform\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    ed=min(i,j,h-1-i,w-1-j)\n#    row.append((g[i][j]+ed*2)%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a distance transform pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_distance_transform: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_modular_grid(task_data, analysis):\n#     \"\"\"Apply modular arithmetic based on grid position\"\"\"\n#     debug_print(f\"Trying handle_modular_grid\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             for mod_h in range(2, 5):\n#                 for mod_w in range(2, 5):\n#                     test = np.copy(inp)\n#                     for i in range(h):\n#                         for j in range(w):\n#                             factor = (i % mod_h) * mod_w + (j % mod_w)\n#                             test[i,j] = (inp[i,j] + factor) % 10\n                    \n#                     if np.array_equal(test, out):\n#                         debug_print(f\"   Found modular grid (mod_h={mod_h}, mod_w={mod_w})\")\n#                         return f\"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    f=(i%{mod_h})*{mod_w}+(j%{mod_w})\n#    row.append((g[i][j]+f)%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a modular grid pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_modular_grid: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_pattern_mask_multiply(task_data, analysis):\n#     \"\"\"Multiply by mask pattern\"\"\"\n#     debug_print(f\"Trying handle_pattern_mask_multiply\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Try multiplication by position-based mask\n#             test = np.zeros_like(inp)\n#             for i in range(h):\n#                 for j in range(w):\n#                     mask_val = 1 + (i + j) % 3\n#                     test[i,j] = (inp[i,j] * mask_val) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found pattern mask multiply\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    m=1+(i+j)%3\n#    row.append((g[i][j]*m)%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a pattern mask multiply\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_pattern_mask_multiply: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_recursive_fill(task_data, analysis):\n#     \"\"\"Recursively fill based on neighbors\"\"\"\n#     debug_print(f\"Trying handle_recursive_fill\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.copy(inp)\n            \n#             # Fill zeros with average of non-zero neighbors\n#             changed = True\n#             while changed:\n#                 changed = False\n#                 new_test = np.copy(test)\n#                 for i in range(h):\n#                     for j in range(w):\n#                         if test[i,j] == 0:\n#                             neighbors = []\n#                             for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                                 ni, nj = i + di, j + dj\n#                                 if 0 <= ni < h and 0 <= nj < w and test[ni,nj] != 0:\n#                                     neighbors.append(test[ni,nj])\n#                             if neighbors:\n#                                 new_test[i,j] = sum(neighbors) // len(neighbors)\n#                                 changed = True\n#                 test = new_test\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found recursive fill\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[r[:]for r in g]\n#  ch=True\n#  while ch:\n#   ch=False\n#   nr=[r[:]for r in res]\n#   for i in range(h):\n#    for j in range(w):\n#     if res[i][j]==0:\n#      n=[]\n#      for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#       ni,nj=i+di,j+dj\n#       if 0<=ni<h and 0<=nj<w and res[ni][nj]!=0:\n#        n.append(res[ni][nj])\n#      if n:\n#       nr[i][j]=sum(n)//len(n)\n#       ch=True\n#   res=nr\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a recursive fill pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_recursive_fill: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_gradient_mask(task_data, analysis):\n#     \"\"\"Apply gradient-based masks\"\"\"\n#     debug_print(f\"Trying handle_gradient_mask\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n        \n#         # Linear gradient from top-left to bottom-right\n#         test = np.zeros((h, w), dtype=int)\n#         for i in range(h):\n#             for j in range(w):\n#                 grad = (i + j) * 9 // (h + w - 2) if h + w > 2 else 0\n#                 test[i,j] = grad\n        \n#         if np.array_equal(test, out):\n#             debug_print(f\"   Found gradient mask\")\n#             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    gr=(i+j)*9//(h+w-2)if h+w>2 else 0\n#    row.append(gr)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a gradient mask pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_gradient_mask: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_phase_shift_pattern(task_data, analysis):\n#     \"\"\"Apply phase-shifted periodic patterns\"\"\"\n#     debug_print(f\"Trying handle_phase_shift_pattern\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Try phase shift based on row\n#             test = np.zeros_like(inp)\n#             for i in range(h):\n#                 for j in range(w):\n#                     phase = i % 3\n#                     test[i,j] = (inp[i,j] + j + phase) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found phase shift pattern\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    ph=i%3\n#    row.append((g[i][j]+j+ph)%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a phase shift pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_phase_shift_pattern: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_overflow_mask(task_data, analysis):\n#     \"\"\"Apply masks that overflow grid boundaries\"\"\"\n#     debug_print(f\"Trying handle_overflow_mask\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             # Virtual larger grid mask\n#             for i in range(h):\n#                 for j in range(w):\n#                     # Treat as if part of larger grid\n#                     virtual_i = i + h\n#                     virtual_j = j + w\n#                     mask_val = (virtual_i * virtual_j) % 10\n#                     test[i,j] = (inp[i,j] + mask_val) % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found overflow mask\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    vi=i+h\n#    vj=j+w\n#    m=(vi*vj)%10\n#    row.append((g[i][j]+m)%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not an overflow mask pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_overflow_mask: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_1d_block_swap(task_data, analysis):\n#     \"\"\"Swap blocks in 1D representation\"\"\"\n#     debug_print(f\"Trying handle_1d_block_swap\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         arr_in = to_1d_raster(inp.tolist(), 'row_major')\n#         arr_out = to_1d_raster(out.tolist(), 'row_major')\n        \n#         # Try swapping blocks of different sizes\n#         for block_size in range(2, len(arr_in)//2 + 1):\n#             if len(arr_in) % block_size == 0:\n#                 blocks = [arr_in[i:i+block_size] for i in range(0, len(arr_in), block_size)]\n#                 # Try reversing blocks\n#                 reversed_blocks = blocks[::-1]\n#                 test = []\n#                 for block in reversed_blocks:\n#                     test.extend(block)\n                \n#                 if test == arr_out:\n#                     h, w = out.shape\n#                     debug_print(f\"   Found 1D block swap (block_size={block_size})\")\n#                     return f\"\"\"def p(g):\n#  arr=[g[i][j]for i in range(len(g))for j in range(len(g[0]))]\n#  bs={block_size}\n#  blocks=[arr[i:i+bs]for i in range(0,len(arr),bs)]\n#  rb=blocks[::-1]\n#  res=[]\n#  for b in rb:\n#   res.extend(b)\n#  h,w={h},{w}\n#  out=[[0]*w for _ in range(h)]\n#  for i,v in enumerate(res):\n#   out[i//w][i%w]=v\n#  return out\n# \"\"\"\n#         debug_print(f\"   Not a 1D block swap pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_1d_block_swap: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_number_sequence_fill(task_data, analysis):\n#     \"\"\"Fill with various number sequences\"\"\"\n#     debug_print(f\"Trying handle_number_sequence_fill\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         h, w = out.shape\n        \n#         # Fibonacci mod 10\n#         test = np.zeros((h, w), dtype=int)\n#         a, b = 0, 1\n#         for i in range(h):\n#             for j in range(w):\n#                 test[i,j] = a % 10\n#                 a, b = b, (a + b)\n        \n#         if np.array_equal(test, out):\n#             debug_print(f\"   Found Fibonacci sequence fill\")\n#             return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  res=[]\n#  a,b=0,1\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    row.append(a%10)\n#    a,b=b,a+b\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a number sequence fill pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_number_sequence_fill: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_complex_bit_ops(task_data, analysis):\n#     \"\"\"Complex bit manipulation patterns\"\"\"\n#     debug_print(f\"Trying handle_complex_bit_ops\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             # XOR with position and rotate bits\n#             for i in range(h):\n#                 for j in range(w):\n#                     pos = (i * w + j) % 8\n#                     val = inp[i,j]\n#                     # Rotate bits left by position\n#                     rotated = ((val << pos) | (val >> (8 - pos))) & 0xFF\n#                     test[i,j] = rotated % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found complex bit operations\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    pos=(i*w+j)%8\n#    v=g[i][j]\n#    r=((v<<pos)|(v>>(8-pos)))&0xFF\n#    row.append(r%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a complex bit ops pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_complex_bit_ops: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_transformation_chain(task_data, analysis):\n#     \"\"\"Chain multiple transformations\"\"\"\n#     debug_print(f\"Trying handle_transformation_chain\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n            \n#             # Try: add position, then multiply by 2, then mod 10\n#             test = np.zeros_like(inp)\n#             for i in range(h):\n#                 for j in range(w):\n#                     step1 = inp[i,j] + i + j\n#                     step2 = step1 * 2\n#                     test[i,j] = step2 % 10\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found transformation chain\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[]\n#  for i in range(h):\n#   row=[]\n#   for j in range(w):\n#    s1=g[i][j]+i+j\n#    s2=s1*2\n#    row.append(s2%10)\n#   res.append(row)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a transformation chain pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_transformation_chain: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_neighbor_product(task_data, analysis):\n#     \"\"\"Product of neighbors\"\"\"\n#     debug_print(f\"Trying handle_neighbor_product\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             for i in range(h):\n#                 for j in range(w):\n#                     product = 1\n#                     count = 0\n#                     for di, dj in [(0,1), (1,0), (0,-1), (-1,0)]:\n#                         ni, nj = i + di, j + dj\n#                         if 0 <= ni < h and 0 <= nj < w:\n#                             if inp[ni,nj] != 0:\n#                                 product *= inp[ni,nj]\n#                                 count += 1\n#                     if count > 0:\n#                         test[i,j] = product % 10\n#                     else:\n#                         test[i,j] = inp[i,j]\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found neighbor product\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    pr=1\n#    c=0\n#    for di,dj in[(0,1),(1,0),(0,-1),(-1,0)]:\n#     ni,nj=i+di,j+dj\n#     if 0<=ni<h and 0<=nj<w:\n#      if g[ni][nj]!=0:\n#       pr*=g[ni][nj]\n#       c+=1\n#    if c>0:\n#     res[i][j]=pr%10\n#    else:\n#     res[i][j]=g[i][j]\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a neighbor product pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_neighbor_product: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_1d_segment_reverse(task_data, analysis):\n#     \"\"\"Reverse specific segments in 1D\"\"\"\n#     debug_print(f\"Trying handle_1d_segment_reverse\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         arr_in = to_1d_raster(inp.tolist(), 'row_major')\n#         arr_out = to_1d_raster(out.tolist(), 'row_major')\n        \n#         # Try reversing segments between zeros\n#         segments = []\n#         current = []\n#         for val in arr_in:\n#             if val == 0:\n#                 if current:\n#                     segments.append(current[::-1])\n#                     current = []\n#                 segments.append([0])\n#             else:\n#                 current.append(val)\n#         if current:\n#             segments.append(current[::-1])\n        \n#         test = []\n#         for seg in segments:\n#             test.extend(seg)\n        \n#         if test == arr_out:\n#             h, w = out.shape\n#             debug_print(f\"   Found 1D segment reverse\")\n#             return f\"\"\"def p(g):\n#  arr=[g[i][j]for i in range(len(g))for j in range(len(g[0]))]\n#  segs=[]\n#  cur=[]\n#  for v in arr:\n#   if v==0:\n#    if cur:\n#     segs.append(cur[::-1])\n#     cur=[]\n#    segs.append([0])\n#   else:\n#    cur.append(v)\n#  if cur:\n#   segs.append(cur[::-1])\n#  res=[]\n#  for s in segs:\n#   res.extend(s)\n#  h,w={h},{w}\n#  out=[[0]*w for _ in range(h)]\n#  for i,v in enumerate(res):\n#   out[i//w][i%w]=v\n#  return out\n# \"\"\"\n#         debug_print(f\"   Not a 1D segment reverse pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_1d_segment_reverse: {str(e)}\")\n#     return None\n\n# @timed_handler\n# def handle_symmetric_mask_ops(task_data, analysis):\n#     \"\"\"Operations that create symmetric patterns\"\"\"\n#     debug_print(f\"Trying handle_symmetric_mask_ops\")\n#     try:\n#         inp, out = (np.array(task_data['train'][0][k]) for k in ('input','output'))\n        \n#         if inp.shape == out.shape:\n#             h, w = inp.shape\n#             test = np.zeros_like(inp)\n            \n#             # Create symmetric pattern from input\n#             for i in range(h):\n#                 for j in range(w):\n#                     # Take max of symmetric positions\n#                     sym_vals = [inp[i,j]]\n#                     if i < h-1-i:\n#                         sym_vals.append(inp[h-1-i,j])\n#                     if j < w-1-j:\n#                         sym_vals.append(inp[i,w-1-j])\n#                     if i < h-1-i and j < w-1-j:\n#                         sym_vals.append(inp[h-1-i,w-1-j])\n#                     test[i,j] = max(sym_vals)\n            \n#             if np.array_equal(test, out):\n#                 debug_print(f\"   Found symmetric mask operations\")\n#                 return \"\"\"def p(g):\n#  h,w=len(g),len(g[0])\n#  res=[[0]*w for _ in range(h)]\n#  for i in range(h):\n#   for j in range(w):\n#    sv=[g[i][j]]\n#    if i<h-1-i:\n#     sv.append(g[h-1-i][j])\n#    if j<w-1-j:\n#     sv.append(g[i][w-1-j])\n#    if i<h-1-i and j<w-1-j:\n#     sv.append(g[h-1-i][w-1-j])\n#    res[i][j]=max(sv)\n#  return res\n# \"\"\"\n#         debug_print(f\"   Not a symmetric mask operations pattern\")\n#     except Exception as e:\n#         debug_print(f\"  !! Exception in handle_symmetric_mask_ops: {str(e)}\")\n#     return None\n\n# def analyze_task(task_data):\n#     \"\"\"Enhanced task analysis with pattern detection\"\"\"\n#     all_examples = task_data['train'] + task_data['test']\n#     analysis = {\n#         'color_changes': defaultdict(set),\n#         'shape_changes': set(),\n#         'symmetry': None,\n#         'arithmetic': None,\n#         'pattern_types': set(),\n#         'color_count': set(),\n#         'has_objects': False,\n#         'has_lines': False,\n#         'has_repeating_patterns': False,\n#     }\n    \n#     for example in all_examples:\n#         in_grid = np.array(example['input'])\n#         out_grid = np.array(example['output'])\n        \n#         analysis['shape_changes'].add((in_grid.shape, out_grid.shape))\n#         analysis['color_count'].add(len(np.unique(in_grid)))\n        \n#         # Check for objects\n#         if len(np.unique(in_grid)) > 2:\n#             analysis['has_objects'] = True\n        \n#         # Check for lines\n#         for i in range(in_grid.shape[0]):\n#             if len(np.unique(in_grid[i,:])) == 1 and in_grid[i,0] != 0:\n#                 analysis['has_lines'] = True\n        \n#         for (i,j), val in np.ndenumerate(in_grid):\n#             if i < out_grid.shape[0] and j < out_grid.shape[1]:\n#                 if in_grid[i,j] != out_grid[i,j]:\n#                     analysis['color_changes'][(i,j)].add((int(in_grid[i,j]), int(out_grid[i,j])))\n    \n#     return analysis\n\n# def verify_solution(solution_code, task_data):\n#     \"\"\"Verify solution against all training examples\"\"\"\n#     try:\n#         # Create a local namespace for execution\n#         local_namespace = {}\n#         exec(solution_code, globals(), local_namespace)\n        \n#         if 'p' not in local_namespace:\n#             return False\n        \n#         p = local_namespace['p']\n        \n#         # Test against all training examples\n#         for idx, example in enumerate(task_data['train']):\n#             input_grid = example['input']\n#             expected = example['output']\n#             try:\n#                 actual = p(input_grid)\n#                 if actual != expected:\n#                     debug_print(f\"  Failed on training example {idx}\", \"WARNING\")\n#                     return False\n#             except Exception as e:\n#                 debug_print(f\"  Exception on training example {idx}: {str(e)}\", \"ERROR\")\n#                 return False\n#         return True\n#     except Exception as e:\n#         debug_print(f\"  Verification failed: {str(e)}\", \"ERROR\")\n#         return False\n\n# # Pattern combination functions\n# def try_sequential_combinations(task_data, pattern_handlers, analysis):\n#     \"\"\"Try applying two patterns in sequence\"\"\"\n#     debug_print(\"=== Trying sequential pattern combinations ===\", \"INFO\")\n    \n#     # Get candidate handlers that might work together\n#     candidate_handlers = []\n    \n#     # Quick test each handler to see if it produces valid intermediate results\n#     for handler in pattern_handlers[:30]:  # Limit to avoid explosion\n#         try:\n#             solution = handler(task_data, analysis)\n#             if solution and solution != \"\"\"def p(g):\\n return g\\n\"\"\":\n#                 candidate_handlers.append((handler, solution))\n#         except:\n#             pass\n    \n#     debug_print(f\"Found {len(candidate_handlers)} candidate handlers for combination\", \"INFO\")\n    \n#     # Try combining pairs\n#     for i, (handler1, sol1) in enumerate(candidate_handlers[:10]):\n#         for j, (handler2, sol2) in enumerate(candidate_handlers[:10]):\n#             if i == j:\n#                 continue\n            \n#             debug_print(f\"  Trying {handler1.__name__}  {handler2.__name__}\", \"DEBUG\")\n            \n#             # Create combined transformation\n#             combined_solution = create_sequential_combination(sol1, sol2, handler1.__name__, handler2.__name__)\n            \n#             if verify_solution(combined_solution, task_data):\n#                 debug_print(f\" Found sequential combination: {handler1.__name__}  {handler2.__name__}\", \"SUCCESS\")\n#                 return combined_solution\n    \n#     return None\n\n# def create_sequential_combination(sol1, sol2, name1, name2):\n#     \"\"\"Create a solution that applies sol1 then sol2\"\"\"\n#     body1 = extract_function_body(sol1)\n#     body2 = extract_function_body(sol2)\n    \n#     return f\"\"\"def p(g):\n#  # Step 1: {name1}\n#  def t1(g):\n# {indent_code(body1, 2)}\n \n#  # Step 2: {name2}\n#  def t2(g):\n# {indent_code(body2, 2)}\n \n#  # Apply both transformations\n#  intermediate = t1(g)\n#  return t2(intermediate)\n# \"\"\"\n\n# def try_conditional_combinations(task_data, pattern_handlers, analysis):\n#     \"\"\"Try applying patterns based on conditions\"\"\"\n#     debug_print(\"=== Trying conditional pattern combinations ===\", \"INFO\")\n    \n#     # Get shape info\n#     inp_shape = list(analysis['shape_changes'])[0][0]\n    \n#     # Try color-based conditions\n#     if analysis['color_count'] and max(analysis['color_count']) > 2:\n#         debug_print(\"  Trying color-based conditional patterns\", \"DEBUG\")\n        \n#         # Find handlers that work on specific colors\n#         color_handlers = []\n#         for handler in pattern_handlers[:20]:\n#             if 'color' in handler.__name__.lower():\n#                 try:\n#                     solution = handler(task_data, analysis)\n#                     if solution:\n#                         color_handlers.append((handler, solution))\n#                 except:\n#                     pass\n        \n#         # Try region-based handlers\n#         region_handlers = []\n#         for handler in pattern_handlers[:20]:\n#             if any(word in handler.__name__.lower() for word in ['region', 'quadrant', 'ring']):\n#                 try:\n#                     solution = handler(task_data, analysis)\n#                     if solution:\n#                         region_handlers.append((handler, solution))\n#                 except:\n#                     pass\n        \n#         # Combine color and region handlers\n#         for (ch, cs) in color_handlers[:3]:\n#             for (rh, rs) in region_handlers[:3]:\n#                 combined = create_conditional_combination(cs, rs, ch.__name__, rh.__name__, inp_shape)\n#                 if verify_solution(combined, task_data):\n#                     debug_print(f\" Found conditional combination: {ch.__name__} + {rh.__name__}\", \"SUCCESS\")\n#                     return combined\n    \n#     return None\n\n# def create_conditional_combination(sol1, sol2, name1, name2, shape):\n#     \"\"\"Create a solution that applies different patterns to different regions\"\"\"\n#     body1 = extract_function_body(sol1)\n#     body2 = extract_function_body(sol2)\n#     h, w = shape\n    \n#     return f\"\"\"def p(g):\n#  h,w={h},{w}\n#  res=[r[:]for r in g]\n \n#  # Apply {name1} to top half\n#  def t1(g):\n# {indent_code(body1, 2)}\n \n#  # Apply {name2} to bottom half\n#  def t2(g):\n# {indent_code(body2, 2)}\n \n#  # Split application\n#  top_half = [r[:] for r in g[:h//2]]\n#  bottom_half = [r[:] for r in g[h//2:]]\n \n#  top_result = t1(top_half)\n#  bottom_result = t2(bottom_half)\n \n#  return top_result + bottom_result\n# \"\"\"\n\n# def generate_solution(task_data):\n#     \"\"\"Enhanced solution generation with pattern combination\"\"\"\n#     global DEBUG_LOG, HANDLER_CACHE\n#     DEBUG_LOG = []  # Clear log for each task\n    \n#     # Check cache\n#     key = cache_key(task_data)\n#     if key in HANDLER_CACHE:\n#         debug_print(\"Found cached solution\", \"INFO\")\n#         return HANDLER_CACHE[key]\n    \n#     analysis = analyze_task(task_data)\n    \n#     debug_print(f\"\\n{'='*60}\", \"INFO\")\n#     debug_print(f\"Processing task with shape changes: {analysis['shape_changes']}\", \"INFO\")\n#     debug_print(f\"Color count: {analysis['color_count']}\", \"INFO\")\n#     debug_print(f\"Has objects: {analysis['has_objects']}\", \"INFO\")\n#     debug_print(f\"Has lines: {analysis['has_lines']}\", \"INFO\")\n    \n#     pattern_handlers = [\n#         handle_empty_input,\n#         handle_identity,\n#         handle_1d_raster_transform,\n#         handle_1d_pattern_repeat,\n#         handle_1d_sort_colors,\n#         handle_1d_run_length_decode,\n#         handle_1d_reverse_segments,\n#         handle_1d_shuffle_pattern,\n#         handle_1d_wave_transform,\n#         handle_1d_compression,\n#         handle_1d_periodic_transform,\n#         handle_1d_fibonacci_transform,\n#         handle_1d_prime_positions,\n#         handle_1d_alternating_ops,\n#         handle_diagonal_linearization,\n#         handle_hilbert_curve,\n#         handle_morton_order,\n#         handle_block_linearization,\n#         handle_snake_pattern,\n#         handle_radial_linearization,\n#         handle_odd_even_rows,\n#         handle_odd_even_cols,\n#         handle_checkerboard_transform,\n#         handle_parity_coloring,\n#         handle_alternating_blocks,\n#         handle_modular_arithmetic,\n#         handle_xor_patterns,\n#         handle_binary_operations,\n#         handle_bit_manipulation,\n#         handle_arithmetic_sequences,\n#         handle_geometric_sequences,\n#         handle_template_matching,\n#         handle_convolution_patterns,\n#         handle_morphological_ops,\n#         handle_edge_detection_advanced,\n#         handle_corner_detection,\n#         handle_pattern_completion_advanced,\n#         handle_graph_coloring,\n#         handle_tree_traversal,\n#         handle_component_labeling,\n#         handle_minimum_spanning_tree,\n#         handle_graph_isomorphism,\n#         handle_color_gradients,\n#         handle_color_mixing,\n#         handle_palette_reduction,\n#         handle_color_quantization,\n#         handle_color_spreading,\n#         handle_color_waves,\n#         handle_rotate_90,\n#         handle_rotate_180,\n#         handle_rotate_270,\n#         handle_flip_horizontal,\n#         handle_flip_vertical,\n#         handle_transpose,\n#         handle_rotate_45,\n#         handle_shear_transform,\n#         handle_perspective_transform,\n#         handle_upscale,\n#         handle_downscale,\n#         handle_pad_to_square,\n#         handle_crop_to_content,\n#         handle_zoom_center,\n#         handle_aspect_ratio_change,\n#         handle_repeat_pattern,\n#         handle_tile_pattern,\n#         handle_mirror_pattern,\n#         handle_extract_pattern,\n#         handle_apply_mask,\n#         handle_pattern_substitution,\n#         handle_count_objects,\n#         handle_largest_object,\n#         handle_move_objects,\n#         handle_gravity,\n#         handle_connect_same_color,\n#         handle_outline_objects,\n#         handle_fill_objects,\n#         handle_object_intersection,\n#         handle_draw_lines,\n#         handle_detect_lines,\n#         handle_extend_lines,\n#         handle_line_intersection,\n#         handle_perpendicular_lines,\n#         handle_make_symmetric,\n#         handle_complete_pattern,\n#         handle_find_symmetry_axis,\n#         handle_rotational_symmetry,\n#         handle_conway_step,\n#         handle_cellular_automaton,\n#         handle_maze_solve,\n#         handle_path_finding,\n#         handle_voronoi_regions,\n#         handle_fractal_generation,\n#         handle_multi_step_transform,\n#         handle_conditional_transform,\n#         handle_recursive_transform,\n#         handle_learned_transform,\n#         handle_color_count,\n#         handle_color_frequency_sort,\n#         handle_replace_most_common,\n#         handle_color_propagation,\n#         handle_flood_fill,\n#         handle_split_grid,\n#         handle_merge_grids,\n#         handle_overlay_grids,\n#         handle_subtract_grids,\n#         handle_color_mapping,\n#         # Add all the new handlers\n#         handle_diagonal_mirror,\n#         handle_color_inversion,\n#         handle_distance_coloring,\n#         handle_neighbor_sum_mod,\n#         handle_wave_propagation,\n#         handle_quadrant_operations,\n#         handle_ring_operations,\n#         handle_pattern_frequency,\n#         handle_sliding_window_ops,\n#         handle_cross_product_transform,\n#         handle_spiral_fill,\n#         handle_border_operations,\n#         handle_corner_operations,\n#         handle_chess_pattern,\n#         handle_diamond_pattern,\n#         handle_triangular_numbers,\n#         handle_color_cycle,\n#         handle_connectivity_color,\n#         handle_layered_transform,\n#         handle_local_symmetry,\n#         handle_shape_detection,\n#         handle_directional_fill,\n#         handle_boundary_trace,\n#         handle_color_gradient_fill,\n#         handle_pattern_interpolation,\n#         handle_region_growing,\n#         handle_symmetry_detection_fill,\n#         handle_pixel_sorting,\n#         handle_fractal_pattern,\n#         handle_position_encoding,\n#         handle_path_tracing,\n#         # Add all the new creative handlers\n#         handle_mask_arithmetic,\n#         handle_wraparound_shift,\n#         handle_1d_interleave,\n#         handle_diagonal_stripes,\n#         handle_cellular_rule,\n#         handle_prime_mask,\n#         handle_bit_pattern_mask,\n#         handle_symmetric_operations,\n#         handle_distance_transform,\n#         handle_modular_grid,\n#         handle_pattern_mask_multiply,\n#         handle_recursive_fill,\n#         handle_gradient_mask,\n#         handle_phase_shift_pattern,\n#         handle_overflow_mask,\n#         handle_1d_block_swap,\n#         handle_number_sequence_fill,\n#         handle_complex_bit_ops,\n#         handle_transformation_chain,\n#         handle_neighbor_product,\n#         handle_1d_segment_reverse,\n#         handle_symmetric_mask_ops,\n#     ]\n    \n#     debug_print(f\"Total handlers available: {len(pattern_handlers)}\", \"INFO\")\n    \n#     # PHASE 1: Try individual handlers\n#     debug_print(\"\\n=== PHASE 1: Trying individual handlers ===\", \"INFO\")\n    \n#     handlers_tried = 0\n#     handlers_with_solutions = 0\n#     handlers_with_exceptions = 0\n    \n#     for idx, handler in enumerate(pattern_handlers):\n#         handlers_tried += 1\n#         solution = handler(task_data, analysis)\n        \n#         if solution:\n#             handlers_with_solutions += 1\n#             debug_print(f\"   Handler #{idx+1} ({handler.__name__}) returned a solution\", \"DEBUG\")\n#             if verify_solution(solution, task_data):\n#                 debug_print(f\"   SOLUTION VERIFIED! Found by handler #{idx+1} ({handler.__name__})\", \"SUCCESS\")\n#                 debug_print(f\"  Stats: Tried {handlers_tried}/{len(pattern_handlers)} handlers\", \"INFO\")\n                \n#                 # Cache the solution\n#                 HANDLER_CACHE[key] = solution\n#                 return solution\n#             else:\n#                 debug_print(f\"   Solution failed verification\", \"WARNING\")\n    \n#     # PHASE 2: Try pattern combinations\n#     debug_print(\"\\n=== PHASE 2: Trying pattern combinations ===\", \"INFO\")\n    \n#     # Try sequential combinations\n#     combination_solution = try_sequential_combinations(task_data, pattern_handlers, analysis)\n#     if combination_solution:\n#         HANDLER_CACHE[key] = combination_solution\n#         return combination_solution\n    \n#     # Try conditional combinations\n#     combination_solution = try_conditional_combinations(task_data, pattern_handlers, analysis)\n#     if combination_solution:\n#         HANDLER_CACHE[key] = combination_solution\n#         return combination_solution\n    \n#     debug_print(f\"\\n  SUMMARY: Tried {handlers_tried} handlers, {handlers_with_solutions} returned solutions\", \"INFO\")\n#     debug_print(\"  No valid solution found - returning identity\", \"WARNING\")\n    \n#     identity_solution = \"\"\"def p(g):\n#  return g\n# \"\"\"\n#     HANDLER_CACHE[key] = identity_solution\n#     return identity_solution\n\n# # ==================== SECTION 18: MAIN EXECUTION ====================\n\n# def create_arc_solutions_enhanced(input_dir=\".\", output_dir=\"submission\"):\n#     \"\"\"Enhanced main execution with performance tracking and better reporting\"\"\"\n#     solutions = {}\n    \n#     os.makedirs(output_dir, exist_ok=True)\n    \n#     solved_count = 0\n#     total_count = 0\n#     start_time = time.time()\n    \n#     # Task difficulty tracking\n#     task_difficulty = defaultdict(int)\n    \n#     for task_num in range(1, 401):\n#         task_id = f\"{task_num:03d}\"\n#         task_file = os.path.join(input_dir, f\"task{task_id}.json\")\n        \n#         task_start_time = time.time()\n        \n#         try:\n#             with open(task_file) as f:\n#                 task_data = json.load(f)\n            \n#             solution = generate_solution(task_data)\n#             solutions[task_id] = solution\n            \n#             task_time = time.time() - task_start_time\n            \n#             if verify_solution(solution, task_data):\n#                 print(f\" Task {task_id} solved in {task_time:.2f}s\")\n#                 solved_count += 1\n                \n#                 # Track which handler solved it\n#                 for line in solution.split('\\n'):\n#                     if 'Step 1:' in line or 'Found' in line:\n#                         task_difficulty['easy'] += 1\n#                         break\n#                 else:\n#                     task_difficulty['hard'] += 1\n#             else:\n#                 print(f\" Task {task_id} fallback in {task_time:.2f}s\")\n#                 task_difficulty['failed'] += 1\n            \n#             total_count += 1\n            \n#             # Save debug log if debugging is enabled\n#             if DEBUG_MODE and DEBUG_LOG:\n#                 debug_file = os.path.join(output_dir, f\"debug_task{task_id}.log\")\n#                 with open(debug_file, \"w\") as f:\n#                     f.write(\"\\n\".join(DEBUG_LOG))\n                \n#         except Exception as e:\n#             print(f\"Error task {task_id}: {str(e)}\")\n#             solutions[task_id] = \"\"\"def p(g):\n#  return g\n# \"\"\"\n#             total_count += 1\n#             task_difficulty['error'] += 1\n    \n#     # Save solutions\n#     for task_id, code in solutions.items():\n#         output_file = os.path.join(output_dir, f\"task{task_id}.py\")\n#         with open(output_file, \"w\") as f:\n#             f.write(code)\n    \n#     # Create submission zip\n#     with zipfile.ZipFile(\"submission.zip\", \"w\") as zipf:\n#         for task_id in solutions:\n#             file_path = os.path.join(output_dir, f\"task{task_id}.py\")\n#             zipf.write(file_path, f\"task{task_id}.py\")\n    \n#     total_time = time.time() - start_time\n    \n#     # Print summary statistics\n#     print(f\"\\n{'='*60}\")\n#     print(f\"FINAL RESULTS\")\n#     print(f\"{'='*60}\")\n#     print(f\" Solved: {solved_count}/{total_count} ({solved_count/total_count*100:.1f}%)\")\n#     print(f\"  Total time: {total_time:.1f}s\")\n#     print(f\" Average time per task: {total_time/total_count:.2f}s\")\n#     print(f\"\\nDifficulty breakdown:\")\n#     for level, count in task_difficulty.items():\n#         print(f\"  {level}: {count}\")\n    \n#     # Print handler performance stats\n#     if PERFORMANCE_STATS:\n#         print(f\"\\nTop performing handlers:\")\n#         sorted_handlers = sorted(\n#             PERFORMANCE_STATS.items(), \n#             key=lambda x: x[1]['successes'], \n#             reverse=True\n#         )[:10]\n        \n#         for handler_name, stats in sorted_handlers:\n#             if stats['successes'] > 0:\n#                 avg_time = stats['total_time'] / stats['calls'] if stats['calls'] > 0 else 0\n#                 print(f\"  {handler_name}: {stats['successes']} successes, {avg_time:.3f}s avg\")\n    \n#     print(f\"\\n Created: submission.zip\")\n\n# if __name__ == \"__main__\":\n#     create_arc_solutions_enhanced(input_dir='/kaggle/input/google-code-golf-2025')","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}